2024-11-05 02:58 - INFO - Fit the preprocessing pipeline
2024-11-05 02:58 - INFO - Training using device: mps
2024-11-05 02:58 - INFO - Creating generators
2024-11-05 02:58 - INFO - The model has 651,257 trainable parameters
2024-11-05 02:58 - INFO - * Model:
2024-11-05 02:58 - INFO - * -----------
2024-11-05 02:58 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 02:58 - INFO - * -----------
2024-11-05 02:58 - INFO - Evaluating model based on: aucpr
2024-11-05 02:58 - INFO - Training..

2024-11-05 02:59 - INFO - ---------------------------------------------
2024-11-05 02:59 - INFO - Epoch: 01 | Time: 1m 42s
2024-11-05 02:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05131
2024-11-05 02:59 - INFO - 	 Train Loss: 0.252
2024-11-05 02:59 - INFO - 	 Val. Loss: 0.310
2024-11-05 02:59 - INFO - 	 ROC-AUC: 0.512
2024-11-05 02:59 - INFO - 	 PR-AUC: 0.051
2024-11-05 02:59 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 02:59 - INFO - 	 Best Val. Loss: 0.310
2024-11-05 02:59 - INFO - 	 Best ROC-AUC: 0.512
2024-11-05 02:59 - INFO - 	 Best PR-AUC: 0.051
2024-11-05 02:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.514
2024-11-05 02:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.053
2024-11-05 02:59 - INFO - 	 Best Recall for 0.4 precision: 0.002
2024-11-05 02:59 - INFO - ---------------------------------------------
2024-11-05 03:01 - INFO - ---------------------------------------------
2024-11-05 03:01 - INFO - Epoch: 02 | Time: 1m 46s
2024-11-05 03:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05352
2024-11-05 03:01 - INFO - 	 Train Loss: 0.206
2024-11-05 03:01 - INFO - 	 Val. Loss: 0.255
2024-11-05 03:01 - INFO - 	 ROC-AUC: 0.544
2024-11-05 03:01 - INFO - 	 PR-AUC: 0.054
2024-11-05 03:01 - INFO - 	 Recall for 0.4 precision: 0.026
2024-11-05 03:01 - INFO - 	 Best Val. Loss: 0.255
2024-11-05 03:01 - INFO - 	 Best ROC-AUC: 0.544
2024-11-05 03:01 - INFO - 	 Best PR-AUC: 0.054
2024-11-05 03:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.542
2024-11-05 03:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.055
2024-11-05 03:01 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:01 - INFO - ---------------------------------------------
2024-11-05 03:03 - INFO - ---------------------------------------------
2024-11-05 03:03 - INFO - Epoch: 03 | Time: 1m 48s
2024-11-05 03:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05953
2024-11-05 03:03 - INFO - 	 Train Loss: 0.198
2024-11-05 03:03 - INFO - 	 Val. Loss: 0.253
2024-11-05 03:03 - INFO - 	 ROC-AUC: 0.519
2024-11-05 03:03 - INFO - 	 PR-AUC: 0.060
2024-11-05 03:03 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 03:03 - INFO - 	 Best Val. Loss: 0.253
2024-11-05 03:03 - INFO - 	 Best ROC-AUC: 0.544
2024-11-05 03:03 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 03:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.542
2024-11-05 03:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 03:03 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:03 - INFO - ---------------------------------------------
2024-11-05 03:05 - INFO - ---------------------------------------------
2024-11-05 03:05 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 03:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05978
2024-11-05 03:05 - INFO - 	 Train Loss: 0.188
2024-11-05 03:05 - INFO - 	 Val. Loss: 0.234
2024-11-05 03:05 - INFO - 	 ROC-AUC: 0.546
2024-11-05 03:05 - INFO - 	 PR-AUC: 0.060
2024-11-05 03:05 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 03:05 - INFO - 	 Best Val. Loss: 0.234
2024-11-05 03:05 - INFO - 	 Best ROC-AUC: 0.546
2024-11-05 03:05 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 03:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.571
2024-11-05 03:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.071
2024-11-05 03:05 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:05 - INFO - ---------------------------------------------
2024-11-05 03:07 - INFO - ---------------------------------------------
2024-11-05 03:07 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-05 03:07 - INFO - 	 Train Loss: 0.187
2024-11-05 03:07 - INFO - 	 Val. Loss: 0.250
2024-11-05 03:07 - INFO - 	 ROC-AUC: 0.518
2024-11-05 03:07 - INFO - 	 PR-AUC: 0.057
2024-11-05 03:07 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 03:07 - INFO - 	 Best Val. Loss: 0.234
2024-11-05 03:07 - INFO - 	 Best ROC-AUC: 0.546
2024-11-05 03:07 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 03:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.571
2024-11-05 03:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.071
2024-11-05 03:07 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:07 - INFO - ---------------------------------------------
2024-11-05 03:09 - INFO - ---------------------------------------------
2024-11-05 03:09 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 03:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06363
2024-11-05 03:09 - INFO - 	 Train Loss: 0.185
2024-11-05 03:09 - INFO - 	 Val. Loss: 0.238
2024-11-05 03:09 - INFO - 	 ROC-AUC: 0.586
2024-11-05 03:09 - INFO - 	 PR-AUC: 0.064
2024-11-05 03:09 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-05 03:09 - INFO - 	 Best Val. Loss: 0.234
2024-11-05 03:09 - INFO - 	 Best ROC-AUC: 0.586
2024-11-05 03:09 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 03:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 03:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 03:09 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:09 - INFO - ---------------------------------------------
2024-11-05 03:10 - INFO - ---------------------------------------------
2024-11-05 03:10 - INFO - Epoch: 07 | Time: 1m 51s
2024-11-05 03:10 - INFO - 	 Train Loss: 0.182
2024-11-05 03:10 - INFO - 	 Val. Loss: 0.224
2024-11-05 03:10 - INFO - 	 ROC-AUC: 0.544
2024-11-05 03:10 - INFO - 	 PR-AUC: 0.060
2024-11-05 03:10 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 03:10 - INFO - 	 Best Val. Loss: 0.224
2024-11-05 03:10 - INFO - 	 Best ROC-AUC: 0.586
2024-11-05 03:10 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 03:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 03:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 03:10 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:10 - INFO - ---------------------------------------------
2024-11-05 03:12 - INFO - ---------------------------------------------
2024-11-05 03:12 - INFO - Epoch: 08 | Time: 1m 51s
2024-11-05 03:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06775
2024-11-05 03:12 - INFO - 	 Train Loss: 0.180
2024-11-05 03:12 - INFO - 	 Val. Loss: 0.207
2024-11-05 03:12 - INFO - 	 ROC-AUC: 0.567
2024-11-05 03:12 - INFO - 	 PR-AUC: 0.068
2024-11-05 03:12 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 03:12 - INFO - 	 Best Val. Loss: 0.207
2024-11-05 03:12 - INFO - 	 Best ROC-AUC: 0.586
2024-11-05 03:12 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 03:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 03:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.067
2024-11-05 03:12 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:12 - INFO - ---------------------------------------------
2024-11-05 03:14 - INFO - ---------------------------------------------
2024-11-05 03:14 - INFO - Epoch: 09 | Time: 1m 51s
2024-11-05 03:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07725
2024-11-05 03:14 - INFO - 	 Train Loss: 0.181
2024-11-05 03:14 - INFO - 	 Val. Loss: 0.208
2024-11-05 03:14 - INFO - 	 ROC-AUC: 0.632
2024-11-05 03:14 - INFO - 	 PR-AUC: 0.077
2024-11-05 03:14 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 03:14 - INFO - 	 Best Val. Loss: 0.207
2024-11-05 03:14 - INFO - 	 Best ROC-AUC: 0.632
2024-11-05 03:14 - INFO - 	 Best PR-AUC: 0.077
2024-11-05 03:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.608
2024-11-05 03:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.068
2024-11-05 03:14 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:14 - INFO - ---------------------------------------------
2024-11-05 03:16 - INFO - ---------------------------------------------
2024-11-05 03:16 - INFO - Epoch: 10 | Time: 1m 51s
2024-11-05 03:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.12376
2024-11-05 03:16 - INFO - 	 Train Loss: 0.176
2024-11-05 03:16 - INFO - 	 Val. Loss: 0.199
2024-11-05 03:16 - INFO - 	 ROC-AUC: 0.686
2024-11-05 03:16 - INFO - 	 PR-AUC: 0.124
2024-11-05 03:16 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 03:16 - INFO - 	 Best Val. Loss: 0.199
2024-11-05 03:16 - INFO - 	 Best ROC-AUC: 0.686
2024-11-05 03:16 - INFO - 	 Best PR-AUC: 0.124
2024-11-05 03:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.655
2024-11-05 03:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.090
2024-11-05 03:16 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-05 03:16 - INFO - ---------------------------------------------
2024-11-05 03:19 - INFO - Fit the preprocessing pipeline
2024-11-05 03:19 - INFO - Training using device: mps
2024-11-05 03:19 - INFO - Creating generators
2024-11-05 03:19 - INFO - The model has 651,257 trainable parameters
2024-11-05 03:19 - INFO - * Model:
2024-11-05 03:19 - INFO - * -----------
2024-11-05 03:19 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 03:19 - INFO - * -----------
2024-11-05 03:19 - INFO - Evaluating model based on: aucpr
2024-11-05 03:19 - INFO - Training..

2024-11-05 03:20 - INFO - ---------------------------------------------
2024-11-05 03:20 - INFO - Epoch: 01 | Time: 1m 39s
2024-11-05 03:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05647
2024-11-05 03:20 - INFO - 	 Train Loss: 0.253
2024-11-05 03:20 - INFO - 	 Val. Loss: 0.298
2024-11-05 03:20 - INFO - 	 ROC-AUC: 0.543
2024-11-05 03:20 - INFO - 	 PR-AUC: 0.056
2024-11-05 03:20 - INFO - 	 Recall for 0.4 precision: 0.062
2024-11-05 03:20 - INFO - 	 Best Val. Loss: 0.298
2024-11-05 03:20 - INFO - 	 Best ROC-AUC: 0.543
2024-11-05 03:20 - INFO - 	 Best PR-AUC: 0.056
2024-11-05 03:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.538
2024-11-05 03:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 03:20 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:20 - INFO - ---------------------------------------------
2024-11-05 03:22 - INFO - ---------------------------------------------
2024-11-05 03:22 - INFO - Epoch: 02 | Time: 1m 42s
2024-11-05 03:22 - INFO - 	 Train Loss: 0.205
2024-11-05 03:22 - INFO - 	 Val. Loss: 0.266
2024-11-05 03:22 - INFO - 	 ROC-AUC: 0.526
2024-11-05 03:22 - INFO - 	 PR-AUC: 0.052
2024-11-05 03:22 - INFO - 	 Recall for 0.4 precision: 0.023
2024-11-05 03:22 - INFO - 	 Best Val. Loss: 0.266
2024-11-05 03:22 - INFO - 	 Best ROC-AUC: 0.543
2024-11-05 03:22 - INFO - 	 Best PR-AUC: 0.056
2024-11-05 03:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.538
2024-11-05 03:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 03:22 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:22 - INFO - ---------------------------------------------
2024-11-05 03:24 - INFO - ---------------------------------------------
2024-11-05 03:24 - INFO - Epoch: 03 | Time: 1m 51s
2024-11-05 03:24 - INFO - 	 Train Loss: 0.192
2024-11-05 03:24 - INFO - 	 Val. Loss: 0.282
2024-11-05 03:24 - INFO - 	 ROC-AUC: 0.543
2024-11-05 03:24 - INFO - 	 PR-AUC: 0.053
2024-11-05 03:24 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-05 03:24 - INFO - 	 Best Val. Loss: 0.266
2024-11-05 03:24 - INFO - 	 Best ROC-AUC: 0.543
2024-11-05 03:24 - INFO - 	 Best PR-AUC: 0.056
2024-11-05 03:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.537
2024-11-05 03:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 03:24 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:24 - INFO - ---------------------------------------------
2024-11-05 03:26 - INFO - ---------------------------------------------
2024-11-05 03:26 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 03:26 - INFO - 	 Train Loss: 0.196
2024-11-05 03:26 - INFO - 	 Val. Loss: 0.243
2024-11-05 03:26 - INFO - 	 ROC-AUC: 0.578
2024-11-05 03:26 - INFO - 	 PR-AUC: 0.055
2024-11-05 03:26 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 03:26 - INFO - 	 Best Val. Loss: 0.243
2024-11-05 03:26 - INFO - 	 Best ROC-AUC: 0.578
2024-11-05 03:26 - INFO - 	 Best PR-AUC: 0.056
2024-11-05 03:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 03:26 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:26 - INFO - ---------------------------------------------
2024-11-05 03:28 - INFO - ---------------------------------------------
2024-11-05 03:28 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 03:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06757
2024-11-05 03:28 - INFO - 	 Train Loss: 0.186
2024-11-05 03:28 - INFO - 	 Val. Loss: 0.231
2024-11-05 03:28 - INFO - 	 ROC-AUC: 0.618
2024-11-05 03:28 - INFO - 	 PR-AUC: 0.068
2024-11-05 03:28 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 03:28 - INFO - 	 Best Val. Loss: 0.231
2024-11-05 03:28 - INFO - 	 Best ROC-AUC: 0.618
2024-11-05 03:28 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 03:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 03:28 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:28 - INFO - ---------------------------------------------
2024-11-05 03:29 - INFO - ---------------------------------------------
2024-11-05 03:29 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 03:29 - INFO - 	 Train Loss: 0.183
2024-11-05 03:29 - INFO - 	 Val. Loss: 0.218
2024-11-05 03:29 - INFO - 	 ROC-AUC: 0.596
2024-11-05 03:29 - INFO - 	 PR-AUC: 0.060
2024-11-05 03:29 - INFO - 	 Recall for 0.4 precision: 0.011
2024-11-05 03:29 - INFO - 	 Best Val. Loss: 0.218
2024-11-05 03:29 - INFO - 	 Best ROC-AUC: 0.618
2024-11-05 03:29 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 03:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 03:29 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:29 - INFO - ---------------------------------------------
2024-11-05 03:31 - INFO - ---------------------------------------------
2024-11-05 03:31 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 03:31 - INFO - 	 Train Loss: 0.181
2024-11-05 03:31 - INFO - 	 Val. Loss: 0.212
2024-11-05 03:31 - INFO - 	 ROC-AUC: 0.608
2024-11-05 03:31 - INFO - 	 PR-AUC: 0.063
2024-11-05 03:31 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 03:31 - INFO - 	 Best Val. Loss: 0.212
2024-11-05 03:31 - INFO - 	 Best ROC-AUC: 0.618
2024-11-05 03:31 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 03:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 03:31 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:31 - INFO - ---------------------------------------------
2024-11-05 03:33 - INFO - ---------------------------------------------
2024-11-05 03:33 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 03:33 - INFO - 	 Train Loss: 0.179
2024-11-05 03:33 - INFO - 	 Val. Loss: 0.210
2024-11-05 03:33 - INFO - 	 ROC-AUC: 0.604
2024-11-05 03:33 - INFO - 	 PR-AUC: 0.063
2024-11-05 03:33 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 03:33 - INFO - 	 Best Val. Loss: 0.210
2024-11-05 03:33 - INFO - 	 Best ROC-AUC: 0.618
2024-11-05 03:33 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 03:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 03:33 - INFO - 	 Best Recall for 0.4 precision: 0.062
2024-11-05 03:33 - INFO - ---------------------------------------------
2024-11-05 03:35 - INFO - ---------------------------------------------
2024-11-05 03:35 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 03:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14653
2024-11-05 03:35 - INFO - 	 Train Loss: 0.177
2024-11-05 03:35 - INFO - 	 Val. Loss: 0.208
2024-11-05 03:35 - INFO - 	 ROC-AUC: 0.602
2024-11-05 03:35 - INFO - 	 PR-AUC: 0.147
2024-11-05 03:35 - INFO - 	 Recall for 0.4 precision: 0.107
2024-11-05 03:35 - INFO - 	 Best Val. Loss: 0.208
2024-11-05 03:35 - INFO - 	 Best ROC-AUC: 0.618
2024-11-05 03:35 - INFO - 	 Best PR-AUC: 0.147
2024-11-05 03:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.587
2024-11-05 03:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 03:35 - INFO - 	 Best Recall for 0.4 precision: 0.107
2024-11-05 03:35 - INFO - ---------------------------------------------
2024-11-05 03:37 - INFO - ---------------------------------------------
2024-11-05 03:37 - INFO - Epoch: 10 | Time: 1m 51s
2024-11-05 03:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.17594
2024-11-05 03:37 - INFO - 	 Train Loss: 0.174
2024-11-05 03:37 - INFO - 	 Val. Loss: 0.196
2024-11-05 03:37 - INFO - 	 ROC-AUC: 0.690
2024-11-05 03:37 - INFO - 	 PR-AUC: 0.176
2024-11-05 03:37 - INFO - 	 Recall for 0.4 precision: 0.107
2024-11-05 03:37 - INFO - 	 Best Val. Loss: 0.196
2024-11-05 03:37 - INFO - 	 Best ROC-AUC: 0.690
2024-11-05 03:37 - INFO - 	 Best PR-AUC: 0.176
2024-11-05 03:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.644
2024-11-05 03:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.091
2024-11-05 03:37 - INFO - 	 Best Recall for 0.4 precision: 0.107
2024-11-05 03:37 - INFO - ---------------------------------------------
2024-11-05 03:39 - INFO - Fit the preprocessing pipeline
2024-11-05 03:39 - INFO - Training using device: mps
2024-11-05 03:39 - INFO - Creating generators
2024-11-05 03:39 - INFO - The model has 651,257 trainable parameters
2024-11-05 03:39 - INFO - * Model:
2024-11-05 03:39 - INFO - * -----------
2024-11-05 03:39 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 03:39 - INFO - * -----------
2024-11-05 03:39 - INFO - Evaluating model based on: aucpr
2024-11-05 03:39 - INFO - Training..

2024-11-05 03:41 - INFO - ---------------------------------------------
2024-11-05 03:41 - INFO - Epoch: 01 | Time: 1m 39s
2024-11-05 03:41 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05884
2024-11-05 03:41 - INFO - 	 Train Loss: 0.253
2024-11-05 03:41 - INFO - 	 Val. Loss: 0.324
2024-11-05 03:41 - INFO - 	 ROC-AUC: 0.526
2024-11-05 03:41 - INFO - 	 PR-AUC: 0.059
2024-11-05 03:41 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 03:41 - INFO - 	 Best Val. Loss: 0.324
2024-11-05 03:41 - INFO - 	 Best ROC-AUC: 0.526
2024-11-05 03:41 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 03:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.520
2024-11-05 03:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.055
2024-11-05 03:41 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 03:41 - INFO - ---------------------------------------------
2024-11-05 03:43 - INFO - ---------------------------------------------
2024-11-05 03:43 - INFO - Epoch: 02 | Time: 1m 42s
2024-11-05 03:43 - INFO - 	 Train Loss: 0.218
2024-11-05 03:43 - INFO - 	 Val. Loss: 0.276
2024-11-05 03:43 - INFO - 	 ROC-AUC: 0.564
2024-11-05 03:43 - INFO - 	 PR-AUC: 0.058
2024-11-05 03:43 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 03:43 - INFO - 	 Best Val. Loss: 0.276
2024-11-05 03:43 - INFO - 	 Best ROC-AUC: 0.564
2024-11-05 03:43 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 03:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.555
2024-11-05 03:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.055
2024-11-05 03:43 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 03:43 - INFO - ---------------------------------------------
2024-11-05 03:45 - INFO - ---------------------------------------------
2024-11-05 03:45 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 03:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.09544
2024-11-05 03:45 - INFO - 	 Train Loss: 0.195
2024-11-05 03:45 - INFO - 	 Val. Loss: 0.254
2024-11-05 03:45 - INFO - 	 ROC-AUC: 0.639
2024-11-05 03:45 - INFO - 	 PR-AUC: 0.095
2024-11-05 03:45 - INFO - 	 Recall for 0.4 precision: 0.008
2024-11-05 03:45 - INFO - 	 Best Val. Loss: 0.254
2024-11-05 03:45 - INFO - 	 Best ROC-AUC: 0.639
2024-11-05 03:45 - INFO - 	 Best PR-AUC: 0.095
2024-11-05 03:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.622
2024-11-05 03:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.078
2024-11-05 03:45 - INFO - 	 Best Recall for 0.4 precision: 0.008
2024-11-05 03:45 - INFO - ---------------------------------------------
2024-11-05 03:46 - INFO - ---------------------------------------------
2024-11-05 03:46 - INFO - Epoch: 04 | Time: 1m 47s
2024-11-05 03:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14287
2024-11-05 03:46 - INFO - 	 Train Loss: 0.186
2024-11-05 03:46 - INFO - 	 Val. Loss: 0.229
2024-11-05 03:46 - INFO - 	 ROC-AUC: 0.706
2024-11-05 03:46 - INFO - 	 PR-AUC: 0.143
2024-11-05 03:46 - INFO - 	 Recall for 0.4 precision: 0.041
2024-11-05 03:46 - INFO - 	 Best Val. Loss: 0.229
2024-11-05 03:46 - INFO - 	 Best ROC-AUC: 0.706
2024-11-05 03:46 - INFO - 	 Best PR-AUC: 0.143
2024-11-05 03:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.662
2024-11-05 03:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.104
2024-11-05 03:46 - INFO - 	 Best Recall for 0.4 precision: 0.041
2024-11-05 03:46 - INFO - ---------------------------------------------
2024-11-05 03:48 - INFO - ---------------------------------------------
2024-11-05 03:48 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 03:48 - INFO - 	 New best val_rocauc loss was found, current best value is 0.18649
2024-11-05 03:48 - INFO - 	 Train Loss: 0.184
2024-11-05 03:48 - INFO - 	 Val. Loss: 0.213
2024-11-05 03:48 - INFO - 	 ROC-AUC: 0.719
2024-11-05 03:48 - INFO - 	 PR-AUC: 0.186
2024-11-05 03:48 - INFO - 	 Recall for 0.4 precision: 0.109
2024-11-05 03:48 - INFO - 	 Best Val. Loss: 0.213
2024-11-05 03:48 - INFO - 	 Best ROC-AUC: 0.719
2024-11-05 03:48 - INFO - 	 Best PR-AUC: 0.186
2024-11-05 03:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.686
2024-11-05 03:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.116
2024-11-05 03:48 - INFO - 	 Best Recall for 0.4 precision: 0.109
2024-11-05 03:48 - INFO - ---------------------------------------------
2024-11-05 03:50 - INFO - ---------------------------------------------
2024-11-05 03:50 - INFO - Epoch: 06 | Time: 1m 49s
2024-11-05 03:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.21219
2024-11-05 03:50 - INFO - 	 Train Loss: 0.169
2024-11-05 03:50 - INFO - 	 Val. Loss: 0.203
2024-11-05 03:50 - INFO - 	 ROC-AUC: 0.743
2024-11-05 03:50 - INFO - 	 PR-AUC: 0.212
2024-11-05 03:50 - INFO - 	 Recall for 0.4 precision: 0.169
2024-11-05 03:50 - INFO - 	 Best Val. Loss: 0.203
2024-11-05 03:50 - INFO - 	 Best ROC-AUC: 0.743
2024-11-05 03:50 - INFO - 	 Best PR-AUC: 0.212
2024-11-05 03:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.671
2024-11-05 03:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.109
2024-11-05 03:50 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 03:50 - INFO - ---------------------------------------------
2024-11-05 03:52 - INFO - ---------------------------------------------
2024-11-05 03:52 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-05 03:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22712
2024-11-05 03:52 - INFO - 	 Train Loss: 0.161
2024-11-05 03:52 - INFO - 	 Val. Loss: 0.190
2024-11-05 03:52 - INFO - 	 ROC-AUC: 0.777
2024-11-05 03:52 - INFO - 	 PR-AUC: 0.227
2024-11-05 03:52 - INFO - 	 Recall for 0.4 precision: 0.151
2024-11-05 03:52 - INFO - 	 Best Val. Loss: 0.190
2024-11-05 03:52 - INFO - 	 Best ROC-AUC: 0.777
2024-11-05 03:52 - INFO - 	 Best PR-AUC: 0.227
2024-11-05 03:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-11-05 03:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.118
2024-11-05 03:52 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 03:52 - INFO - ---------------------------------------------
2024-11-05 03:54 - INFO - ---------------------------------------------
2024-11-05 03:54 - INFO - Epoch: 08 | Time: 1m 49s
2024-11-05 03:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30741
2024-11-05 03:54 - INFO - 	 Train Loss: 0.154
2024-11-05 03:54 - INFO - 	 Val. Loss: 0.209
2024-11-05 03:54 - INFO - 	 ROC-AUC: 0.888
2024-11-05 03:54 - INFO - 	 PR-AUC: 0.307
2024-11-05 03:54 - INFO - 	 Recall for 0.4 precision: 0.267
2024-11-05 03:54 - INFO - 	 Best Val. Loss: 0.190
2024-11-05 03:54 - INFO - 	 Best ROC-AUC: 0.888
2024-11-05 03:54 - INFO - 	 Best PR-AUC: 0.307
2024-11-05 03:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.818
2024-11-05 03:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-05 03:54 - INFO - 	 Best Recall for 0.4 precision: 0.267
2024-11-05 03:54 - INFO - ---------------------------------------------
2024-11-05 03:56 - INFO - ---------------------------------------------
2024-11-05 03:56 - INFO - Epoch: 09 | Time: 1m 51s
2024-11-05 03:56 - INFO - 	 Train Loss: 0.141
2024-11-05 03:56 - INFO - 	 Val. Loss: 0.162
2024-11-05 03:56 - INFO - 	 ROC-AUC: 0.874
2024-11-05 03:56 - INFO - 	 PR-AUC: 0.260
2024-11-05 03:56 - INFO - 	 Recall for 0.4 precision: 0.120
2024-11-05 03:56 - INFO - 	 Best Val. Loss: 0.162
2024-11-05 03:56 - INFO - 	 Best ROC-AUC: 0.888
2024-11-05 03:56 - INFO - 	 Best PR-AUC: 0.307
2024-11-05 03:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.818
2024-11-05 03:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-05 03:56 - INFO - 	 Best Recall for 0.4 precision: 0.267
2024-11-05 03:56 - INFO - ---------------------------------------------
2024-11-05 03:57 - INFO - ---------------------------------------------
2024-11-05 03:57 - INFO - Epoch: 10 | Time: 1m 49s
2024-11-05 03:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31983
2024-11-05 03:57 - INFO - 	 Train Loss: 0.132
2024-11-05 03:57 - INFO - 	 Val. Loss: 0.163
2024-11-05 03:57 - INFO - 	 ROC-AUC: 0.906
2024-11-05 03:57 - INFO - 	 PR-AUC: 0.320
2024-11-05 03:57 - INFO - 	 Recall for 0.4 precision: 0.280
2024-11-05 03:57 - INFO - 	 Best Val. Loss: 0.162
2024-11-05 03:57 - INFO - 	 Best ROC-AUC: 0.906
2024-11-05 03:57 - INFO - 	 Best PR-AUC: 0.320
2024-11-05 03:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.869
2024-11-05 03:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.211
2024-11-05 03:57 - INFO - 	 Best Recall for 0.4 precision: 0.280
2024-11-05 03:57 - INFO - ---------------------------------------------
2024-11-05 04:00 - INFO - Fit the preprocessing pipeline
2024-11-05 04:00 - INFO - Training using device: mps
2024-11-05 04:00 - INFO - Creating generators
2024-11-05 04:00 - INFO - The model has 651,257 trainable parameters
2024-11-05 04:00 - INFO - * Model:
2024-11-05 04:00 - INFO - * -----------
2024-11-05 04:00 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 04:00 - INFO - * -----------
2024-11-05 04:00 - INFO - Evaluating model based on: aucpr
2024-11-05 04:00 - INFO - Training..

2024-11-05 04:02 - INFO - ---------------------------------------------
2024-11-05 04:02 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 04:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05387
2024-11-05 04:02 - INFO - 	 Train Loss: 0.248
2024-11-05 04:02 - INFO - 	 Val. Loss: 0.309
2024-11-05 04:02 - INFO - 	 ROC-AUC: 0.573
2024-11-05 04:02 - INFO - 	 PR-AUC: 0.054
2024-11-05 04:02 - INFO - 	 Recall for 0.4 precision: 0.029
2024-11-05 04:02 - INFO - 	 Best Val. Loss: 0.309
2024-11-05 04:02 - INFO - 	 Best ROC-AUC: 0.573
2024-11-05 04:02 - INFO - 	 Best PR-AUC: 0.054
2024-11-05 04:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.567
2024-11-05 04:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.056
2024-11-05 04:02 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:02 - INFO - ---------------------------------------------
2024-11-05 04:03 - INFO - ---------------------------------------------
2024-11-05 04:03 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 04:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05432
2024-11-05 04:03 - INFO - 	 Train Loss: 0.207
2024-11-05 04:03 - INFO - 	 Val. Loss: 0.273
2024-11-05 04:03 - INFO - 	 ROC-AUC: 0.561
2024-11-05 04:03 - INFO - 	 PR-AUC: 0.054
2024-11-05 04:03 - INFO - 	 Recall for 0.4 precision: 0.008
2024-11-05 04:03 - INFO - 	 Best Val. Loss: 0.273
2024-11-05 04:03 - INFO - 	 Best ROC-AUC: 0.573
2024-11-05 04:03 - INFO - 	 Best PR-AUC: 0.054
2024-11-05 04:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.567
2024-11-05 04:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.061
2024-11-05 04:03 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:03 - INFO - ---------------------------------------------
2024-11-05 04:05 - INFO - ---------------------------------------------
2024-11-05 04:05 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 04:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06353
2024-11-05 04:05 - INFO - 	 Train Loss: 0.200
2024-11-05 04:05 - INFO - 	 Val. Loss: 0.256
2024-11-05 04:05 - INFO - 	 ROC-AUC: 0.581
2024-11-05 04:05 - INFO - 	 PR-AUC: 0.064
2024-11-05 04:05 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:05 - INFO - 	 Best Val. Loss: 0.256
2024-11-05 04:05 - INFO - 	 Best ROC-AUC: 0.581
2024-11-05 04:05 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 04:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 04:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 04:05 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:05 - INFO - ---------------------------------------------
2024-11-05 04:07 - INFO - ---------------------------------------------
2024-11-05 04:07 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 04:07 - INFO - 	 Train Loss: 0.190
2024-11-05 04:07 - INFO - 	 Val. Loss: 0.235
2024-11-05 04:07 - INFO - 	 ROC-AUC: 0.606
2024-11-05 04:07 - INFO - 	 PR-AUC: 0.062
2024-11-05 04:07 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:07 - INFO - 	 Best Val. Loss: 0.235
2024-11-05 04:07 - INFO - 	 Best ROC-AUC: 0.606
2024-11-05 04:07 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 04:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 04:07 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:07 - INFO - ---------------------------------------------
2024-11-05 04:09 - INFO - ---------------------------------------------
2024-11-05 04:09 - INFO - Epoch: 05 | Time: 1m 48s
2024-11-05 04:09 - INFO - 	 Train Loss: 0.188
2024-11-05 04:09 - INFO - 	 Val. Loss: 0.226
2024-11-05 04:09 - INFO - 	 ROC-AUC: 0.577
2024-11-05 04:09 - INFO - 	 PR-AUC: 0.061
2024-11-05 04:09 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:09 - INFO - 	 Best Val. Loss: 0.226
2024-11-05 04:09 - INFO - 	 Best ROC-AUC: 0.606
2024-11-05 04:09 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 04:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 04:09 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:09 - INFO - ---------------------------------------------
2024-11-05 04:11 - INFO - ---------------------------------------------
2024-11-05 04:11 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 04:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06996
2024-11-05 04:11 - INFO - 	 Train Loss: 0.188
2024-11-05 04:11 - INFO - 	 Val. Loss: 0.223
2024-11-05 04:11 - INFO - 	 ROC-AUC: 0.633
2024-11-05 04:11 - INFO - 	 PR-AUC: 0.070
2024-11-05 04:11 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:11 - INFO - 	 Best Val. Loss: 0.223
2024-11-05 04:11 - INFO - 	 Best ROC-AUC: 0.633
2024-11-05 04:11 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.613
2024-11-05 04:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.068
2024-11-05 04:11 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:11 - INFO - ---------------------------------------------
2024-11-05 04:13 - INFO - ---------------------------------------------
2024-11-05 04:13 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 04:13 - INFO - 	 Train Loss: 0.185
2024-11-05 04:13 - INFO - 	 Val. Loss: 0.222
2024-11-05 04:13 - INFO - 	 ROC-AUC: 0.608
2024-11-05 04:13 - INFO - 	 PR-AUC: 0.062
2024-11-05 04:13 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:13 - INFO - 	 Best Val. Loss: 0.222
2024-11-05 04:13 - INFO - 	 Best ROC-AUC: 0.633
2024-11-05 04:13 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.613
2024-11-05 04:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.068
2024-11-05 04:13 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:13 - INFO - ---------------------------------------------
2024-11-05 04:14 - INFO - ---------------------------------------------
2024-11-05 04:14 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 04:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.08981
2024-11-05 04:14 - INFO - 	 Train Loss: 0.181
2024-11-05 04:14 - INFO - 	 Val. Loss: 0.206
2024-11-05 04:14 - INFO - 	 ROC-AUC: 0.637
2024-11-05 04:14 - INFO - 	 PR-AUC: 0.090
2024-11-05 04:14 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 04:14 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 04:14 - INFO - 	 Best ROC-AUC: 0.637
2024-11-05 04:14 - INFO - 	 Best PR-AUC: 0.090
2024-11-05 04:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.617
2024-11-05 04:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:14 - INFO - 	 Best Recall for 0.4 precision: 0.029
2024-11-05 04:14 - INFO - ---------------------------------------------
2024-11-05 04:16 - INFO - ---------------------------------------------
2024-11-05 04:16 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 04:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.09566
2024-11-05 04:16 - INFO - 	 Train Loss: 0.180
2024-11-05 04:16 - INFO - 	 Val. Loss: 0.215
2024-11-05 04:16 - INFO - 	 ROC-AUC: 0.649
2024-11-05 04:16 - INFO - 	 PR-AUC: 0.096
2024-11-05 04:16 - INFO - 	 Recall for 0.4 precision: 0.034
2024-11-05 04:16 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 04:16 - INFO - 	 Best ROC-AUC: 0.649
2024-11-05 04:16 - INFO - 	 Best PR-AUC: 0.096
2024-11-05 04:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.624
2024-11-05 04:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.076
2024-11-05 04:16 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 04:16 - INFO - ---------------------------------------------
2024-11-05 04:18 - INFO - ---------------------------------------------
2024-11-05 04:18 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 04:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.12873
2024-11-05 04:18 - INFO - 	 Train Loss: 0.178
2024-11-05 04:18 - INFO - 	 Val. Loss: 0.225
2024-11-05 04:18 - INFO - 	 ROC-AUC: 0.693
2024-11-05 04:18 - INFO - 	 PR-AUC: 0.129
2024-11-05 04:18 - INFO - 	 Recall for 0.4 precision: 0.033
2024-11-05 04:18 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 04:18 - INFO - 	 Best ROC-AUC: 0.693
2024-11-05 04:18 - INFO - 	 Best PR-AUC: 0.129
2024-11-05 04:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.643
2024-11-05 04:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.089
2024-11-05 04:18 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 04:18 - INFO - ---------------------------------------------
2024-11-05 04:21 - INFO - Fit the preprocessing pipeline
2024-11-05 04:21 - INFO - Training using device: mps
2024-11-05 04:21 - INFO - Creating generators
2024-11-05 04:21 - INFO - The model has 651,257 trainable parameters
2024-11-05 04:21 - INFO - * Model:
2024-11-05 04:21 - INFO - * -----------
2024-11-05 04:21 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 04:21 - INFO - * -----------
2024-11-05 04:21 - INFO - Evaluating model based on: aucpr
2024-11-05 04:21 - INFO - Training..

2024-11-05 04:22 - INFO - ---------------------------------------------
2024-11-05 04:22 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 04:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.0514
2024-11-05 04:22 - INFO - 	 Train Loss: 0.260
2024-11-05 04:22 - INFO - 	 Val. Loss: 0.289
2024-11-05 04:22 - INFO - 	 ROC-AUC: 0.508
2024-11-05 04:22 - INFO - 	 PR-AUC: 0.051
2024-11-05 04:22 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:22 - INFO - 	 Best Val. Loss: 0.289
2024-11-05 04:22 - INFO - 	 Best ROC-AUC: 0.508
2024-11-05 04:22 - INFO - 	 Best PR-AUC: 0.051
2024-11-05 04:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.510
2024-11-05 04:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.053
2024-11-05 04:22 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 04:22 - INFO - ---------------------------------------------
2024-11-05 04:24 - INFO - ---------------------------------------------
2024-11-05 04:24 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 04:24 - INFO - 	 Train Loss: 0.212
2024-11-05 04:24 - INFO - 	 Val. Loss: 0.277
2024-11-05 04:24 - INFO - 	 ROC-AUC: 0.523
2024-11-05 04:24 - INFO - 	 PR-AUC: 0.050
2024-11-05 04:24 - INFO - 	 Recall for 0.4 precision: 0.047
2024-11-05 04:24 - INFO - 	 Best Val. Loss: 0.277
2024-11-05 04:24 - INFO - 	 Best ROC-AUC: 0.523
2024-11-05 04:24 - INFO - 	 Best PR-AUC: 0.051
2024-11-05 04:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.521
2024-11-05 04:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.053
2024-11-05 04:24 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:24 - INFO - ---------------------------------------------
2024-11-05 04:26 - INFO - ---------------------------------------------
2024-11-05 04:26 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 04:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06019
2024-11-05 04:26 - INFO - 	 Train Loss: 0.199
2024-11-05 04:26 - INFO - 	 Val. Loss: 0.273
2024-11-05 04:26 - INFO - 	 ROC-AUC: 0.546
2024-11-05 04:26 - INFO - 	 PR-AUC: 0.060
2024-11-05 04:26 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:26 - INFO - 	 Best Val. Loss: 0.273
2024-11-05 04:26 - INFO - 	 Best ROC-AUC: 0.546
2024-11-05 04:26 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 04:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.584
2024-11-05 04:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.071
2024-11-05 04:26 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:26 - INFO - ---------------------------------------------
2024-11-05 04:28 - INFO - ---------------------------------------------
2024-11-05 04:28 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 04:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06338
2024-11-05 04:28 - INFO - 	 Train Loss: 0.193
2024-11-05 04:28 - INFO - 	 Val. Loss: 0.258
2024-11-05 04:28 - INFO - 	 ROC-AUC: 0.589
2024-11-05 04:28 - INFO - 	 PR-AUC: 0.063
2024-11-05 04:28 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 04:28 - INFO - 	 Best Val. Loss: 0.258
2024-11-05 04:28 - INFO - 	 Best ROC-AUC: 0.589
2024-11-05 04:28 - INFO - 	 Best PR-AUC: 0.063
2024-11-05 04:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 04:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 04:28 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:28 - INFO - ---------------------------------------------
2024-11-05 04:30 - INFO - ---------------------------------------------
2024-11-05 04:30 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-05 04:30 - INFO - 	 Train Loss: 0.187
2024-11-05 04:30 - INFO - 	 Val. Loss: 0.228
2024-11-05 04:30 - INFO - 	 ROC-AUC: 0.529
2024-11-05 04:30 - INFO - 	 PR-AUC: 0.059
2024-11-05 04:30 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:30 - INFO - 	 Best Val. Loss: 0.228
2024-11-05 04:30 - INFO - 	 Best ROC-AUC: 0.589
2024-11-05 04:30 - INFO - 	 Best PR-AUC: 0.063
2024-11-05 04:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 04:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 04:30 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:30 - INFO - ---------------------------------------------
2024-11-05 04:31 - INFO - ---------------------------------------------
2024-11-05 04:31 - INFO - Epoch: 06 | Time: 1m 49s
2024-11-05 04:31 - INFO - 	 Train Loss: 0.187
2024-11-05 04:31 - INFO - 	 Val. Loss: 0.224
2024-11-05 04:31 - INFO - 	 ROC-AUC: 0.553
2024-11-05 04:31 - INFO - 	 PR-AUC: 0.055
2024-11-05 04:31 - INFO - 	 Recall for 0.4 precision: 0.023
2024-11-05 04:31 - INFO - 	 Best Val. Loss: 0.224
2024-11-05 04:31 - INFO - 	 Best ROC-AUC: 0.589
2024-11-05 04:31 - INFO - 	 Best PR-AUC: 0.063
2024-11-05 04:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 04:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 04:31 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:31 - INFO - ---------------------------------------------
2024-11-05 04:33 - INFO - ---------------------------------------------
2024-11-05 04:33 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-05 04:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.067
2024-11-05 04:33 - INFO - 	 Train Loss: 0.182
2024-11-05 04:33 - INFO - 	 Val. Loss: 0.223
2024-11-05 04:33 - INFO - 	 ROC-AUC: 0.566
2024-11-05 04:33 - INFO - 	 PR-AUC: 0.067
2024-11-05 04:33 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:33 - INFO - 	 Best Val. Loss: 0.223
2024-11-05 04:33 - INFO - 	 Best ROC-AUC: 0.589
2024-11-05 04:33 - INFO - 	 Best PR-AUC: 0.067
2024-11-05 04:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 04:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 04:33 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:33 - INFO - ---------------------------------------------
2024-11-05 04:35 - INFO - ---------------------------------------------
2024-11-05 04:35 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 04:35 - INFO - 	 Train Loss: 0.180
2024-11-05 04:35 - INFO - 	 Val. Loss: 0.212
2024-11-05 04:35 - INFO - 	 ROC-AUC: 0.558
2024-11-05 04:35 - INFO - 	 PR-AUC: 0.058
2024-11-05 04:35 - INFO - 	 Recall for 0.4 precision: 0.036
2024-11-05 04:35 - INFO - 	 Best Val. Loss: 0.212
2024-11-05 04:35 - INFO - 	 Best ROC-AUC: 0.589
2024-11-05 04:35 - INFO - 	 Best PR-AUC: 0.067
2024-11-05 04:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 04:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 04:35 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:35 - INFO - ---------------------------------------------
2024-11-05 04:37 - INFO - ---------------------------------------------
2024-11-05 04:37 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 04:37 - INFO - 	 Train Loss: 0.179
2024-11-05 04:37 - INFO - 	 Val. Loss: 0.206
2024-11-05 04:37 - INFO - 	 ROC-AUC: 0.614
2024-11-05 04:37 - INFO - 	 PR-AUC: 0.066
2024-11-05 04:37 - INFO - 	 Recall for 0.4 precision: 0.026
2024-11-05 04:37 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 04:37 - INFO - 	 Best ROC-AUC: 0.614
2024-11-05 04:37 - INFO - 	 Best PR-AUC: 0.067
2024-11-05 04:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.572
2024-11-05 04:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 04:37 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:37 - INFO - ---------------------------------------------
2024-11-05 04:39 - INFO - ---------------------------------------------
2024-11-05 04:39 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 04:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07327
2024-11-05 04:39 - INFO - 	 Train Loss: 0.178
2024-11-05 04:39 - INFO - 	 Val. Loss: 0.203
2024-11-05 04:39 - INFO - 	 ROC-AUC: 0.594
2024-11-05 04:39 - INFO - 	 PR-AUC: 0.073
2024-11-05 04:39 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:39 - INFO - 	 Best Val. Loss: 0.203
2024-11-05 04:39 - INFO - 	 Best ROC-AUC: 0.614
2024-11-05 04:39 - INFO - 	 Best PR-AUC: 0.073
2024-11-05 04:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.572
2024-11-05 04:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.073
2024-11-05 04:39 - INFO - 	 Best Recall for 0.4 precision: 0.047
2024-11-05 04:39 - INFO - ---------------------------------------------
2024-11-05 04:41 - INFO - Fit the preprocessing pipeline
2024-11-05 04:41 - INFO - Training using device: mps
2024-11-05 04:41 - INFO - Creating generators
2024-11-05 04:41 - INFO - The model has 651,257 trainable parameters
2024-11-05 04:41 - INFO - * Model:
2024-11-05 04:41 - INFO - * -----------
2024-11-05 04:41 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 04:41 - INFO - * -----------
2024-11-05 04:41 - INFO - Evaluating model based on: aucpr
2024-11-05 04:41 - INFO - Training..

2024-11-05 04:43 - INFO - ---------------------------------------------
2024-11-05 04:43 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 04:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.04949
2024-11-05 04:43 - INFO - 	 Train Loss: 0.249
2024-11-05 04:43 - INFO - 	 Val. Loss: 0.296
2024-11-05 04:43 - INFO - 	 ROC-AUC: 0.531
2024-11-05 04:43 - INFO - 	 PR-AUC: 0.049
2024-11-05 04:43 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 04:43 - INFO - 	 Best Val. Loss: 0.296
2024-11-05 04:43 - INFO - 	 Best ROC-AUC: 0.531
2024-11-05 04:43 - INFO - 	 Best PR-AUC: 0.049
2024-11-05 04:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.555
2024-11-05 04:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 04:43 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:43 - INFO - ---------------------------------------------
2024-11-05 04:45 - INFO - ---------------------------------------------
2024-11-05 04:45 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 04:45 - INFO - 	 Train Loss: 0.208
2024-11-05 04:45 - INFO - 	 Val. Loss: 0.279
2024-11-05 04:45 - INFO - 	 ROC-AUC: 0.519
2024-11-05 04:45 - INFO - 	 PR-AUC: 0.049
2024-11-05 04:45 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:45 - INFO - 	 Best Val. Loss: 0.279
2024-11-05 04:45 - INFO - 	 Best ROC-AUC: 0.531
2024-11-05 04:45 - INFO - 	 Best PR-AUC: 0.049
2024-11-05 04:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.555
2024-11-05 04:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 04:45 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:45 - INFO - ---------------------------------------------
2024-11-05 04:47 - INFO - ---------------------------------------------
2024-11-05 04:47 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 04:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06562
2024-11-05 04:47 - INFO - 	 Train Loss: 0.205
2024-11-05 04:47 - INFO - 	 Val. Loss: 0.265
2024-11-05 04:47 - INFO - 	 ROC-AUC: 0.595
2024-11-05 04:47 - INFO - 	 PR-AUC: 0.066
2024-11-05 04:47 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:47 - INFO - 	 Best Val. Loss: 0.265
2024-11-05 04:47 - INFO - 	 Best ROC-AUC: 0.595
2024-11-05 04:47 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 04:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.564
2024-11-05 04:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.064
2024-11-05 04:47 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:47 - INFO - ---------------------------------------------
2024-11-05 04:48 - INFO - ---------------------------------------------
2024-11-05 04:48 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 04:48 - INFO - 	 Train Loss: 0.198
2024-11-05 04:48 - INFO - 	 Val. Loss: 0.268
2024-11-05 04:48 - INFO - 	 ROC-AUC: 0.556
2024-11-05 04:48 - INFO - 	 PR-AUC: 0.058
2024-11-05 04:48 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:48 - INFO - 	 Best Val. Loss: 0.265
2024-11-05 04:48 - INFO - 	 Best ROC-AUC: 0.595
2024-11-05 04:48 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 04:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.564
2024-11-05 04:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.064
2024-11-05 04:48 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:48 - INFO - ---------------------------------------------
2024-11-05 04:50 - INFO - ---------------------------------------------
2024-11-05 04:50 - INFO - Epoch: 05 | Time: 1m 48s
2024-11-05 04:50 - INFO - 	 Train Loss: 0.196
2024-11-05 04:50 - INFO - 	 Val. Loss: 0.247
2024-11-05 04:50 - INFO - 	 ROC-AUC: 0.563
2024-11-05 04:50 - INFO - 	 PR-AUC: 0.060
2024-11-05 04:50 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:50 - INFO - 	 Best Val. Loss: 0.247
2024-11-05 04:50 - INFO - 	 Best ROC-AUC: 0.595
2024-11-05 04:50 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 04:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.564
2024-11-05 04:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.064
2024-11-05 04:50 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:50 - INFO - ---------------------------------------------
2024-11-05 04:52 - INFO - ---------------------------------------------
2024-11-05 04:52 - INFO - Epoch: 06 | Time: 1m 49s
2024-11-05 04:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06997
2024-11-05 04:52 - INFO - 	 Train Loss: 0.186
2024-11-05 04:52 - INFO - 	 Val. Loss: 0.234
2024-11-05 04:52 - INFO - 	 ROC-AUC: 0.608
2024-11-05 04:52 - INFO - 	 PR-AUC: 0.070
2024-11-05 04:52 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:52 - INFO - 	 Best Val. Loss: 0.234
2024-11-05 04:52 - INFO - 	 Best ROC-AUC: 0.608
2024-11-05 04:52 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:52 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:52 - INFO - ---------------------------------------------
2024-11-05 04:54 - INFO - ---------------------------------------------
2024-11-05 04:54 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-05 04:54 - INFO - 	 Train Loss: 0.186
2024-11-05 04:54 - INFO - 	 Val. Loss: 0.219
2024-11-05 04:54 - INFO - 	 ROC-AUC: 0.543
2024-11-05 04:54 - INFO - 	 PR-AUC: 0.050
2024-11-05 04:54 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:54 - INFO - 	 Best Val. Loss: 0.219
2024-11-05 04:54 - INFO - 	 Best ROC-AUC: 0.608
2024-11-05 04:54 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:54 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:54 - INFO - ---------------------------------------------
2024-11-05 04:56 - INFO - ---------------------------------------------
2024-11-05 04:56 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 04:56 - INFO - 	 Train Loss: 0.182
2024-11-05 04:56 - INFO - 	 Val. Loss: 0.219
2024-11-05 04:56 - INFO - 	 ROC-AUC: 0.592
2024-11-05 04:56 - INFO - 	 PR-AUC: 0.068
2024-11-05 04:56 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 04:56 - INFO - 	 Best Val. Loss: 0.219
2024-11-05 04:56 - INFO - 	 Best ROC-AUC: 0.608
2024-11-05 04:56 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:56 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:56 - INFO - ---------------------------------------------
2024-11-05 04:58 - INFO - ---------------------------------------------
2024-11-05 04:58 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 04:58 - INFO - 	 Train Loss: 0.181
2024-11-05 04:58 - INFO - 	 Val. Loss: 0.210
2024-11-05 04:58 - INFO - 	 ROC-AUC: 0.583
2024-11-05 04:58 - INFO - 	 PR-AUC: 0.063
2024-11-05 04:58 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 04:58 - INFO - 	 Best Val. Loss: 0.210
2024-11-05 04:58 - INFO - 	 Best ROC-AUC: 0.608
2024-11-05 04:58 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 04:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.580
2024-11-05 04:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:58 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:58 - INFO - ---------------------------------------------
2024-11-05 04:59 - INFO - ---------------------------------------------
2024-11-05 04:59 - INFO - Epoch: 10 | Time: 1m 49s
2024-11-05 04:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.09161
2024-11-05 04:59 - INFO - 	 Train Loss: 0.179
2024-11-05 04:59 - INFO - 	 Val. Loss: 0.205
2024-11-05 04:59 - INFO - 	 ROC-AUC: 0.640
2024-11-05 04:59 - INFO - 	 PR-AUC: 0.092
2024-11-05 04:59 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 04:59 - INFO - 	 Best Val. Loss: 0.205
2024-11-05 04:59 - INFO - 	 Best ROC-AUC: 0.640
2024-11-05 04:59 - INFO - 	 Best PR-AUC: 0.092
2024-11-05 04:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.588
2024-11-05 04:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 04:59 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-05 04:59 - INFO - ---------------------------------------------
2024-11-05 05:02 - INFO - Fit the preprocessing pipeline
2024-11-05 05:02 - INFO - Training using device: mps
2024-11-05 05:02 - INFO - Creating generators
2024-11-05 05:02 - INFO - The model has 651,257 trainable parameters
2024-11-05 05:02 - INFO - * Model:
2024-11-05 05:02 - INFO - * -----------
2024-11-05 05:02 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 05:02 - INFO - * -----------
2024-11-05 05:02 - INFO - Evaluating model based on: aucpr
2024-11-05 05:02 - INFO - Training..

2024-11-05 05:04 - INFO - ---------------------------------------------
2024-11-05 05:04 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 05:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05897
2024-11-05 05:04 - INFO - 	 Train Loss: 0.256
2024-11-05 05:04 - INFO - 	 Val. Loss: 0.315
2024-11-05 05:04 - INFO - 	 ROC-AUC: 0.545
2024-11-05 05:04 - INFO - 	 PR-AUC: 0.059
2024-11-05 05:04 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 05:04 - INFO - 	 Best Val. Loss: 0.315
2024-11-05 05:04 - INFO - 	 Best ROC-AUC: 0.545
2024-11-05 05:04 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 05:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 05:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 05:04 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 05:04 - INFO - ---------------------------------------------
2024-11-05 05:05 - INFO - ---------------------------------------------
2024-11-05 05:05 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 05:05 - INFO - 	 Train Loss: 0.211
2024-11-05 05:05 - INFO - 	 Val. Loss: 0.267
2024-11-05 05:05 - INFO - 	 ROC-AUC: 0.516
2024-11-05 05:05 - INFO - 	 PR-AUC: 0.047
2024-11-05 05:05 - INFO - 	 Recall for 0.4 precision: 0.172
2024-11-05 05:05 - INFO - 	 Best Val. Loss: 0.267
2024-11-05 05:05 - INFO - 	 Best ROC-AUC: 0.545
2024-11-05 05:05 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 05:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 05:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 05:05 - INFO - 	 Best Recall for 0.4 precision: 0.172
2024-11-05 05:05 - INFO - ---------------------------------------------
2024-11-05 05:07 - INFO - ---------------------------------------------
2024-11-05 05:07 - INFO - Epoch: 03 | Time: 1m 46s
2024-11-05 05:07 - INFO - 	 Train Loss: 0.198
2024-11-05 05:07 - INFO - 	 Val. Loss: 0.253
2024-11-05 05:07 - INFO - 	 ROC-AUC: 0.543
2024-11-05 05:07 - INFO - 	 PR-AUC: 0.050
2024-11-05 05:07 - INFO - 	 Recall for 0.4 precision: 0.187
2024-11-05 05:07 - INFO - 	 Best Val. Loss: 0.253
2024-11-05 05:07 - INFO - 	 Best ROC-AUC: 0.545
2024-11-05 05:07 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 05:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 05:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.063
2024-11-05 05:07 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:07 - INFO - ---------------------------------------------
2024-11-05 05:09 - INFO - ---------------------------------------------
2024-11-05 05:09 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 05:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06297
2024-11-05 05:09 - INFO - 	 Train Loss: 0.194
2024-11-05 05:09 - INFO - 	 Val. Loss: 0.242
2024-11-05 05:09 - INFO - 	 ROC-AUC: 0.542
2024-11-05 05:09 - INFO - 	 PR-AUC: 0.063
2024-11-05 05:09 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 05:09 - INFO - 	 Best Val. Loss: 0.242
2024-11-05 05:09 - INFO - 	 Best ROC-AUC: 0.545
2024-11-05 05:09 - INFO - 	 Best PR-AUC: 0.063
2024-11-05 05:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 05:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.066
2024-11-05 05:09 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:09 - INFO - ---------------------------------------------
2024-11-05 05:11 - INFO - ---------------------------------------------
2024-11-05 05:11 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 05:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.068
2024-11-05 05:11 - INFO - 	 Train Loss: 0.188
2024-11-05 05:11 - INFO - 	 Val. Loss: 0.233
2024-11-05 05:11 - INFO - 	 ROC-AUC: 0.607
2024-11-05 05:11 - INFO - 	 PR-AUC: 0.068
2024-11-05 05:11 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-05 05:11 - INFO - 	 Best Val. Loss: 0.233
2024-11-05 05:11 - INFO - 	 Best ROC-AUC: 0.607
2024-11-05 05:11 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 05:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.583
2024-11-05 05:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.074
2024-11-05 05:11 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:11 - INFO - ---------------------------------------------
2024-11-05 05:13 - INFO - ---------------------------------------------
2024-11-05 05:13 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 05:13 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06998
2024-11-05 05:13 - INFO - 	 Train Loss: 0.184
2024-11-05 05:13 - INFO - 	 Val. Loss: 0.219
2024-11-05 05:13 - INFO - 	 ROC-AUC: 0.615
2024-11-05 05:13 - INFO - 	 PR-AUC: 0.070
2024-11-05 05:13 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 05:13 - INFO - 	 Best Val. Loss: 0.219
2024-11-05 05:13 - INFO - 	 Best ROC-AUC: 0.615
2024-11-05 05:13 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 05:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.621
2024-11-05 05:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.076
2024-11-05 05:13 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:13 - INFO - ---------------------------------------------
2024-11-05 05:15 - INFO - ---------------------------------------------
2024-11-05 05:15 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 05:15 - INFO - 	 Train Loss: 0.183
2024-11-05 05:15 - INFO - 	 Val. Loss: 0.213
2024-11-05 05:15 - INFO - 	 ROC-AUC: 0.581
2024-11-05 05:15 - INFO - 	 PR-AUC: 0.063
2024-11-05 05:15 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 05:15 - INFO - 	 Best Val. Loss: 0.213
2024-11-05 05:15 - INFO - 	 Best ROC-AUC: 0.615
2024-11-05 05:15 - INFO - 	 Best PR-AUC: 0.070
2024-11-05 05:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.621
2024-11-05 05:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.076
2024-11-05 05:15 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:15 - INFO - ---------------------------------------------
2024-11-05 05:16 - INFO - ---------------------------------------------
2024-11-05 05:16 - INFO - Epoch: 08 | Time: 1m 51s
2024-11-05 05:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07786
2024-11-05 05:16 - INFO - 	 Train Loss: 0.179
2024-11-05 05:16 - INFO - 	 Val. Loss: 0.210
2024-11-05 05:16 - INFO - 	 ROC-AUC: 0.603
2024-11-05 05:16 - INFO - 	 PR-AUC: 0.078
2024-11-05 05:16 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 05:16 - INFO - 	 Best Val. Loss: 0.210
2024-11-05 05:16 - INFO - 	 Best ROC-AUC: 0.615
2024-11-05 05:16 - INFO - 	 Best PR-AUC: 0.078
2024-11-05 05:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.621
2024-11-05 05:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 05:16 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:16 - INFO - ---------------------------------------------
2024-11-05 05:18 - INFO - ---------------------------------------------
2024-11-05 05:18 - INFO - Epoch: 09 | Time: 1m 51s
2024-11-05 05:18 - INFO - 	 Train Loss: 0.179
2024-11-05 05:18 - INFO - 	 Val. Loss: 0.207
2024-11-05 05:18 - INFO - 	 ROC-AUC: 0.606
2024-11-05 05:18 - INFO - 	 PR-AUC: 0.071
2024-11-05 05:18 - INFO - 	 Recall for 0.4 precision: 0.028
2024-11-05 05:18 - INFO - 	 Best Val. Loss: 0.207
2024-11-05 05:18 - INFO - 	 Best ROC-AUC: 0.615
2024-11-05 05:18 - INFO - 	 Best PR-AUC: 0.078
2024-11-05 05:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.621
2024-11-05 05:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 05:18 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:18 - INFO - ---------------------------------------------
2024-11-05 05:20 - INFO - ---------------------------------------------
2024-11-05 05:20 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 05:20 - INFO - 	 Train Loss: 0.177
2024-11-05 05:20 - INFO - 	 Val. Loss: 0.200
2024-11-05 05:20 - INFO - 	 ROC-AUC: 0.638
2024-11-05 05:20 - INFO - 	 PR-AUC: 0.078
2024-11-05 05:20 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 05:20 - INFO - 	 Best Val. Loss: 0.200
2024-11-05 05:20 - INFO - 	 Best ROC-AUC: 0.638
2024-11-05 05:20 - INFO - 	 Best PR-AUC: 0.078
2024-11-05 05:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.593
2024-11-05 05:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 05:20 - INFO - 	 Best Recall for 0.4 precision: 0.187
2024-11-05 05:20 - INFO - ---------------------------------------------
2024-11-05 05:23 - INFO - Fit the preprocessing pipeline
2024-11-05 05:23 - INFO - Training using device: mps
2024-11-05 05:23 - INFO - Creating generators
2024-11-05 05:23 - INFO - The model has 651,257 trainable parameters
2024-11-05 05:23 - INFO - * Model:
2024-11-05 05:23 - INFO - * -----------
2024-11-05 05:23 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 05:23 - INFO - * -----------
2024-11-05 05:23 - INFO - Evaluating model based on: aucpr
2024-11-05 05:23 - INFO - Training..

2024-11-05 05:24 - INFO - ---------------------------------------------
2024-11-05 05:24 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 05:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05968
2024-11-05 05:24 - INFO - 	 Train Loss: 0.251
2024-11-05 05:24 - INFO - 	 Val. Loss: 0.288
2024-11-05 05:24 - INFO - 	 ROC-AUC: 0.527
2024-11-05 05:24 - INFO - 	 PR-AUC: 0.060
2024-11-05 05:24 - INFO - 	 Recall for 0.4 precision: 0.013
2024-11-05 05:24 - INFO - 	 Best Val. Loss: 0.288
2024-11-05 05:24 - INFO - 	 Best ROC-AUC: 0.527
2024-11-05 05:24 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 05:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.536
2024-11-05 05:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.053
2024-11-05 05:24 - INFO - 	 Best Recall for 0.4 precision: 0.013
2024-11-05 05:24 - INFO - ---------------------------------------------
2024-11-05 05:26 - INFO - ---------------------------------------------
2024-11-05 05:26 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 05:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.114
2024-11-05 05:26 - INFO - 	 Train Loss: 0.206
2024-11-05 05:26 - INFO - 	 Val. Loss: 0.265
2024-11-05 05:26 - INFO - 	 ROC-AUC: 0.621
2024-11-05 05:26 - INFO - 	 PR-AUC: 0.114
2024-11-05 05:26 - INFO - 	 Recall for 0.4 precision: 0.049
2024-11-05 05:26 - INFO - 	 Best Val. Loss: 0.265
2024-11-05 05:26 - INFO - 	 Best ROC-AUC: 0.621
2024-11-05 05:26 - INFO - 	 Best PR-AUC: 0.114
2024-11-05 05:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.624
2024-11-05 05:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.078
2024-11-05 05:26 - INFO - 	 Best Recall for 0.4 precision: 0.049
2024-11-05 05:26 - INFO - ---------------------------------------------
2024-11-05 05:28 - INFO - ---------------------------------------------
2024-11-05 05:28 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 05:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14311
2024-11-05 05:28 - INFO - 	 Train Loss: 0.187
2024-11-05 05:28 - INFO - 	 Val. Loss: 0.220
2024-11-05 05:28 - INFO - 	 ROC-AUC: 0.710
2024-11-05 05:28 - INFO - 	 PR-AUC: 0.143
2024-11-05 05:28 - INFO - 	 Recall for 0.4 precision: 0.020
2024-11-05 05:28 - INFO - 	 Best Val. Loss: 0.220
2024-11-05 05:28 - INFO - 	 Best ROC-AUC: 0.710
2024-11-05 05:28 - INFO - 	 Best PR-AUC: 0.143
2024-11-05 05:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.697
2024-11-05 05:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.111
2024-11-05 05:28 - INFO - 	 Best Recall for 0.4 precision: 0.049
2024-11-05 05:28 - INFO - ---------------------------------------------
2024-11-05 05:30 - INFO - ---------------------------------------------
2024-11-05 05:30 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 05:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.19331
2024-11-05 05:30 - INFO - 	 Train Loss: 0.176
2024-11-05 05:30 - INFO - 	 Val. Loss: 0.209
2024-11-05 05:30 - INFO - 	 ROC-AUC: 0.775
2024-11-05 05:30 - INFO - 	 PR-AUC: 0.193
2024-11-05 05:30 - INFO - 	 Recall for 0.4 precision: 0.033
2024-11-05 05:30 - INFO - 	 Best Val. Loss: 0.209
2024-11-05 05:30 - INFO - 	 Best ROC-AUC: 0.775
2024-11-05 05:30 - INFO - 	 Best PR-AUC: 0.193
2024-11-05 05:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-11-05 05:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.128
2024-11-05 05:30 - INFO - 	 Best Recall for 0.4 precision: 0.049
2024-11-05 05:30 - INFO - ---------------------------------------------
2024-11-05 05:32 - INFO - ---------------------------------------------
2024-11-05 05:32 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 05:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30196
2024-11-05 05:32 - INFO - 	 Train Loss: 0.162
2024-11-05 05:32 - INFO - 	 Val. Loss: 0.176
2024-11-05 05:32 - INFO - 	 ROC-AUC: 0.883
2024-11-05 05:32 - INFO - 	 PR-AUC: 0.302
2024-11-05 05:32 - INFO - 	 Recall for 0.4 precision: 0.247
2024-11-05 05:32 - INFO - 	 Best Val. Loss: 0.176
2024-11-05 05:32 - INFO - 	 Best ROC-AUC: 0.883
2024-11-05 05:32 - INFO - 	 Best PR-AUC: 0.302
2024-11-05 05:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.843
2024-11-05 05:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.215
2024-11-05 05:32 - INFO - 	 Best Recall for 0.4 precision: 0.247
2024-11-05 05:32 - INFO - ---------------------------------------------
2024-11-05 05:33 - INFO - ---------------------------------------------
2024-11-05 05:33 - INFO - Epoch: 06 | Time: 1m 49s
2024-11-05 05:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.42083
2024-11-05 05:33 - INFO - 	 Train Loss: 0.142
2024-11-05 05:33 - INFO - 	 Val. Loss: 0.147
2024-11-05 05:33 - INFO - 	 ROC-AUC: 0.947
2024-11-05 05:33 - INFO - 	 PR-AUC: 0.421
2024-11-05 05:33 - INFO - 	 Recall for 0.4 precision: 0.676
2024-11-05 05:33 - INFO - 	 Best Val. Loss: 0.147
2024-11-05 05:33 - INFO - 	 Best ROC-AUC: 0.947
2024-11-05 05:33 - INFO - 	 Best PR-AUC: 0.421
2024-11-05 05:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.925
2024-11-05 05:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.319
2024-11-05 05:33 - INFO - 	 Best Recall for 0.4 precision: 0.676
2024-11-05 05:33 - INFO - ---------------------------------------------
2024-11-05 05:35 - INFO - ---------------------------------------------
2024-11-05 05:35 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 05:35 - INFO - 	 Train Loss: 0.129
2024-11-05 05:35 - INFO - 	 Val. Loss: 0.138
2024-11-05 05:35 - INFO - 	 ROC-AUC: 0.938
2024-11-05 05:35 - INFO - 	 PR-AUC: 0.380
2024-11-05 05:35 - INFO - 	 Recall for 0.4 precision: 0.527
2024-11-05 05:35 - INFO - 	 Best Val. Loss: 0.138
2024-11-05 05:35 - INFO - 	 Best ROC-AUC: 0.947
2024-11-05 05:35 - INFO - 	 Best PR-AUC: 0.421
2024-11-05 05:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.925
2024-11-05 05:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.319
2024-11-05 05:35 - INFO - 	 Best Recall for 0.4 precision: 0.676
2024-11-05 05:35 - INFO - ---------------------------------------------
2024-11-05 05:37 - INFO - ---------------------------------------------
2024-11-05 05:37 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 05:37 - INFO - 	 Train Loss: 0.124
2024-11-05 05:37 - INFO - 	 Val. Loss: 0.160
2024-11-05 05:37 - INFO - 	 ROC-AUC: 0.914
2024-11-05 05:37 - INFO - 	 PR-AUC: 0.334
2024-11-05 05:37 - INFO - 	 Recall for 0.4 precision: 0.348
2024-11-05 05:37 - INFO - 	 Best Val. Loss: 0.138
2024-11-05 05:37 - INFO - 	 Best ROC-AUC: 0.947
2024-11-05 05:37 - INFO - 	 Best PR-AUC: 0.421
2024-11-05 05:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.925
2024-11-05 05:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.319
2024-11-05 05:37 - INFO - 	 Best Recall for 0.4 precision: 0.676
2024-11-05 05:37 - INFO - ---------------------------------------------
2024-11-05 05:39 - INFO - ---------------------------------------------
2024-11-05 05:39 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 05:39 - INFO - 	 Train Loss: 0.119
2024-11-05 05:39 - INFO - 	 Val. Loss: 0.143
2024-11-05 05:39 - INFO - 	 ROC-AUC: 0.923
2024-11-05 05:39 - INFO - 	 PR-AUC: 0.410
2024-11-05 05:39 - INFO - 	 Recall for 0.4 precision: 0.598
2024-11-05 05:39 - INFO - 	 Best Val. Loss: 0.138
2024-11-05 05:39 - INFO - 	 Best ROC-AUC: 0.947
2024-11-05 05:39 - INFO - 	 Best PR-AUC: 0.421
2024-11-05 05:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.925
2024-11-05 05:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.319
2024-11-05 05:39 - INFO - 	 Best Recall for 0.4 precision: 0.676
2024-11-05 05:39 - INFO - ---------------------------------------------
2024-11-05 05:43 - INFO - Fit the preprocessing pipeline
2024-11-05 05:43 - INFO - Training using device: mps
2024-11-05 05:43 - INFO - Creating generators
2024-11-05 05:43 - INFO - The model has 651,257 trainable parameters
2024-11-05 05:43 - INFO - * Model:
2024-11-05 05:43 - INFO - * -----------
2024-11-05 05:43 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 05:43 - INFO - * -----------
2024-11-05 05:43 - INFO - Evaluating model based on: aucpr
2024-11-05 05:43 - INFO - Training..

2024-11-05 05:45 - INFO - ---------------------------------------------
2024-11-05 05:45 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 05:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06203
2024-11-05 05:45 - INFO - 	 Train Loss: 0.257
2024-11-05 05:45 - INFO - 	 Val. Loss: 0.310
2024-11-05 05:45 - INFO - 	 ROC-AUC: 0.551
2024-11-05 05:45 - INFO - 	 PR-AUC: 0.062
2024-11-05 05:45 - INFO - 	 Recall for 0.4 precision: 0.015
2024-11-05 05:45 - INFO - 	 Best Val. Loss: 0.310
2024-11-05 05:45 - INFO - 	 Best ROC-AUC: 0.551
2024-11-05 05:45 - INFO - 	 Best PR-AUC: 0.062
2024-11-05 05:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.539
2024-11-05 05:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 05:45 - INFO - 	 Best Recall for 0.4 precision: 0.015
2024-11-05 05:45 - INFO - ---------------------------------------------
2024-11-05 05:47 - INFO - ---------------------------------------------
2024-11-05 05:47 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 05:47 - INFO - 	 Train Loss: 0.213
2024-11-05 05:47 - INFO - 	 Val. Loss: 0.285
2024-11-05 05:47 - INFO - 	 ROC-AUC: 0.490
2024-11-05 05:47 - INFO - 	 PR-AUC: 0.046
2024-11-05 05:47 - INFO - 	 Recall for 0.4 precision: 0.018
2024-11-05 05:47 - INFO - 	 Best Val. Loss: 0.285
2024-11-05 05:47 - INFO - 	 Best ROC-AUC: 0.551
2024-11-05 05:47 - INFO - 	 Best PR-AUC: 0.062
2024-11-05 05:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.539
2024-11-05 05:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 05:47 - INFO - 	 Best Recall for 0.4 precision: 0.018
2024-11-05 05:47 - INFO - ---------------------------------------------
2024-11-05 05:49 - INFO - ---------------------------------------------
2024-11-05 05:49 - INFO - Epoch: 03 | Time: 1m 46s
2024-11-05 05:49 - INFO - 	 Train Loss: 0.200
2024-11-05 05:49 - INFO - 	 Val. Loss: 0.263
2024-11-05 05:49 - INFO - 	 ROC-AUC: 0.556
2024-11-05 05:49 - INFO - 	 PR-AUC: 0.054
2024-11-05 05:49 - INFO - 	 Recall for 0.4 precision: 0.263
2024-11-05 05:49 - INFO - 	 Best Val. Loss: 0.263
2024-11-05 05:49 - INFO - 	 Best ROC-AUC: 0.556
2024-11-05 05:49 - INFO - 	 Best PR-AUC: 0.062
2024-11-05 05:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.552
2024-11-05 05:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 05:49 - INFO - 	 Best Recall for 0.4 precision: 0.263
2024-11-05 05:49 - INFO - ---------------------------------------------
2024-11-05 05:50 - INFO - ---------------------------------------------
2024-11-05 05:50 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 05:50 - INFO - 	 Train Loss: 0.195
2024-11-05 05:50 - INFO - 	 Val. Loss: 0.243
2024-11-05 05:50 - INFO - 	 ROC-AUC: 0.582
2024-11-05 05:50 - INFO - 	 PR-AUC: 0.059
2024-11-05 05:50 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 05:50 - INFO - 	 Best Val. Loss: 0.243
2024-11-05 05:50 - INFO - 	 Best ROC-AUC: 0.582
2024-11-05 05:50 - INFO - 	 Best PR-AUC: 0.062
2024-11-05 05:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.557
2024-11-05 05:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.057
2024-11-05 05:50 - INFO - 	 Best Recall for 0.4 precision: 0.263
2024-11-05 05:50 - INFO - ---------------------------------------------
2024-11-05 05:55 - INFO - Fit the preprocessing pipeline
2024-11-05 05:55 - INFO - Training using device: mps
2024-11-05 05:55 - INFO - Creating generators
2024-11-05 05:55 - INFO - The model has 651,257 trainable parameters
2024-11-05 05:55 - INFO - * Model:
2024-11-05 05:55 - INFO - * -----------
2024-11-05 05:55 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 05:55 - INFO - * -----------
2024-11-05 05:55 - INFO - Evaluating model based on: aucpr
2024-11-05 05:55 - INFO - Training..

2024-11-05 05:57 - INFO - ---------------------------------------------
2024-11-05 05:57 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 05:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05175
2024-11-05 05:57 - INFO - 	 Train Loss: 0.259
2024-11-05 05:57 - INFO - 	 Val. Loss: 0.335
2024-11-05 05:57 - INFO - 	 ROC-AUC: 0.534
2024-11-05 05:57 - INFO - 	 PR-AUC: 0.052
2024-11-05 05:57 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 05:57 - INFO - 	 Best Val. Loss: 0.335
2024-11-05 05:57 - INFO - 	 Best ROC-AUC: 0.534
2024-11-05 05:57 - INFO - 	 Best PR-AUC: 0.052
2024-11-05 05:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.488
2024-11-05 05:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.046
2024-11-05 05:57 - INFO - 	 Best Recall for 0.4 precision: 0.002
2024-11-05 05:57 - INFO - ---------------------------------------------
2024-11-05 05:58 - INFO - ---------------------------------------------
2024-11-05 05:58 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 05:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.0565
2024-11-05 05:58 - INFO - 	 Train Loss: 0.214
2024-11-05 05:58 - INFO - 	 Val. Loss: 0.276
2024-11-05 05:58 - INFO - 	 ROC-AUC: 0.562
2024-11-05 05:58 - INFO - 	 PR-AUC: 0.057
2024-11-05 05:58 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 05:58 - INFO - 	 Best Val. Loss: 0.276
2024-11-05 05:58 - INFO - 	 Best ROC-AUC: 0.562
2024-11-05 05:58 - INFO - 	 Best PR-AUC: 0.057
2024-11-05 05:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.551
2024-11-05 05:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.062
2024-11-05 05:58 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 05:58 - INFO - ---------------------------------------------
2024-11-05 06:00 - INFO - ---------------------------------------------
2024-11-05 06:00 - INFO - Epoch: 03 | Time: 1m 46s
2024-11-05 06:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07071
2024-11-05 06:00 - INFO - 	 Train Loss: 0.203
2024-11-05 06:00 - INFO - 	 Val. Loss: 0.266
2024-11-05 06:00 - INFO - 	 ROC-AUC: 0.599
2024-11-05 06:00 - INFO - 	 PR-AUC: 0.071
2024-11-05 06:00 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 06:00 - INFO - 	 Best Val. Loss: 0.266
2024-11-05 06:00 - INFO - 	 Best ROC-AUC: 0.599
2024-11-05 06:00 - INFO - 	 Best PR-AUC: 0.071
2024-11-05 06:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.592
2024-11-05 06:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.067
2024-11-05 06:00 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 06:00 - INFO - ---------------------------------------------
2024-11-05 06:02 - INFO - ---------------------------------------------
2024-11-05 06:02 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 06:02 - INFO - 	 Train Loss: 0.194
2024-11-05 06:02 - INFO - 	 Val. Loss: 0.273
2024-11-05 06:02 - INFO - 	 ROC-AUC: 0.595
2024-11-05 06:02 - INFO - 	 PR-AUC: 0.064
2024-11-05 06:02 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 06:02 - INFO - 	 Best Val. Loss: 0.266
2024-11-05 06:02 - INFO - 	 Best ROC-AUC: 0.599
2024-11-05 06:02 - INFO - 	 Best PR-AUC: 0.071
2024-11-05 06:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.592
2024-11-05 06:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.067
2024-11-05 06:02 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 06:02 - INFO - ---------------------------------------------
2024-11-05 06:04 - INFO - ---------------------------------------------
2024-11-05 06:04 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 06:04 - INFO - 	 Train Loss: 0.192
2024-11-05 06:04 - INFO - 	 Val. Loss: 0.238
2024-11-05 06:04 - INFO - 	 ROC-AUC: 0.586
2024-11-05 06:04 - INFO - 	 PR-AUC: 0.068
2024-11-05 06:04 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 06:04 - INFO - 	 Best Val. Loss: 0.238
2024-11-05 06:04 - INFO - 	 Best ROC-AUC: 0.599
2024-11-05 06:04 - INFO - 	 Best PR-AUC: 0.071
2024-11-05 06:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.592
2024-11-05 06:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.067
2024-11-05 06:04 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 06:04 - INFO - ---------------------------------------------
2024-11-05 06:06 - INFO - ---------------------------------------------
2024-11-05 06:06 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 06:06 - INFO - 	 Train Loss: 0.187
2024-11-05 06:06 - INFO - 	 Val. Loss: 0.222
2024-11-05 06:06 - INFO - 	 ROC-AUC: 0.579
2024-11-05 06:06 - INFO - 	 PR-AUC: 0.067
2024-11-05 06:06 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 06:06 - INFO - 	 Best Val. Loss: 0.222
2024-11-05 06:06 - INFO - 	 Best ROC-AUC: 0.599
2024-11-05 06:06 - INFO - 	 Best PR-AUC: 0.071
2024-11-05 06:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.592
2024-11-05 06:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.067
2024-11-05 06:06 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 06:06 - INFO - ---------------------------------------------
2024-11-05 06:10 - INFO - Fit the preprocessing pipeline
2024-11-05 06:10 - INFO - Training using device: mps
2024-11-05 06:10 - INFO - Creating generators
2024-11-05 06:10 - INFO - The model has 651,257 trainable parameters
2024-11-05 06:10 - INFO - * Model:
2024-11-05 06:10 - INFO - * -----------
2024-11-05 06:10 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 06:10 - INFO - * -----------
2024-11-05 06:10 - INFO - Evaluating model based on: aucpr
2024-11-05 06:10 - INFO - Training..

2024-11-05 06:12 - INFO - ---------------------------------------------
2024-11-05 06:12 - INFO - Epoch: 01 | Time: 1m 42s
2024-11-05 06:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07883
2024-11-05 06:12 - INFO - 	 Train Loss: 0.253
2024-11-05 06:12 - INFO - 	 Val. Loss: 0.320
2024-11-05 06:12 - INFO - 	 ROC-AUC: 0.578
2024-11-05 06:12 - INFO - 	 PR-AUC: 0.079
2024-11-05 06:12 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 06:12 - INFO - 	 Best Val. Loss: 0.320
2024-11-05 06:12 - INFO - 	 Best ROC-AUC: 0.578
2024-11-05 06:12 - INFO - 	 Best PR-AUC: 0.079
2024-11-05 06:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.577
2024-11-05 06:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.079
2024-11-05 06:12 - INFO - 	 Best Recall for 0.4 precision: 0.003
2024-11-05 06:12 - INFO - ---------------------------------------------
2024-11-05 06:13 - INFO - ---------------------------------------------
2024-11-05 06:13 - INFO - Epoch: 02 | Time: 1m 43s
2024-11-05 06:13 - INFO - 	 Train Loss: 0.208
2024-11-05 06:13 - INFO - 	 Val. Loss: 0.280
2024-11-05 06:13 - INFO - 	 ROC-AUC: 0.560
2024-11-05 06:13 - INFO - 	 PR-AUC: 0.067
2024-11-05 06:13 - INFO - 	 Recall for 0.4 precision: 0.034
2024-11-05 06:13 - INFO - 	 Best Val. Loss: 0.280
2024-11-05 06:13 - INFO - 	 Best ROC-AUC: 0.578
2024-11-05 06:13 - INFO - 	 Best PR-AUC: 0.079
2024-11-05 06:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.577
2024-11-05 06:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.079
2024-11-05 06:13 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:13 - INFO - ---------------------------------------------
2024-11-05 06:15 - INFO - ---------------------------------------------
2024-11-05 06:15 - INFO - Epoch: 03 | Time: 1m 48s
2024-11-05 06:15 - INFO - 	 Train Loss: 0.198
2024-11-05 06:15 - INFO - 	 Val. Loss: 0.282
2024-11-05 06:15 - INFO - 	 ROC-AUC: 0.517
2024-11-05 06:15 - INFO - 	 PR-AUC: 0.061
2024-11-05 06:15 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 06:15 - INFO - 	 Best Val. Loss: 0.280
2024-11-05 06:15 - INFO - 	 Best ROC-AUC: 0.578
2024-11-05 06:15 - INFO - 	 Best PR-AUC: 0.079
2024-11-05 06:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.577
2024-11-05 06:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.079
2024-11-05 06:15 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:15 - INFO - ---------------------------------------------
2024-11-05 06:17 - INFO - ---------------------------------------------
2024-11-05 06:17 - INFO - Epoch: 04 | Time: 1m 50s
2024-11-05 06:17 - INFO - 	 Train Loss: 0.193
2024-11-05 06:17 - INFO - 	 Val. Loss: 0.244
2024-11-05 06:17 - INFO - 	 ROC-AUC: 0.595
2024-11-05 06:17 - INFO - 	 PR-AUC: 0.071
2024-11-05 06:17 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 06:17 - INFO - 	 Best Val. Loss: 0.244
2024-11-05 06:17 - INFO - 	 Best ROC-AUC: 0.595
2024-11-05 06:17 - INFO - 	 Best PR-AUC: 0.079
2024-11-05 06:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.563
2024-11-05 06:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.079
2024-11-05 06:17 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:17 - INFO - ---------------------------------------------
2024-11-05 06:19 - INFO - ---------------------------------------------
2024-11-05 06:19 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-05 06:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.10962
2024-11-05 06:19 - INFO - 	 Train Loss: 0.184
2024-11-05 06:19 - INFO - 	 Val. Loss: 0.213
2024-11-05 06:19 - INFO - 	 ROC-AUC: 0.662
2024-11-05 06:19 - INFO - 	 PR-AUC: 0.110
2024-11-05 06:19 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 06:19 - INFO - 	 Best Val. Loss: 0.213
2024-11-05 06:19 - INFO - 	 Best ROC-AUC: 0.662
2024-11-05 06:19 - INFO - 	 Best PR-AUC: 0.110
2024-11-05 06:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.646
2024-11-05 06:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.095
2024-11-05 06:19 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:19 - INFO - ---------------------------------------------
2024-11-05 06:21 - INFO - ---------------------------------------------
2024-11-05 06:21 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 06:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.19823
2024-11-05 06:21 - INFO - 	 Train Loss: 0.178
2024-11-05 06:21 - INFO - 	 Val. Loss: 0.196
2024-11-05 06:21 - INFO - 	 ROC-AUC: 0.748
2024-11-05 06:21 - INFO - 	 PR-AUC: 0.198
2024-11-05 06:21 - INFO - 	 Recall for 0.4 precision: 0.137
2024-11-05 06:21 - INFO - 	 Best Val. Loss: 0.196
2024-11-05 06:21 - INFO - 	 Best ROC-AUC: 0.748
2024-11-05 06:21 - INFO - 	 Best PR-AUC: 0.198
2024-11-05 06:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.686
2024-11-05 06:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.103
2024-11-05 06:21 - INFO - 	 Best Recall for 0.4 precision: 0.137
2024-11-05 06:21 - INFO - ---------------------------------------------
2024-11-05 06:23 - INFO - ---------------------------------------------
2024-11-05 06:23 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 06:23 - INFO - 	 New best val_rocauc loss was found, current best value is 0.24111
2024-11-05 06:23 - INFO - 	 Train Loss: 0.168
2024-11-05 06:23 - INFO - 	 Val. Loss: 0.181
2024-11-05 06:23 - INFO - 	 ROC-AUC: 0.781
2024-11-05 06:23 - INFO - 	 PR-AUC: 0.241
2024-11-05 06:23 - INFO - 	 Recall for 0.4 precision: 0.172
2024-11-05 06:23 - INFO - 	 Best Val. Loss: 0.181
2024-11-05 06:23 - INFO - 	 Best ROC-AUC: 0.781
2024-11-05 06:23 - INFO - 	 Best PR-AUC: 0.241
2024-11-05 06:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.714
2024-11-05 06:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.135
2024-11-05 06:23 - INFO - 	 Best Recall for 0.4 precision: 0.172
2024-11-05 06:23 - INFO - ---------------------------------------------
2024-11-05 06:25 - INFO - ---------------------------------------------
2024-11-05 06:25 - INFO - Epoch: 08 | Time: 1m 51s
2024-11-05 06:25 - INFO - 	 New best val_rocauc loss was found, current best value is 0.33002
2024-11-05 06:25 - INFO - 	 Train Loss: 0.156
2024-11-05 06:25 - INFO - 	 Val. Loss: 0.158
2024-11-05 06:25 - INFO - 	 ROC-AUC: 0.907
2024-11-05 06:25 - INFO - 	 PR-AUC: 0.330
2024-11-05 06:25 - INFO - 	 Recall for 0.4 precision: 0.374
2024-11-05 06:25 - INFO - 	 Best Val. Loss: 0.158
2024-11-05 06:25 - INFO - 	 Best ROC-AUC: 0.907
2024-11-05 06:25 - INFO - 	 Best PR-AUC: 0.330
2024-11-05 06:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.877
2024-11-05 06:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.240
2024-11-05 06:25 - INFO - 	 Best Recall for 0.4 precision: 0.374
2024-11-05 06:25 - INFO - ---------------------------------------------
2024-11-05 06:26 - INFO - ---------------------------------------------
2024-11-05 06:26 - INFO - Epoch: 09 | Time: 1m 51s
2024-11-05 06:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.34433
2024-11-05 06:26 - INFO - 	 Train Loss: 0.137
2024-11-05 06:26 - INFO - 	 Val. Loss: 0.143
2024-11-05 06:26 - INFO - 	 ROC-AUC: 0.923
2024-11-05 06:26 - INFO - 	 PR-AUC: 0.344
2024-11-05 06:26 - INFO - 	 Recall for 0.4 precision: 0.382
2024-11-05 06:26 - INFO - 	 Best Val. Loss: 0.143
2024-11-05 06:26 - INFO - 	 Best ROC-AUC: 0.923
2024-11-05 06:26 - INFO - 	 Best PR-AUC: 0.344
2024-11-05 06:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.895
2024-11-05 06:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.276
2024-11-05 06:26 - INFO - 	 Best Recall for 0.4 precision: 0.382
2024-11-05 06:26 - INFO - ---------------------------------------------
2024-11-05 06:28 - INFO - ---------------------------------------------
2024-11-05 06:28 - INFO - Epoch: 10 | Time: 1m 51s
2024-11-05 06:28 - INFO - 	 Train Loss: 0.128
2024-11-05 06:28 - INFO - 	 Val. Loss: 0.147
2024-11-05 06:28 - INFO - 	 ROC-AUC: 0.925
2024-11-05 06:28 - INFO - 	 PR-AUC: 0.329
2024-11-05 06:28 - INFO - 	 Recall for 0.4 precision: 0.309
2024-11-05 06:28 - INFO - 	 Best Val. Loss: 0.143
2024-11-05 06:28 - INFO - 	 Best ROC-AUC: 0.925
2024-11-05 06:28 - INFO - 	 Best PR-AUC: 0.344
2024-11-05 06:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.912
2024-11-05 06:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.276
2024-11-05 06:28 - INFO - 	 Best Recall for 0.4 precision: 0.382
2024-11-05 06:28 - INFO - ---------------------------------------------
2024-11-05 06:31 - INFO - Fit the preprocessing pipeline
2024-11-05 06:31 - INFO - Training using device: mps
2024-11-05 06:31 - INFO - Creating generators
2024-11-05 06:31 - INFO - The model has 651,257 trainable parameters
2024-11-05 06:31 - INFO - * Model:
2024-11-05 06:31 - INFO - * -----------
2024-11-05 06:31 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 06:31 - INFO - * -----------
2024-11-05 06:31 - INFO - Evaluating model based on: aucpr
2024-11-05 06:31 - INFO - Training..

2024-11-05 06:33 - INFO - ---------------------------------------------
2024-11-05 06:33 - INFO - Epoch: 01 | Time: 1m 41s
2024-11-05 06:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05299
2024-11-05 06:33 - INFO - 	 Train Loss: 0.252
2024-11-05 06:33 - INFO - 	 Val. Loss: 0.320
2024-11-05 06:33 - INFO - 	 ROC-AUC: 0.566
2024-11-05 06:33 - INFO - 	 PR-AUC: 0.053
2024-11-05 06:33 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 06:33 - INFO - 	 Best Val. Loss: 0.320
2024-11-05 06:33 - INFO - 	 Best ROC-AUC: 0.566
2024-11-05 06:33 - INFO - 	 Best PR-AUC: 0.053
2024-11-05 06:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.558
2024-11-05 06:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.052
2024-11-05 06:33 - INFO - 	 Best Recall for 0.4 precision: 0.002
2024-11-05 06:33 - INFO - ---------------------------------------------
2024-11-05 06:34 - INFO - ---------------------------------------------
2024-11-05 06:34 - INFO - Epoch: 02 | Time: 1m 42s
2024-11-05 06:34 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05958
2024-11-05 06:34 - INFO - 	 Train Loss: 0.218
2024-11-05 06:34 - INFO - 	 Val. Loss: 0.280
2024-11-05 06:34 - INFO - 	 ROC-AUC: 0.568
2024-11-05 06:34 - INFO - 	 PR-AUC: 0.060
2024-11-05 06:34 - INFO - 	 Recall for 0.4 precision: 0.034
2024-11-05 06:34 - INFO - 	 Best Val. Loss: 0.280
2024-11-05 06:34 - INFO - 	 Best ROC-AUC: 0.568
2024-11-05 06:34 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 06:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.553
2024-11-05 06:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.059
2024-11-05 06:34 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:34 - INFO - ---------------------------------------------
2024-11-05 06:36 - INFO - ---------------------------------------------
2024-11-05 06:36 - INFO - Epoch: 03 | Time: 1m 45s
2024-11-05 06:36 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06133
2024-11-05 06:36 - INFO - 	 Train Loss: 0.204
2024-11-05 06:36 - INFO - 	 Val. Loss: 0.268
2024-11-05 06:36 - INFO - 	 ROC-AUC: 0.562
2024-11-05 06:36 - INFO - 	 PR-AUC: 0.061
2024-11-05 06:36 - INFO - 	 Recall for 0.4 precision: 0.015
2024-11-05 06:36 - INFO - 	 Best Val. Loss: 0.268
2024-11-05 06:36 - INFO - 	 Best ROC-AUC: 0.568
2024-11-05 06:36 - INFO - 	 Best PR-AUC: 0.061
2024-11-05 06:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.553
2024-11-05 06:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.066
2024-11-05 06:36 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:36 - INFO - ---------------------------------------------
2024-11-05 06:38 - INFO - ---------------------------------------------
2024-11-05 06:38 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 06:38 - INFO - 	 Train Loss: 0.201
2024-11-05 06:38 - INFO - 	 Val. Loss: 0.252
2024-11-05 06:38 - INFO - 	 ROC-AUC: 0.571
2024-11-05 06:38 - INFO - 	 PR-AUC: 0.061
2024-11-05 06:38 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 06:38 - INFO - 	 Best Val. Loss: 0.252
2024-11-05 06:38 - INFO - 	 Best ROC-AUC: 0.571
2024-11-05 06:38 - INFO - 	 Best PR-AUC: 0.061
2024-11-05 06:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.535
2024-11-05 06:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.066
2024-11-05 06:38 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:38 - INFO - ---------------------------------------------
2024-11-05 06:40 - INFO - ---------------------------------------------
2024-11-05 06:40 - INFO - Epoch: 05 | Time: 1m 49s
2024-11-05 06:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.08032
2024-11-05 06:40 - INFO - 	 Train Loss: 0.192
2024-11-05 06:40 - INFO - 	 Val. Loss: 0.238
2024-11-05 06:40 - INFO - 	 ROC-AUC: 0.629
2024-11-05 06:40 - INFO - 	 PR-AUC: 0.080
2024-11-05 06:40 - INFO - 	 Recall for 0.4 precision: 0.008
2024-11-05 06:40 - INFO - 	 Best Val. Loss: 0.238
2024-11-05 06:40 - INFO - 	 Best ROC-AUC: 0.629
2024-11-05 06:40 - INFO - 	 Best PR-AUC: 0.080
2024-11-05 06:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.584
2024-11-05 06:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.071
2024-11-05 06:40 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:40 - INFO - ---------------------------------------------
2024-11-05 06:42 - INFO - ---------------------------------------------
2024-11-05 06:42 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 06:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.10904
2024-11-05 06:42 - INFO - 	 Train Loss: 0.184
2024-11-05 06:42 - INFO - 	 Val. Loss: 0.218
2024-11-05 06:42 - INFO - 	 ROC-AUC: 0.699
2024-11-05 06:42 - INFO - 	 PR-AUC: 0.109
2024-11-05 06:42 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-05 06:42 - INFO - 	 Best Val. Loss: 0.218
2024-11-05 06:42 - INFO - 	 Best ROC-AUC: 0.699
2024-11-05 06:42 - INFO - 	 Best PR-AUC: 0.109
2024-11-05 06:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.653
2024-11-05 06:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.084
2024-11-05 06:42 - INFO - 	 Best Recall for 0.4 precision: 0.034
2024-11-05 06:42 - INFO - ---------------------------------------------
2024-11-05 06:43 - INFO - ---------------------------------------------
2024-11-05 06:43 - INFO - Epoch: 07 | Time: 1m 51s
2024-11-05 06:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14008
2024-11-05 06:43 - INFO - 	 Train Loss: 0.178
2024-11-05 06:43 - INFO - 	 Val. Loss: 0.210
2024-11-05 06:43 - INFO - 	 ROC-AUC: 0.656
2024-11-05 06:43 - INFO - 	 PR-AUC: 0.140
2024-11-05 06:43 - INFO - 	 Recall for 0.4 precision: 0.085
2024-11-05 06:43 - INFO - 	 Best Val. Loss: 0.210
2024-11-05 06:43 - INFO - 	 Best ROC-AUC: 0.699
2024-11-05 06:43 - INFO - 	 Best PR-AUC: 0.140
2024-11-05 06:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.653
2024-11-05 06:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.097
2024-11-05 06:43 - INFO - 	 Best Recall for 0.4 precision: 0.085
2024-11-05 06:43 - INFO - ---------------------------------------------
2024-11-05 06:45 - INFO - ---------------------------------------------
2024-11-05 06:45 - INFO - Epoch: 08 | Time: 1m 52s
2024-11-05 06:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.16465
2024-11-05 06:45 - INFO - 	 Train Loss: 0.173
2024-11-05 06:45 - INFO - 	 Val. Loss: 0.201
2024-11-05 06:45 - INFO - 	 ROC-AUC: 0.703
2024-11-05 06:45 - INFO - 	 PR-AUC: 0.165
2024-11-05 06:45 - INFO - 	 Recall for 0.4 precision: 0.091
2024-11-05 06:45 - INFO - 	 Best Val. Loss: 0.201
2024-11-05 06:45 - INFO - 	 Best ROC-AUC: 0.703
2024-11-05 06:45 - INFO - 	 Best PR-AUC: 0.165
2024-11-05 06:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.641
2024-11-05 06:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.096
2024-11-05 06:45 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-05 06:45 - INFO - ---------------------------------------------
2024-11-05 06:47 - INFO - ---------------------------------------------
2024-11-05 06:47 - INFO - Epoch: 09 | Time: 1m 52s
2024-11-05 06:47 - INFO - 	 Train Loss: 0.173
2024-11-05 06:47 - INFO - 	 Val. Loss: 0.201
2024-11-05 06:47 - INFO - 	 ROC-AUC: 0.723
2024-11-05 06:47 - INFO - 	 PR-AUC: 0.163
2024-11-05 06:47 - INFO - 	 Recall for 0.4 precision: 0.088
2024-11-05 06:47 - INFO - 	 Best Val. Loss: 0.201
2024-11-05 06:47 - INFO - 	 Best ROC-AUC: 0.723
2024-11-05 06:47 - INFO - 	 Best PR-AUC: 0.165
2024-11-05 06:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.670
2024-11-05 06:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.096
2024-11-05 06:47 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-05 06:47 - INFO - ---------------------------------------------
2024-11-05 06:49 - INFO - ---------------------------------------------
2024-11-05 06:49 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 06:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.18051
2024-11-05 06:49 - INFO - 	 Train Loss: 0.171
2024-11-05 06:49 - INFO - 	 Val. Loss: 0.197
2024-11-05 06:49 - INFO - 	 ROC-AUC: 0.732
2024-11-05 06:49 - INFO - 	 PR-AUC: 0.181
2024-11-05 06:49 - INFO - 	 Recall for 0.4 precision: 0.088
2024-11-05 06:49 - INFO - 	 Best Val. Loss: 0.197
2024-11-05 06:49 - INFO - 	 Best ROC-AUC: 0.732
2024-11-05 06:49 - INFO - 	 Best PR-AUC: 0.181
2024-11-05 06:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-11-05 06:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.114
2024-11-05 06:49 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-05 06:49 - INFO - ---------------------------------------------
2024-11-05 06:52 - INFO - Fit the preprocessing pipeline
2024-11-05 06:52 - INFO - Training using device: mps
2024-11-05 06:52 - INFO - Creating generators
2024-11-05 06:52 - INFO - The model has 651,257 trainable parameters
2024-11-05 06:52 - INFO - * Model:
2024-11-05 06:52 - INFO - * -----------
2024-11-05 06:52 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 06:52 - INFO - * -----------
2024-11-05 06:52 - INFO - Evaluating model based on: aucpr
2024-11-05 06:52 - INFO - Training..

2024-11-05 06:53 - INFO - ---------------------------------------------
2024-11-05 06:53 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 06:53 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05776
2024-11-05 06:53 - INFO - 	 Train Loss: 0.263
2024-11-05 06:53 - INFO - 	 Val. Loss: 0.311
2024-11-05 06:53 - INFO - 	 ROC-AUC: 0.572
2024-11-05 06:53 - INFO - 	 PR-AUC: 0.058
2024-11-05 06:53 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 06:53 - INFO - 	 Best Val. Loss: 0.311
2024-11-05 06:53 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 06:53 - INFO - 	 Best PR-AUC: 0.058
2024-11-05 06:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 06:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.061
2024-11-05 06:53 - INFO - 	 Best Recall for 0.4 precision: 0.002
2024-11-05 06:53 - INFO - ---------------------------------------------
2024-11-05 06:55 - INFO - ---------------------------------------------
2024-11-05 06:55 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 06:55 - INFO - 	 Train Loss: 0.216
2024-11-05 06:55 - INFO - 	 Val. Loss: 0.267
2024-11-05 06:55 - INFO - 	 ROC-AUC: 0.532
2024-11-05 06:55 - INFO - 	 PR-AUC: 0.051
2024-11-05 06:55 - INFO - 	 Recall for 0.4 precision: 0.018
2024-11-05 06:55 - INFO - 	 Best Val. Loss: 0.267
2024-11-05 06:55 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 06:55 - INFO - 	 Best PR-AUC: 0.058
2024-11-05 06:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 06:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.061
2024-11-05 06:55 - INFO - 	 Best Recall for 0.4 precision: 0.018
2024-11-05 06:55 - INFO - ---------------------------------------------
2024-11-05 06:57 - INFO - ---------------------------------------------
2024-11-05 06:57 - INFO - Epoch: 03 | Time: 1m 47s
2024-11-05 06:57 - INFO - 	 Train Loss: 0.202
2024-11-05 06:57 - INFO - 	 Val. Loss: 0.242
2024-11-05 06:57 - INFO - 	 ROC-AUC: 0.565
2024-11-05 06:57 - INFO - 	 PR-AUC: 0.057
2024-11-05 06:57 - INFO - 	 Recall for 0.4 precision: 0.195
2024-11-05 06:57 - INFO - 	 Best Val. Loss: 0.242
2024-11-05 06:57 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 06:57 - INFO - 	 Best PR-AUC: 0.058
2024-11-05 06:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 06:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.061
2024-11-05 06:57 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 06:57 - INFO - ---------------------------------------------
2024-11-05 06:59 - INFO - ---------------------------------------------
2024-11-05 06:59 - INFO - Epoch: 04 | Time: 1m 48s
2024-11-05 06:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05979
2024-11-05 06:59 - INFO - 	 Train Loss: 0.193
2024-11-05 06:59 - INFO - 	 Val. Loss: 0.242
2024-11-05 06:59 - INFO - 	 ROC-AUC: 0.569
2024-11-05 06:59 - INFO - 	 PR-AUC: 0.060
2024-11-05 06:59 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-05 06:59 - INFO - 	 Best Val. Loss: 0.242
2024-11-05 06:59 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 06:59 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 06:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 06:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.064
2024-11-05 06:59 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 06:59 - INFO - ---------------------------------------------
2024-11-05 07:00 - INFO - ---------------------------------------------
2024-11-05 07:00 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-05 07:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06585
2024-11-05 07:00 - INFO - 	 Train Loss: 0.190
2024-11-05 07:00 - INFO - 	 Val. Loss: 0.229
2024-11-05 07:00 - INFO - 	 ROC-AUC: 0.570
2024-11-05 07:00 - INFO - 	 PR-AUC: 0.066
2024-11-05 07:00 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:00 - INFO - 	 Best Val. Loss: 0.229
2024-11-05 07:00 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 07:00 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 07:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 07:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 07:00 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:00 - INFO - ---------------------------------------------
2024-11-05 07:02 - INFO - ---------------------------------------------
2024-11-05 07:02 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 07:02 - INFO - 	 Train Loss: 0.184
2024-11-05 07:02 - INFO - 	 Val. Loss: 0.224
2024-11-05 07:02 - INFO - 	 ROC-AUC: 0.567
2024-11-05 07:02 - INFO - 	 PR-AUC: 0.059
2024-11-05 07:02 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 07:02 - INFO - 	 Best Val. Loss: 0.224
2024-11-05 07:02 - INFO - 	 Best ROC-AUC: 0.572
2024-11-05 07:02 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 07:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.562
2024-11-05 07:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 07:02 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:02 - INFO - ---------------------------------------------
2024-11-05 07:04 - INFO - ---------------------------------------------
2024-11-05 07:04 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 07:04 - INFO - 	 Train Loss: 0.182
2024-11-05 07:04 - INFO - 	 Val. Loss: 0.218
2024-11-05 07:04 - INFO - 	 ROC-AUC: 0.576
2024-11-05 07:04 - INFO - 	 PR-AUC: 0.060
2024-11-05 07:04 - INFO - 	 Recall for 0.4 precision: 0.075
2024-11-05 07:04 - INFO - 	 Best Val. Loss: 0.218
2024-11-05 07:04 - INFO - 	 Best ROC-AUC: 0.576
2024-11-05 07:04 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 07:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.573
2024-11-05 07:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 07:04 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:04 - INFO - ---------------------------------------------
2024-11-05 07:06 - INFO - ---------------------------------------------
2024-11-05 07:06 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 07:06 - INFO - 	 Train Loss: 0.184
2024-11-05 07:06 - INFO - 	 Val. Loss: 0.206
2024-11-05 07:06 - INFO - 	 ROC-AUC: 0.594
2024-11-05 07:06 - INFO - 	 PR-AUC: 0.063
2024-11-05 07:06 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:06 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 07:06 - INFO - 	 Best ROC-AUC: 0.594
2024-11-05 07:06 - INFO - 	 Best PR-AUC: 0.066
2024-11-05 07:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.582
2024-11-05 07:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.060
2024-11-05 07:06 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:06 - INFO - ---------------------------------------------
2024-11-05 07:08 - INFO - ---------------------------------------------
2024-11-05 07:08 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 07:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06886
2024-11-05 07:08 - INFO - 	 Train Loss: 0.180
2024-11-05 07:08 - INFO - 	 Val. Loss: 0.210
2024-11-05 07:08 - INFO - 	 ROC-AUC: 0.638
2024-11-05 07:08 - INFO - 	 PR-AUC: 0.069
2024-11-05 07:08 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 07:08 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 07:08 - INFO - 	 Best ROC-AUC: 0.638
2024-11-05 07:08 - INFO - 	 Best PR-AUC: 0.069
2024-11-05 07:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.620
2024-11-05 07:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.076
2024-11-05 07:08 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:08 - INFO - ---------------------------------------------
2024-11-05 07:10 - INFO - ---------------------------------------------
2024-11-05 07:10 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 07:10 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14297
2024-11-05 07:10 - INFO - 	 Train Loss: 0.178
2024-11-05 07:10 - INFO - 	 Val. Loss: 0.207
2024-11-05 07:10 - INFO - 	 ROC-AUC: 0.674
2024-11-05 07:10 - INFO - 	 PR-AUC: 0.143
2024-11-05 07:10 - INFO - 	 Recall for 0.4 precision: 0.059
2024-11-05 07:10 - INFO - 	 Best Val. Loss: 0.206
2024-11-05 07:10 - INFO - 	 Best ROC-AUC: 0.674
2024-11-05 07:10 - INFO - 	 Best PR-AUC: 0.143
2024-11-05 07:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.658
2024-11-05 07:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.095
2024-11-05 07:10 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-05 07:10 - INFO - ---------------------------------------------
2024-11-05 07:12 - INFO - Fit the preprocessing pipeline
2024-11-05 07:12 - INFO - Training using device: mps
2024-11-05 07:12 - INFO - Creating generators
2024-11-05 07:12 - INFO - The model has 651,257 trainable parameters
2024-11-05 07:12 - INFO - * Model:
2024-11-05 07:12 - INFO - * -----------
2024-11-05 07:12 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 07:12 - INFO - * -----------
2024-11-05 07:12 - INFO - Evaluating model based on: aucpr
2024-11-05 07:12 - INFO - Training..

2024-11-05 07:14 - INFO - ---------------------------------------------
2024-11-05 07:14 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 07:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05862
2024-11-05 07:14 - INFO - 	 Train Loss: 0.255
2024-11-05 07:14 - INFO - 	 Val. Loss: 0.317
2024-11-05 07:14 - INFO - 	 ROC-AUC: 0.527
2024-11-05 07:14 - INFO - 	 PR-AUC: 0.059
2024-11-05 07:14 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-05 07:14 - INFO - 	 Best Val. Loss: 0.317
2024-11-05 07:14 - INFO - 	 Best ROC-AUC: 0.527
2024-11-05 07:14 - INFO - 	 Best PR-AUC: 0.059
2024-11-05 07:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.522
2024-11-05 07:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.058
2024-11-05 07:14 - INFO - 	 Best Recall for 0.4 precision: 0.007
2024-11-05 07:14 - INFO - ---------------------------------------------
2024-11-05 07:16 - INFO - ---------------------------------------------
2024-11-05 07:16 - INFO - Epoch: 02 | Time: 1m 44s
2024-11-05 07:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07598
2024-11-05 07:16 - INFO - 	 Train Loss: 0.210
2024-11-05 07:16 - INFO - 	 Val. Loss: 0.267
2024-11-05 07:16 - INFO - 	 ROC-AUC: 0.560
2024-11-05 07:16 - INFO - 	 PR-AUC: 0.076
2024-11-05 07:16 - INFO - 	 Recall for 0.4 precision: 0.020
2024-11-05 07:16 - INFO - 	 Best Val. Loss: 0.267
2024-11-05 07:16 - INFO - 	 Best ROC-AUC: 0.560
2024-11-05 07:16 - INFO - 	 Best PR-AUC: 0.076
2024-11-05 07:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.577
2024-11-05 07:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 07:16 - INFO - 	 Best Recall for 0.4 precision: 0.020
2024-11-05 07:16 - INFO - ---------------------------------------------
2024-11-05 07:18 - INFO - ---------------------------------------------
2024-11-05 07:18 - INFO - Epoch: 03 | Time: 1m 48s
2024-11-05 07:18 - INFO - 	 Train Loss: 0.196
2024-11-05 07:18 - INFO - 	 Val. Loss: 0.250
2024-11-05 07:18 - INFO - 	 ROC-AUC: 0.608
2024-11-05 07:18 - INFO - 	 PR-AUC: 0.074
2024-11-05 07:18 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 07:18 - INFO - 	 Best Val. Loss: 0.250
2024-11-05 07:18 - INFO - 	 Best ROC-AUC: 0.608
2024-11-05 07:18 - INFO - 	 Best PR-AUC: 0.076
2024-11-05 07:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.608
2024-11-05 07:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.070
2024-11-05 07:18 - INFO - 	 Best Recall for 0.4 precision: 0.020
2024-11-05 07:18 - INFO - ---------------------------------------------
2024-11-05 07:19 - INFO - ---------------------------------------------
2024-11-05 07:19 - INFO - Epoch: 04 | Time: 1m 49s
2024-11-05 07:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.10584
2024-11-05 07:19 - INFO - 	 Train Loss: 0.188
2024-11-05 07:19 - INFO - 	 Val. Loss: 0.223
2024-11-05 07:19 - INFO - 	 ROC-AUC: 0.676
2024-11-05 07:19 - INFO - 	 PR-AUC: 0.106
2024-11-05 07:19 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:19 - INFO - 	 Best Val. Loss: 0.223
2024-11-05 07:19 - INFO - 	 Best ROC-AUC: 0.676
2024-11-05 07:19 - INFO - 	 Best PR-AUC: 0.106
2024-11-05 07:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.632
2024-11-05 07:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.083
2024-11-05 07:19 - INFO - 	 Best Recall for 0.4 precision: 0.020
2024-11-05 07:19 - INFO - ---------------------------------------------
2024-11-05 07:21 - INFO - ---------------------------------------------
2024-11-05 07:21 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-05 07:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.17416
2024-11-05 07:21 - INFO - 	 Train Loss: 0.177
2024-11-05 07:21 - INFO - 	 Val. Loss: 0.208
2024-11-05 07:21 - INFO - 	 ROC-AUC: 0.714
2024-11-05 07:21 - INFO - 	 PR-AUC: 0.174
2024-11-05 07:21 - INFO - 	 Recall for 0.4 precision: 0.081
2024-11-05 07:21 - INFO - 	 Best Val. Loss: 0.208
2024-11-05 07:21 - INFO - 	 Best ROC-AUC: 0.714
2024-11-05 07:21 - INFO - 	 Best PR-AUC: 0.174
2024-11-05 07:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.650
2024-11-05 07:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.090
2024-11-05 07:21 - INFO - 	 Best Recall for 0.4 precision: 0.081
2024-11-05 07:21 - INFO - ---------------------------------------------
2024-11-05 07:23 - INFO - ---------------------------------------------
2024-11-05 07:23 - INFO - Epoch: 06 | Time: 1m 50s
2024-11-05 07:23 - INFO - 	 Train Loss: 0.171
2024-11-05 07:23 - INFO - 	 Val. Loss: 0.203
2024-11-05 07:23 - INFO - 	 ROC-AUC: 0.729
2024-11-05 07:23 - INFO - 	 PR-AUC: 0.157
2024-11-05 07:23 - INFO - 	 Recall for 0.4 precision: 0.046
2024-11-05 07:23 - INFO - 	 Best Val. Loss: 0.203
2024-11-05 07:23 - INFO - 	 Best ROC-AUC: 0.729
2024-11-05 07:23 - INFO - 	 Best PR-AUC: 0.174
2024-11-05 07:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.646
2024-11-05 07:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.090
2024-11-05 07:23 - INFO - 	 Best Recall for 0.4 precision: 0.081
2024-11-05 07:23 - INFO - ---------------------------------------------
2024-11-05 07:25 - INFO - ---------------------------------------------
2024-11-05 07:25 - INFO - Epoch: 07 | Time: 1m 50s
2024-11-05 07:25 - INFO - 	 New best val_rocauc loss was found, current best value is 0.19589
2024-11-05 07:25 - INFO - 	 Train Loss: 0.168
2024-11-05 07:25 - INFO - 	 Val. Loss: 0.189
2024-11-05 07:25 - INFO - 	 ROC-AUC: 0.754
2024-11-05 07:25 - INFO - 	 PR-AUC: 0.196
2024-11-05 07:25 - INFO - 	 Recall for 0.4 precision: 0.109
2024-11-05 07:25 - INFO - 	 Best Val. Loss: 0.189
2024-11-05 07:25 - INFO - 	 Best ROC-AUC: 0.754
2024-11-05 07:25 - INFO - 	 Best PR-AUC: 0.196
2024-11-05 07:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.686
2024-11-05 07:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.109
2024-11-05 07:25 - INFO - 	 Best Recall for 0.4 precision: 0.109
2024-11-05 07:25 - INFO - ---------------------------------------------
2024-11-05 07:27 - INFO - ---------------------------------------------
2024-11-05 07:27 - INFO - Epoch: 08 | Time: 1m 50s
2024-11-05 07:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.19821
2024-11-05 07:27 - INFO - 	 Train Loss: 0.162
2024-11-05 07:27 - INFO - 	 Val. Loss: 0.184
2024-11-05 07:27 - INFO - 	 ROC-AUC: 0.795
2024-11-05 07:27 - INFO - 	 PR-AUC: 0.198
2024-11-05 07:27 - INFO - 	 Recall for 0.4 precision: 0.094
2024-11-05 07:27 - INFO - 	 Best Val. Loss: 0.184
2024-11-05 07:27 - INFO - 	 Best ROC-AUC: 0.795
2024-11-05 07:27 - INFO - 	 Best PR-AUC: 0.198
2024-11-05 07:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.715
2024-11-05 07:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.116
2024-11-05 07:27 - INFO - 	 Best Recall for 0.4 precision: 0.109
2024-11-05 07:27 - INFO - ---------------------------------------------
2024-11-05 07:29 - INFO - ---------------------------------------------
2024-11-05 07:29 - INFO - Epoch: 09 | Time: 1m 50s
2024-11-05 07:29 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22529
2024-11-05 07:29 - INFO - 	 Train Loss: 0.159
2024-11-05 07:29 - INFO - 	 Val. Loss: 0.176
2024-11-05 07:29 - INFO - 	 ROC-AUC: 0.790
2024-11-05 07:29 - INFO - 	 PR-AUC: 0.225
2024-11-05 07:29 - INFO - 	 Recall for 0.4 precision: 0.172
2024-11-05 07:29 - INFO - 	 Best Val. Loss: 0.176
2024-11-05 07:29 - INFO - 	 Best ROC-AUC: 0.795
2024-11-05 07:29 - INFO - 	 Best PR-AUC: 0.225
2024-11-05 07:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.715
2024-11-05 07:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.113
2024-11-05 07:29 - INFO - 	 Best Recall for 0.4 precision: 0.172
2024-11-05 07:29 - INFO - ---------------------------------------------
2024-11-05 07:31 - INFO - ---------------------------------------------
2024-11-05 07:31 - INFO - Epoch: 10 | Time: 1m 50s
2024-11-05 07:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.28123
2024-11-05 07:31 - INFO - 	 Train Loss: 0.155
2024-11-05 07:31 - INFO - 	 Val. Loss: 0.159
2024-11-05 07:31 - INFO - 	 ROC-AUC: 0.863
2024-11-05 07:31 - INFO - 	 PR-AUC: 0.281
2024-11-05 07:31 - INFO - 	 Recall for 0.4 precision: 0.221
2024-11-05 07:31 - INFO - 	 Best Val. Loss: 0.159
2024-11-05 07:31 - INFO - 	 Best ROC-AUC: 0.863
2024-11-05 07:31 - INFO - 	 Best PR-AUC: 0.281
2024-11-05 07:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.811
2024-11-05 07:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.160
2024-11-05 07:31 - INFO - 	 Best Recall for 0.4 precision: 0.221
2024-11-05 07:31 - INFO - ---------------------------------------------
2024-11-05 07:33 - INFO - Fit the preprocessing pipeline
2024-11-05 07:33 - INFO - Training using device: mps
2024-11-05 07:33 - INFO - Creating generators
2024-11-05 07:33 - INFO - The model has 651,257 trainable parameters
2024-11-05 07:33 - INFO - * Model:
2024-11-05 07:33 - INFO - * -----------
2024-11-05 07:33 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-05 07:33 - INFO - * -----------
2024-11-05 07:33 - INFO - Evaluating model based on: aucpr
2024-11-05 07:33 - INFO - Training..

2024-11-05 07:35 - INFO - ---------------------------------------------
2024-11-05 07:35 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-05 07:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05514
2024-11-05 07:35 - INFO - 	 Train Loss: 0.256
2024-11-05 07:35 - INFO - 	 Val. Loss: 0.312
2024-11-05 07:35 - INFO - 	 ROC-AUC: 0.534
2024-11-05 07:35 - INFO - 	 PR-AUC: 0.055
2024-11-05 07:35 - INFO - 	 Recall for 0.4 precision: 0.057
2024-11-05 07:35 - INFO - 	 Best Val. Loss: 0.312
2024-11-05 07:35 - INFO - 	 Best ROC-AUC: 0.534
2024-11-05 07:35 - INFO - 	 Best PR-AUC: 0.055
2024-11-05 07:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.543
2024-11-05 07:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.068
2024-11-05 07:35 - INFO - 	 Best Recall for 0.4 precision: 0.057
2024-11-05 07:35 - INFO - ---------------------------------------------
2024-11-05 07:37 - INFO - ---------------------------------------------
2024-11-05 07:37 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-05 07:37 - INFO - 	 Train Loss: 0.227
2024-11-05 07:37 - INFO - 	 Val. Loss: 0.290
2024-11-05 07:37 - INFO - 	 ROC-AUC: 0.548
2024-11-05 07:37 - INFO - 	 PR-AUC: 0.052
2024-11-05 07:37 - INFO - 	 Recall for 0.4 precision: 0.015
2024-11-05 07:37 - INFO - 	 Best Val. Loss: 0.290
2024-11-05 07:37 - INFO - 	 Best ROC-AUC: 0.548
2024-11-05 07:37 - INFO - 	 Best PR-AUC: 0.055
2024-11-05 07:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.528
2024-11-05 07:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.068
2024-11-05 07:37 - INFO - 	 Best Recall for 0.4 precision: 0.057
2024-11-05 07:37 - INFO - ---------------------------------------------
2024-11-05 07:38 - INFO - ---------------------------------------------
2024-11-05 07:38 - INFO - Epoch: 03 | Time: 1m 46s
2024-11-05 07:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.05975
2024-11-05 07:38 - INFO - 	 Train Loss: 0.206
2024-11-05 07:38 - INFO - 	 Val. Loss: 0.256
2024-11-05 07:38 - INFO - 	 ROC-AUC: 0.595
2024-11-05 07:38 - INFO - 	 PR-AUC: 0.060
2024-11-05 07:38 - INFO - 	 Recall for 0.4 precision: 0.169
2024-11-05 07:38 - INFO - 	 Best Val. Loss: 0.256
2024-11-05 07:38 - INFO - 	 Best ROC-AUC: 0.595
2024-11-05 07:38 - INFO - 	 Best PR-AUC: 0.060
2024-11-05 07:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.609
2024-11-05 07:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.073
2024-11-05 07:38 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:38 - INFO - ---------------------------------------------
2024-11-05 07:40 - INFO - ---------------------------------------------
2024-11-05 07:40 - INFO - Epoch: 04 | Time: 1m 47s
2024-11-05 07:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06365
2024-11-05 07:40 - INFO - 	 Train Loss: 0.193
2024-11-05 07:40 - INFO - 	 Val. Loss: 0.239
2024-11-05 07:40 - INFO - 	 ROC-AUC: 0.597
2024-11-05 07:40 - INFO - 	 PR-AUC: 0.064
2024-11-05 07:40 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 07:40 - INFO - 	 Best Val. Loss: 0.239
2024-11-05 07:40 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:40 - INFO - 	 Best PR-AUC: 0.064
2024-11-05 07:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.585
2024-11-05 07:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.065
2024-11-05 07:40 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:40 - INFO - ---------------------------------------------
2024-11-05 07:42 - INFO - ---------------------------------------------
2024-11-05 07:42 - INFO - Epoch: 05 | Time: 1m 48s
2024-11-05 07:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.06832
2024-11-05 07:42 - INFO - 	 Train Loss: 0.192
2024-11-05 07:42 - INFO - 	 Val. Loss: 0.240
2024-11-05 07:42 - INFO - 	 ROC-AUC: 0.570
2024-11-05 07:42 - INFO - 	 PR-AUC: 0.068
2024-11-05 07:42 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-05 07:42 - INFO - 	 Best Val. Loss: 0.239
2024-11-05 07:42 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:42 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 07:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.585
2024-11-05 07:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.077
2024-11-05 07:42 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:42 - INFO - ---------------------------------------------
2024-11-05 07:44 - INFO - ---------------------------------------------
2024-11-05 07:44 - INFO - Epoch: 06 | Time: 2m 3s
2024-11-05 07:44 - INFO - 	 Train Loss: 0.188
2024-11-05 07:44 - INFO - 	 Val. Loss: 0.231
2024-11-05 07:44 - INFO - 	 ROC-AUC: 0.567
2024-11-05 07:44 - INFO - 	 PR-AUC: 0.066
2024-11-05 07:44 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:44 - INFO - 	 Best Val. Loss: 0.231
2024-11-05 07:44 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:44 - INFO - 	 Best PR-AUC: 0.068
2024-11-05 07:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.585
2024-11-05 07:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.077
2024-11-05 07:44 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:44 - INFO - ---------------------------------------------
2024-11-05 07:46 - INFO - ---------------------------------------------
2024-11-05 07:46 - INFO - Epoch: 07 | Time: 2m 14s
2024-11-05 07:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07353
2024-11-05 07:46 - INFO - 	 Train Loss: 0.185
2024-11-05 07:46 - INFO - 	 Val. Loss: 0.225
2024-11-05 07:46 - INFO - 	 ROC-AUC: 0.597
2024-11-05 07:46 - INFO - 	 PR-AUC: 0.074
2024-11-05 07:46 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:46 - INFO - 	 Best Val. Loss: 0.225
2024-11-05 07:46 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:46 - INFO - 	 Best PR-AUC: 0.074
2024-11-05 07:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.581
2024-11-05 07:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.074
2024-11-05 07:46 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:46 - INFO - ---------------------------------------------
2024-11-05 07:48 - INFO - ---------------------------------------------
2024-11-05 07:48 - INFO - Epoch: 08 | Time: 2m 12s
2024-11-05 07:48 - INFO - 	 Train Loss: 0.181
2024-11-05 07:48 - INFO - 	 Val. Loss: 0.216
2024-11-05 07:48 - INFO - 	 ROC-AUC: 0.560
2024-11-05 07:48 - INFO - 	 PR-AUC: 0.056
2024-11-05 07:48 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-05 07:48 - INFO - 	 Best Val. Loss: 0.216
2024-11-05 07:48 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:48 - INFO - 	 Best PR-AUC: 0.074
2024-11-05 07:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.581
2024-11-05 07:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.074
2024-11-05 07:48 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:48 - INFO - ---------------------------------------------
2024-11-05 07:51 - INFO - ---------------------------------------------
2024-11-05 07:51 - INFO - Epoch: 09 | Time: 2m 19s
2024-11-05 07:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.07432
2024-11-05 07:51 - INFO - 	 Train Loss: 0.179
2024-11-05 07:51 - INFO - 	 Val. Loss: 0.220
2024-11-05 07:51 - INFO - 	 ROC-AUC: 0.561
2024-11-05 07:51 - INFO - 	 PR-AUC: 0.074
2024-11-05 07:51 - INFO - 	 Recall for 0.4 precision: 0.003
2024-11-05 07:51 - INFO - 	 Best Val. Loss: 0.216
2024-11-05 07:51 - INFO - 	 Best ROC-AUC: 0.597
2024-11-05 07:51 - INFO - 	 Best PR-AUC: 0.074
2024-11-05 07:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.581
2024-11-05 07:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.053
2024-11-05 07:51 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:51 - INFO - ---------------------------------------------
2024-11-05 07:53 - INFO - ---------------------------------------------
2024-11-05 07:53 - INFO - Epoch: 10 | Time: 2m 21s
2024-11-05 07:53 - INFO - 	 New best val_rocauc loss was found, current best value is 0.15022
2024-11-05 07:53 - INFO - 	 Train Loss: 0.177
2024-11-05 07:53 - INFO - 	 Val. Loss: 0.204
2024-11-05 07:53 - INFO - 	 ROC-AUC: 0.662
2024-11-05 07:53 - INFO - 	 PR-AUC: 0.150
2024-11-05 07:53 - INFO - 	 Recall for 0.4 precision: 0.085
2024-11-05 07:53 - INFO - 	 Best Val. Loss: 0.204
2024-11-05 07:53 - INFO - 	 Best ROC-AUC: 0.662
2024-11-05 07:53 - INFO - 	 Best PR-AUC: 0.150
2024-11-05 07:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.636
2024-11-05 07:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.097
2024-11-05 07:53 - INFO - 	 Best Recall for 0.4 precision: 0.169
2024-11-05 07:53 - INFO - ---------------------------------------------
