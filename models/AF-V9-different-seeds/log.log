2024-01-16 22:08 - INFO - Fit the preprocessing pipeline
2024-01-16 22:08 - INFO - Training using device: cuda
2024-01-16 22:08 - INFO - Creating generators
2024-01-16 22:08 - INFO - The model has 651,257 trainable parameters
2024-01-16 22:08 - INFO - * Model:
2024-01-16 22:08 - INFO - * -----------
2024-01-16 22:08 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-16 22:08 - INFO - * -----------
2024-01-16 22:08 - INFO - Evaluating model based on: rocauc
2024-01-16 22:08 - INFO - Training..

2024-01-16 22:14 - INFO - ---------------------------------------------
2024-01-16 22:14 - INFO - Epoch: 01 | Time: 5m 46s
2024-01-16 22:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.62091
2024-01-16 22:14 - INFO - 	 Train Loss: 0.567
2024-01-16 22:14 - INFO - 	 Val. Loss: 0.540
2024-01-16 22:14 - INFO - 	 ROC-AUC: 0.621
2024-01-16 22:14 - INFO - 	 PR-AUC: 0.347
2024-01-16 22:14 - INFO - 	 Recall for 0.4 precision: 0.225
2024-01-16 22:14 - INFO - 	 Best Val. Loss: 0.540
2024-01-16 22:14 - INFO - 	 Best ROC-AUC: 0.621
2024-01-16 22:14 - INFO - 	 Best PR-AUC: 0.347
2024-01-16 22:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.593
2024-01-16 22:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.328
2024-01-16 22:14 - INFO - 	 Best Recall for 0.4 precision: 0.225
2024-01-16 22:14 - INFO - ---------------------------------------------
2024-01-16 22:19 - INFO - ---------------------------------------------
2024-01-16 22:19 - INFO - Epoch: 02 | Time: 5m 40s
2024-01-16 22:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7047
2024-01-16 22:19 - INFO - 	 Train Loss: 0.523
2024-01-16 22:19 - INFO - 	 Val. Loss: 0.510
2024-01-16 22:19 - INFO - 	 ROC-AUC: 0.705
2024-01-16 22:19 - INFO - 	 PR-AUC: 0.429
2024-01-16 22:19 - INFO - 	 Recall for 0.4 precision: 0.556
2024-01-16 22:19 - INFO - 	 Best Val. Loss: 0.510
2024-01-16 22:19 - INFO - 	 Best ROC-AUC: 0.705
2024-01-16 22:19 - INFO - 	 Best PR-AUC: 0.429
2024-01-16 22:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.672
2024-01-16 22:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.391
2024-01-16 22:19 - INFO - 	 Best Recall for 0.4 precision: 0.556
2024-01-16 22:19 - INFO - ---------------------------------------------
2024-01-16 22:26 - INFO - ---------------------------------------------
2024-01-16 22:26 - INFO - Epoch: 03 | Time: 6m 15s
2024-01-16 22:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71775
2024-01-16 22:26 - INFO - 	 Train Loss: 0.503
2024-01-16 22:26 - INFO - 	 Val. Loss: 0.502
2024-01-16 22:26 - INFO - 	 ROC-AUC: 0.718
2024-01-16 22:26 - INFO - 	 PR-AUC: 0.440
2024-01-16 22:26 - INFO - 	 Recall for 0.4 precision: 0.603
2024-01-16 22:26 - INFO - 	 Best Val. Loss: 0.502
2024-01-16 22:26 - INFO - 	 Best ROC-AUC: 0.718
2024-01-16 22:26 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 22:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.684
2024-01-16 22:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.406
2024-01-16 22:26 - INFO - 	 Best Recall for 0.4 precision: 0.603
2024-01-16 22:26 - INFO - ---------------------------------------------
2024-01-16 22:32 - INFO - ---------------------------------------------
2024-01-16 22:32 - INFO - Epoch: 04 | Time: 6m 7s
2024-01-16 22:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72057
2024-01-16 22:32 - INFO - 	 Train Loss: 0.496
2024-01-16 22:32 - INFO - 	 Val. Loss: 0.500
2024-01-16 22:32 - INFO - 	 ROC-AUC: 0.721
2024-01-16 22:32 - INFO - 	 PR-AUC: 0.438
2024-01-16 22:32 - INFO - 	 Recall for 0.4 precision: 0.618
2024-01-16 22:32 - INFO - 	 Best Val. Loss: 0.500
2024-01-16 22:32 - INFO - 	 Best ROC-AUC: 0.721
2024-01-16 22:32 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 22:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-16 22:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.406
2024-01-16 22:32 - INFO - 	 Best Recall for 0.4 precision: 0.618
2024-01-16 22:32 - INFO - ---------------------------------------------
2024-01-16 22:38 - INFO - ---------------------------------------------
2024-01-16 22:38 - INFO - Epoch: 05 | Time: 6m 31s
2024-01-16 22:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72197
2024-01-16 22:38 - INFO - 	 Train Loss: 0.492
2024-01-16 22:38 - INFO - 	 Val. Loss: 0.497
2024-01-16 22:38 - INFO - 	 ROC-AUC: 0.722
2024-01-16 22:38 - INFO - 	 PR-AUC: 0.442
2024-01-16 22:38 - INFO - 	 Recall for 0.4 precision: 0.627
2024-01-16 22:38 - INFO - 	 Best Val. Loss: 0.497
2024-01-16 22:38 - INFO - 	 Best ROC-AUC: 0.722
2024-01-16 22:38 - INFO - 	 Best PR-AUC: 0.442
2024-01-16 22:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.690
2024-01-16 22:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-16 22:38 - INFO - 	 Best Recall for 0.4 precision: 0.627
2024-01-16 22:38 - INFO - ---------------------------------------------
2024-01-16 22:45 - INFO - ---------------------------------------------
2024-01-16 22:45 - INFO - Epoch: 06 | Time: 6m 18s
2024-01-16 22:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72336
2024-01-16 22:45 - INFO - 	 Train Loss: 0.489
2024-01-16 22:45 - INFO - 	 Val. Loss: 0.497
2024-01-16 22:45 - INFO - 	 ROC-AUC: 0.723
2024-01-16 22:45 - INFO - 	 PR-AUC: 0.437
2024-01-16 22:45 - INFO - 	 Recall for 0.4 precision: 0.634
2024-01-16 22:45 - INFO - 	 Best Val. Loss: 0.497
2024-01-16 22:45 - INFO - 	 Best ROC-AUC: 0.723
2024-01-16 22:45 - INFO - 	 Best PR-AUC: 0.442
2024-01-16 22:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.697
2024-01-16 22:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-16 22:45 - INFO - 	 Best Recall for 0.4 precision: 0.634
2024-01-16 22:45 - INFO - ---------------------------------------------
2024-01-16 22:51 - INFO - ---------------------------------------------
2024-01-16 22:51 - INFO - Epoch: 07 | Time: 6m 12s
2024-01-16 22:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72483
2024-01-16 22:51 - INFO - 	 Train Loss: 0.487
2024-01-16 22:51 - INFO - 	 Val. Loss: 0.496
2024-01-16 22:51 - INFO - 	 ROC-AUC: 0.725
2024-01-16 22:51 - INFO - 	 PR-AUC: 0.442
2024-01-16 22:51 - INFO - 	 Recall for 0.4 precision: 0.634
2024-01-16 22:51 - INFO - 	 Best Val. Loss: 0.496
2024-01-16 22:51 - INFO - 	 Best ROC-AUC: 0.725
2024-01-16 22:51 - INFO - 	 Best PR-AUC: 0.442
2024-01-16 22:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-16 22:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-16 22:51 - INFO - 	 Best Recall for 0.4 precision: 0.634
2024-01-16 22:51 - INFO - ---------------------------------------------
2024-01-16 22:58 - INFO - ---------------------------------------------
2024-01-16 22:58 - INFO - Epoch: 08 | Time: 6m 50s
2024-01-16 22:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72759
2024-01-16 22:58 - INFO - 	 Train Loss: 0.486
2024-01-16 22:58 - INFO - 	 Val. Loss: 0.495
2024-01-16 22:58 - INFO - 	 ROC-AUC: 0.728
2024-01-16 22:58 - INFO - 	 PR-AUC: 0.443
2024-01-16 22:58 - INFO - 	 Recall for 0.4 precision: 0.643
2024-01-16 22:58 - INFO - 	 Best Val. Loss: 0.495
2024-01-16 22:58 - INFO - 	 Best ROC-AUC: 0.728
2024-01-16 22:58 - INFO - 	 Best PR-AUC: 0.443
2024-01-16 22:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-16 22:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.433
2024-01-16 22:58 - INFO - 	 Best Recall for 0.4 precision: 0.643
2024-01-16 22:58 - INFO - ---------------------------------------------
2024-01-16 23:04 - INFO - ---------------------------------------------
2024-01-16 23:04 - INFO - Epoch: 09 | Time: 5m 57s
2024-01-16 23:04 - INFO - 	 Train Loss: 0.484
2024-01-16 23:04 - INFO - 	 Val. Loss: 0.503
2024-01-16 23:04 - INFO - 	 ROC-AUC: 0.714
2024-01-16 23:04 - INFO - 	 PR-AUC: 0.424
2024-01-16 23:04 - INFO - 	 Recall for 0.4 precision: 0.605
2024-01-16 23:04 - INFO - 	 Best Val. Loss: 0.495
2024-01-16 23:04 - INFO - 	 Best ROC-AUC: 0.728
2024-01-16 23:04 - INFO - 	 Best PR-AUC: 0.443
2024-01-16 23:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-16 23:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.433
2024-01-16 23:04 - INFO - 	 Best Recall for 0.4 precision: 0.643
2024-01-16 23:04 - INFO - ---------------------------------------------
2024-01-16 23:10 - INFO - ---------------------------------------------
2024-01-16 23:10 - INFO - Epoch: 10 | Time: 6m 12s
2024-01-16 23:10 - INFO - 	 Train Loss: 0.483
2024-01-16 23:10 - INFO - 	 Val. Loss: 0.500
2024-01-16 23:10 - INFO - 	 ROC-AUC: 0.720
2024-01-16 23:10 - INFO - 	 PR-AUC: 0.431
2024-01-16 23:10 - INFO - 	 Recall for 0.4 precision: 0.621
2024-01-16 23:10 - INFO - 	 Best Val. Loss: 0.495
2024-01-16 23:10 - INFO - 	 Best ROC-AUC: 0.728
2024-01-16 23:10 - INFO - 	 Best PR-AUC: 0.443
2024-01-16 23:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-16 23:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.433
2024-01-16 23:10 - INFO - 	 Best Recall for 0.4 precision: 0.643
2024-01-16 23:10 - INFO - ---------------------------------------------
2024-01-16 23:15 - INFO - Fit the preprocessing pipeline
2024-01-16 23:15 - INFO - Training using device: cuda
2024-01-16 23:15 - INFO - Creating generators
2024-01-16 23:15 - INFO - The model has 651,257 trainable parameters
2024-01-16 23:15 - INFO - * Model:
2024-01-16 23:15 - INFO - * -----------
2024-01-16 23:15 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-16 23:15 - INFO - * -----------
2024-01-16 23:15 - INFO - Evaluating model based on: rocauc
2024-01-16 23:15 - INFO - Training..

2024-01-16 23:22 - INFO - ---------------------------------------------
2024-01-16 23:22 - INFO - Epoch: 01 | Time: 7m 0s
2024-01-16 23:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.59629
2024-01-16 23:22 - INFO - 	 Train Loss: 0.568
2024-01-16 23:22 - INFO - 	 Val. Loss: 0.546
2024-01-16 23:22 - INFO - 	 ROC-AUC: 0.596
2024-01-16 23:22 - INFO - 	 PR-AUC: 0.329
2024-01-16 23:22 - INFO - 	 Recall for 0.4 precision: 0.191
2024-01-16 23:22 - INFO - 	 Best Val. Loss: 0.546
2024-01-16 23:22 - INFO - 	 Best ROC-AUC: 0.596
2024-01-16 23:22 - INFO - 	 Best PR-AUC: 0.329
2024-01-16 23:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.571
2024-01-16 23:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.312
2024-01-16 23:22 - INFO - 	 Best Recall for 0.4 precision: 0.191
2024-01-16 23:22 - INFO - ---------------------------------------------
2024-01-16 23:29 - INFO - ---------------------------------------------
2024-01-16 23:29 - INFO - Epoch: 02 | Time: 6m 42s
2024-01-16 23:29 - INFO - 	 New best val_rocauc loss was found, current best value is 0.699
2024-01-16 23:29 - INFO - 	 Train Loss: 0.521
2024-01-16 23:29 - INFO - 	 Val. Loss: 0.510
2024-01-16 23:29 - INFO - 	 ROC-AUC: 0.699
2024-01-16 23:29 - INFO - 	 PR-AUC: 0.422
2024-01-16 23:29 - INFO - 	 Recall for 0.4 precision: 0.538
2024-01-16 23:29 - INFO - 	 Best Val. Loss: 0.510
2024-01-16 23:29 - INFO - 	 Best ROC-AUC: 0.699
2024-01-16 23:29 - INFO - 	 Best PR-AUC: 0.422
2024-01-16 23:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.669
2024-01-16 23:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.389
2024-01-16 23:29 - INFO - 	 Best Recall for 0.4 precision: 0.538
2024-01-16 23:29 - INFO - ---------------------------------------------
2024-01-16 23:35 - INFO - ---------------------------------------------
2024-01-16 23:35 - INFO - Epoch: 03 | Time: 5m 45s
2024-01-16 23:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71411
2024-01-16 23:35 - INFO - 	 Train Loss: 0.504
2024-01-16 23:35 - INFO - 	 Val. Loss: 0.504
2024-01-16 23:35 - INFO - 	 ROC-AUC: 0.714
2024-01-16 23:35 - INFO - 	 PR-AUC: 0.434
2024-01-16 23:35 - INFO - 	 Recall for 0.4 precision: 0.608
2024-01-16 23:35 - INFO - 	 Best Val. Loss: 0.504
2024-01-16 23:35 - INFO - 	 Best ROC-AUC: 0.714
2024-01-16 23:35 - INFO - 	 Best PR-AUC: 0.434
2024-01-16 23:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.687
2024-01-16 23:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.403
2024-01-16 23:35 - INFO - 	 Best Recall for 0.4 precision: 0.608
2024-01-16 23:35 - INFO - ---------------------------------------------
2024-01-16 23:41 - INFO - ---------------------------------------------
2024-01-16 23:41 - INFO - Epoch: 04 | Time: 6m 11s
2024-01-16 23:41 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71874
2024-01-16 23:41 - INFO - 	 Train Loss: 0.498
2024-01-16 23:41 - INFO - 	 Val. Loss: 0.500
2024-01-16 23:41 - INFO - 	 ROC-AUC: 0.719
2024-01-16 23:41 - INFO - 	 PR-AUC: 0.440
2024-01-16 23:41 - INFO - 	 Recall for 0.4 precision: 0.620
2024-01-16 23:41 - INFO - 	 Best Val. Loss: 0.500
2024-01-16 23:41 - INFO - 	 Best ROC-AUC: 0.719
2024-01-16 23:41 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 23:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.685
2024-01-16 23:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.407
2024-01-16 23:41 - INFO - 	 Best Recall for 0.4 precision: 0.620
2024-01-16 23:41 - INFO - ---------------------------------------------
2024-01-16 23:46 - INFO - ---------------------------------------------
2024-01-16 23:46 - INFO - Epoch: 05 | Time: 5m 46s
2024-01-16 23:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72101
2024-01-16 23:46 - INFO - 	 Train Loss: 0.493
2024-01-16 23:46 - INFO - 	 Val. Loss: 0.498
2024-01-16 23:46 - INFO - 	 ROC-AUC: 0.721
2024-01-16 23:46 - INFO - 	 PR-AUC: 0.440
2024-01-16 23:46 - INFO - 	 Recall for 0.4 precision: 0.630
2024-01-16 23:46 - INFO - 	 Best Val. Loss: 0.498
2024-01-16 23:46 - INFO - 	 Best ROC-AUC: 0.721
2024-01-16 23:46 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 23:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-16 23:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.416
2024-01-16 23:46 - INFO - 	 Best Recall for 0.4 precision: 0.630
2024-01-16 23:46 - INFO - ---------------------------------------------
2024-01-16 23:52 - INFO - ---------------------------------------------
2024-01-16 23:52 - INFO - Epoch: 06 | Time: 5m 47s
2024-01-16 23:52 - INFO - 	 Train Loss: 0.489
2024-01-16 23:52 - INFO - 	 Val. Loss: 0.499
2024-01-16 23:52 - INFO - 	 ROC-AUC: 0.720
2024-01-16 23:52 - INFO - 	 PR-AUC: 0.440
2024-01-16 23:52 - INFO - 	 Recall for 0.4 precision: 0.624
2024-01-16 23:52 - INFO - 	 Best Val. Loss: 0.498
2024-01-16 23:52 - INFO - 	 Best ROC-AUC: 0.721
2024-01-16 23:52 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 23:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-16 23:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.416
2024-01-16 23:52 - INFO - 	 Best Recall for 0.4 precision: 0.630
2024-01-16 23:52 - INFO - ---------------------------------------------
2024-01-16 23:59 - INFO - ---------------------------------------------
2024-01-16 23:59 - INFO - Epoch: 07 | Time: 6m 48s
2024-01-16 23:59 - INFO - 	 Train Loss: 0.487
2024-01-16 23:59 - INFO - 	 Val. Loss: 0.503
2024-01-16 23:59 - INFO - 	 ROC-AUC: 0.712
2024-01-16 23:59 - INFO - 	 PR-AUC: 0.426
2024-01-16 23:59 - INFO - 	 Recall for 0.4 precision: 0.602
2024-01-16 23:59 - INFO - 	 Best Val. Loss: 0.498
2024-01-16 23:59 - INFO - 	 Best ROC-AUC: 0.721
2024-01-16 23:59 - INFO - 	 Best PR-AUC: 0.440
2024-01-16 23:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-16 23:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.416
2024-01-16 23:59 - INFO - 	 Best Recall for 0.4 precision: 0.630
2024-01-16 23:59 - INFO - ---------------------------------------------
2024-01-17 00:05 - INFO - ---------------------------------------------
2024-01-17 00:05 - INFO - Epoch: 08 | Time: 5m 45s
2024-01-17 00:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7211
2024-01-17 00:05 - INFO - 	 Train Loss: 0.485
2024-01-17 00:05 - INFO - 	 Val. Loss: 0.499
2024-01-17 00:05 - INFO - 	 ROC-AUC: 0.721
2024-01-17 00:05 - INFO - 	 PR-AUC: 0.436
2024-01-17 00:05 - INFO - 	 Recall for 0.4 precision: 0.627
2024-01-17 00:05 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 00:05 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 00:05 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 00:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 00:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.416
2024-01-17 00:05 - INFO - 	 Best Recall for 0.4 precision: 0.630
2024-01-17 00:05 - INFO - ---------------------------------------------
2024-01-17 00:12 - INFO - ---------------------------------------------
2024-01-17 00:12 - INFO - Epoch: 09 | Time: 6m 52s
2024-01-17 00:12 - INFO - 	 Train Loss: 0.484
2024-01-17 00:12 - INFO - 	 Val. Loss: 0.498
2024-01-17 00:12 - INFO - 	 ROC-AUC: 0.721
2024-01-17 00:12 - INFO - 	 PR-AUC: 0.435
2024-01-17 00:12 - INFO - 	 Recall for 0.4 precision: 0.634
2024-01-17 00:12 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 00:12 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 00:12 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 00:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 00:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.416
2024-01-17 00:12 - INFO - 	 Best Recall for 0.4 precision: 0.634
2024-01-17 00:12 - INFO - ---------------------------------------------
2024-01-17 00:19 - INFO - ---------------------------------------------
2024-01-17 00:19 - INFO - Epoch: 10 | Time: 6m 50s
2024-01-17 00:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72626
2024-01-17 00:19 - INFO - 	 Train Loss: 0.483
2024-01-17 00:19 - INFO - 	 Val. Loss: 0.496
2024-01-17 00:19 - INFO - 	 ROC-AUC: 0.726
2024-01-17 00:19 - INFO - 	 PR-AUC: 0.446
2024-01-17 00:19 - INFO - 	 Recall for 0.4 precision: 0.643
2024-01-17 00:19 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 00:19 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 00:19 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 00:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 00:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.441
2024-01-17 00:19 - INFO - 	 Best Recall for 0.4 precision: 0.643
2024-01-17 00:19 - INFO - ---------------------------------------------
2024-01-17 00:23 - INFO - Fit the preprocessing pipeline
2024-01-17 00:23 - INFO - Training using device: cuda
2024-01-17 00:23 - INFO - Creating generators
2024-01-17 00:23 - INFO - The model has 651,257 trainable parameters
2024-01-17 00:23 - INFO - * Model:
2024-01-17 00:23 - INFO - * -----------
2024-01-17 00:23 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 00:23 - INFO - * -----------
2024-01-17 00:23 - INFO - Evaluating model based on: rocauc
2024-01-17 00:23 - INFO - Training..

2024-01-17 00:29 - INFO - ---------------------------------------------
2024-01-17 00:29 - INFO - Epoch: 01 | Time: 5m 45s
2024-01-17 00:29 - INFO - 	 New best val_rocauc loss was found, current best value is 0.59692
2024-01-17 00:29 - INFO - 	 Train Loss: 0.572
2024-01-17 00:29 - INFO - 	 Val. Loss: 0.545
2024-01-17 00:29 - INFO - 	 ROC-AUC: 0.597
2024-01-17 00:29 - INFO - 	 PR-AUC: 0.327
2024-01-17 00:29 - INFO - 	 Recall for 0.4 precision: 0.146
2024-01-17 00:29 - INFO - 	 Best Val. Loss: 0.545
2024-01-17 00:29 - INFO - 	 Best ROC-AUC: 0.597
2024-01-17 00:29 - INFO - 	 Best PR-AUC: 0.327
2024-01-17 00:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.570
2024-01-17 00:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.311
2024-01-17 00:29 - INFO - 	 Best Recall for 0.4 precision: 0.146
2024-01-17 00:29 - INFO - ---------------------------------------------
2024-01-17 00:35 - INFO - ---------------------------------------------
2024-01-17 00:35 - INFO - Epoch: 02 | Time: 6m 10s
2024-01-17 00:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.69738
2024-01-17 00:35 - INFO - 	 Train Loss: 0.528
2024-01-17 00:35 - INFO - 	 Val. Loss: 0.515
2024-01-17 00:35 - INFO - 	 ROC-AUC: 0.697
2024-01-17 00:35 - INFO - 	 PR-AUC: 0.413
2024-01-17 00:35 - INFO - 	 Recall for 0.4 precision: 0.524
2024-01-17 00:35 - INFO - 	 Best Val. Loss: 0.515
2024-01-17 00:35 - INFO - 	 Best ROC-AUC: 0.697
2024-01-17 00:35 - INFO - 	 Best PR-AUC: 0.413
2024-01-17 00:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.662
2024-01-17 00:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.382
2024-01-17 00:35 - INFO - 	 Best Recall for 0.4 precision: 0.524
2024-01-17 00:35 - INFO - ---------------------------------------------
2024-01-17 00:42 - INFO - ---------------------------------------------
2024-01-17 00:42 - INFO - Epoch: 03 | Time: 6m 20s
2024-01-17 00:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71236
2024-01-17 00:42 - INFO - 	 Train Loss: 0.505
2024-01-17 00:42 - INFO - 	 Val. Loss: 0.504
2024-01-17 00:42 - INFO - 	 ROC-AUC: 0.712
2024-01-17 00:42 - INFO - 	 PR-AUC: 0.431
2024-01-17 00:42 - INFO - 	 Recall for 0.4 precision: 0.595
2024-01-17 00:42 - INFO - 	 Best Val. Loss: 0.504
2024-01-17 00:42 - INFO - 	 Best ROC-AUC: 0.712
2024-01-17 00:42 - INFO - 	 Best PR-AUC: 0.431
2024-01-17 00:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.681
2024-01-17 00:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.399
2024-01-17 00:42 - INFO - 	 Best Recall for 0.4 precision: 0.595
2024-01-17 00:42 - INFO - ---------------------------------------------
2024-01-17 00:48 - INFO - ---------------------------------------------
2024-01-17 00:48 - INFO - Epoch: 04 | Time: 6m 19s
2024-01-17 00:48 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71925
2024-01-17 00:48 - INFO - 	 Train Loss: 0.497
2024-01-17 00:48 - INFO - 	 Val. Loss: 0.500
2024-01-17 00:48 - INFO - 	 ROC-AUC: 0.719
2024-01-17 00:48 - INFO - 	 PR-AUC: 0.436
2024-01-17 00:48 - INFO - 	 Recall for 0.4 precision: 0.625
2024-01-17 00:48 - INFO - 	 Best Val. Loss: 0.500
2024-01-17 00:48 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 00:48 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 00:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.690
2024-01-17 00:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.411
2024-01-17 00:48 - INFO - 	 Best Recall for 0.4 precision: 0.625
2024-01-17 00:48 - INFO - ---------------------------------------------
2024-01-17 00:54 - INFO - ---------------------------------------------
2024-01-17 00:54 - INFO - Epoch: 05 | Time: 5m 33s
2024-01-17 00:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72383
2024-01-17 00:54 - INFO - 	 Train Loss: 0.492
2024-01-17 00:54 - INFO - 	 Val. Loss: 0.497
2024-01-17 00:54 - INFO - 	 ROC-AUC: 0.724
2024-01-17 00:54 - INFO - 	 PR-AUC: 0.443
2024-01-17 00:54 - INFO - 	 Recall for 0.4 precision: 0.632
2024-01-17 00:54 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 00:54 - INFO - 	 Best ROC-AUC: 0.724
2024-01-17 00:54 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 00:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.698
2024-01-17 00:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 00:54 - INFO - 	 Best Recall for 0.4 precision: 0.632
2024-01-17 00:54 - INFO - ---------------------------------------------
2024-01-17 01:00 - INFO - ---------------------------------------------
2024-01-17 01:00 - INFO - Epoch: 06 | Time: 6m 26s
2024-01-17 01:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72507
2024-01-17 01:00 - INFO - 	 Train Loss: 0.489
2024-01-17 01:00 - INFO - 	 Val. Loss: 0.497
2024-01-17 01:00 - INFO - 	 ROC-AUC: 0.725
2024-01-17 01:00 - INFO - 	 PR-AUC: 0.447
2024-01-17 01:00 - INFO - 	 Recall for 0.4 precision: 0.637
2024-01-17 01:00 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 01:00 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 01:00 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 01:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 01:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 01:00 - INFO - 	 Best Recall for 0.4 precision: 0.637
2024-01-17 01:00 - INFO - ---------------------------------------------
2024-01-17 01:06 - INFO - ---------------------------------------------
2024-01-17 01:06 - INFO - Epoch: 07 | Time: 5m 52s
2024-01-17 01:06 - INFO - 	 Train Loss: 0.487
2024-01-17 01:06 - INFO - 	 Val. Loss: 0.497
2024-01-17 01:06 - INFO - 	 ROC-AUC: 0.724
2024-01-17 01:06 - INFO - 	 PR-AUC: 0.441
2024-01-17 01:06 - INFO - 	 Recall for 0.4 precision: 0.642
2024-01-17 01:06 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 01:06 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 01:06 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 01:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 01:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 01:06 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 01:06 - INFO - ---------------------------------------------
2024-01-17 01:13 - INFO - ---------------------------------------------
2024-01-17 01:13 - INFO - Epoch: 08 | Time: 7m 5s
2024-01-17 01:13 - INFO - 	 Train Loss: 0.485
2024-01-17 01:13 - INFO - 	 Val. Loss: 0.500
2024-01-17 01:13 - INFO - 	 ROC-AUC: 0.717
2024-01-17 01:13 - INFO - 	 PR-AUC: 0.432
2024-01-17 01:13 - INFO - 	 Recall for 0.4 precision: 0.604
2024-01-17 01:13 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 01:13 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 01:13 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 01:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 01:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 01:13 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 01:13 - INFO - ---------------------------------------------
2024-01-17 01:19 - INFO - ---------------------------------------------
2024-01-17 01:19 - INFO - Epoch: 09 | Time: 5m 55s
2024-01-17 01:19 - INFO - 	 Train Loss: 0.483
2024-01-17 01:19 - INFO - 	 Val. Loss: 0.500
2024-01-17 01:19 - INFO - 	 ROC-AUC: 0.718
2024-01-17 01:19 - INFO - 	 PR-AUC: 0.435
2024-01-17 01:19 - INFO - 	 Recall for 0.4 precision: 0.614
2024-01-17 01:19 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 01:19 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 01:19 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 01:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 01:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 01:19 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 01:19 - INFO - ---------------------------------------------
2024-01-17 01:29 - INFO - Fit the preprocessing pipeline
2024-01-17 01:29 - INFO - Training using device: cuda
2024-01-17 01:29 - INFO - Creating generators
2024-01-17 01:29 - INFO - The model has 651,257 trainable parameters
2024-01-17 01:29 - INFO - * Model:
2024-01-17 01:29 - INFO - * -----------
2024-01-17 01:29 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 01:29 - INFO - * -----------
2024-01-17 01:29 - INFO - Evaluating model based on: rocauc
2024-01-17 01:29 - INFO - Training..

2024-01-17 01:35 - INFO - ---------------------------------------------
2024-01-17 01:35 - INFO - Epoch: 01 | Time: 5m 48s
2024-01-17 01:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.58755
2024-01-17 01:35 - INFO - 	 Train Loss: 0.569
2024-01-17 01:35 - INFO - 	 Val. Loss: 0.546
2024-01-17 01:35 - INFO - 	 ROC-AUC: 0.588
2024-01-17 01:35 - INFO - 	 PR-AUC: 0.316
2024-01-17 01:35 - INFO - 	 Recall for 0.4 precision: 0.112
2024-01-17 01:35 - INFO - 	 Best Val. Loss: 0.546
2024-01-17 01:35 - INFO - 	 Best ROC-AUC: 0.588
2024-01-17 01:35 - INFO - 	 Best PR-AUC: 0.316
2024-01-17 01:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.567
2024-01-17 01:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.303
2024-01-17 01:35 - INFO - 	 Best Recall for 0.4 precision: 0.112
2024-01-17 01:35 - INFO - ---------------------------------------------
2024-01-17 01:42 - INFO - ---------------------------------------------
2024-01-17 01:42 - INFO - Epoch: 02 | Time: 6m 16s
2024-01-17 01:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70258
2024-01-17 01:42 - INFO - 	 Train Loss: 0.527
2024-01-17 01:42 - INFO - 	 Val. Loss: 0.509
2024-01-17 01:42 - INFO - 	 ROC-AUC: 0.703
2024-01-17 01:42 - INFO - 	 PR-AUC: 0.423
2024-01-17 01:42 - INFO - 	 Recall for 0.4 precision: 0.565
2024-01-17 01:42 - INFO - 	 Best Val. Loss: 0.509
2024-01-17 01:42 - INFO - 	 Best ROC-AUC: 0.703
2024-01-17 01:42 - INFO - 	 Best PR-AUC: 0.423
2024-01-17 01:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.660
2024-01-17 01:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.384
2024-01-17 01:42 - INFO - 	 Best Recall for 0.4 precision: 0.565
2024-01-17 01:42 - INFO - ---------------------------------------------
2024-01-17 01:47 - INFO - ---------------------------------------------
2024-01-17 01:47 - INFO - Epoch: 03 | Time: 5m 34s
2024-01-17 01:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71572
2024-01-17 01:47 - INFO - 	 Train Loss: 0.506
2024-01-17 01:47 - INFO - 	 Val. Loss: 0.501
2024-01-17 01:47 - INFO - 	 ROC-AUC: 0.716
2024-01-17 01:47 - INFO - 	 PR-AUC: 0.435
2024-01-17 01:47 - INFO - 	 Recall for 0.4 precision: 0.606
2024-01-17 01:47 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 01:47 - INFO - 	 Best ROC-AUC: 0.716
2024-01-17 01:47 - INFO - 	 Best PR-AUC: 0.435
2024-01-17 01:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.683
2024-01-17 01:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.403
2024-01-17 01:47 - INFO - 	 Best Recall for 0.4 precision: 0.606
2024-01-17 01:47 - INFO - ---------------------------------------------
2024-01-17 01:55 - INFO - ---------------------------------------------
2024-01-17 01:55 - INFO - Epoch: 04 | Time: 7m 27s
2024-01-17 01:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72184
2024-01-17 01:55 - INFO - 	 Train Loss: 0.497
2024-01-17 01:55 - INFO - 	 Val. Loss: 0.502
2024-01-17 01:55 - INFO - 	 ROC-AUC: 0.722
2024-01-17 01:55 - INFO - 	 PR-AUC: 0.439
2024-01-17 01:55 - INFO - 	 Recall for 0.4 precision: 0.628
2024-01-17 01:55 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 01:55 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 01:55 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 01:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.691
2024-01-17 01:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.413
2024-01-17 01:55 - INFO - 	 Best Recall for 0.4 precision: 0.628
2024-01-17 01:55 - INFO - ---------------------------------------------
2024-01-17 02:02 - INFO - ---------------------------------------------
2024-01-17 02:02 - INFO - Epoch: 05 | Time: 7m 12s
2024-01-17 02:02 - INFO - 	 Train Loss: 0.492
2024-01-17 02:02 - INFO - 	 Val. Loss: 0.501
2024-01-17 02:02 - INFO - 	 ROC-AUC: 0.720
2024-01-17 02:02 - INFO - 	 PR-AUC: 0.434
2024-01-17 02:02 - INFO - 	 Recall for 0.4 precision: 0.617
2024-01-17 02:02 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 02:02 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 02:02 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 02:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.691
2024-01-17 02:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.413
2024-01-17 02:02 - INFO - 	 Best Recall for 0.4 precision: 0.628
2024-01-17 02:02 - INFO - ---------------------------------------------
2024-01-17 02:08 - INFO - ---------------------------------------------
2024-01-17 02:08 - INFO - Epoch: 06 | Time: 6m 12s
2024-01-17 02:08 - INFO - 	 Train Loss: 0.489
2024-01-17 02:08 - INFO - 	 Val. Loss: 0.503
2024-01-17 02:08 - INFO - 	 ROC-AUC: 0.720
2024-01-17 02:08 - INFO - 	 PR-AUC: 0.439
2024-01-17 02:08 - INFO - 	 Recall for 0.4 precision: 0.613
2024-01-17 02:08 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 02:08 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 02:08 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 02:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.691
2024-01-17 02:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.424
2024-01-17 02:08 - INFO - 	 Best Recall for 0.4 precision: 0.628
2024-01-17 02:08 - INFO - ---------------------------------------------
2024-01-17 02:14 - INFO - ---------------------------------------------
2024-01-17 02:14 - INFO - Epoch: 07 | Time: 5m 50s
2024-01-17 02:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72702
2024-01-17 02:14 - INFO - 	 Train Loss: 0.487
2024-01-17 02:14 - INFO - 	 Val. Loss: 0.499
2024-01-17 02:14 - INFO - 	 ROC-AUC: 0.727
2024-01-17 02:14 - INFO - 	 PR-AUC: 0.447
2024-01-17 02:14 - INFO - 	 Recall for 0.4 precision: 0.649
2024-01-17 02:14 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 02:14 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 02:14 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 02:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-17 02:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 02:14 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 02:14 - INFO - ---------------------------------------------
2024-01-17 02:20 - INFO - ---------------------------------------------
2024-01-17 02:20 - INFO - Epoch: 08 | Time: 5m 43s
2024-01-17 02:20 - INFO - 	 Train Loss: 0.485
2024-01-17 02:20 - INFO - 	 Val. Loss: 0.499
2024-01-17 02:20 - INFO - 	 ROC-AUC: 0.723
2024-01-17 02:20 - INFO - 	 PR-AUC: 0.437
2024-01-17 02:20 - INFO - 	 Recall for 0.4 precision: 0.627
2024-01-17 02:20 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 02:20 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 02:20 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 02:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-17 02:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 02:20 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 02:20 - INFO - ---------------------------------------------
2024-01-17 02:25 - INFO - ---------------------------------------------
2024-01-17 02:25 - INFO - Epoch: 09 | Time: 5m 48s
2024-01-17 02:25 - INFO - 	 Train Loss: 0.484
2024-01-17 02:25 - INFO - 	 Val. Loss: 0.500
2024-01-17 02:25 - INFO - 	 ROC-AUC: 0.724
2024-01-17 02:25 - INFO - 	 PR-AUC: 0.442
2024-01-17 02:25 - INFO - 	 Recall for 0.4 precision: 0.631
2024-01-17 02:25 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 02:25 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 02:25 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 02:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-17 02:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 02:25 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 02:25 - INFO - ---------------------------------------------
2024-01-17 02:31 - INFO - ---------------------------------------------
2024-01-17 02:31 - INFO - Epoch: 10 | Time: 5m 49s
2024-01-17 02:31 - INFO - 	 Train Loss: 0.483
2024-01-17 02:31 - INFO - 	 Val. Loss: 0.499
2024-01-17 02:31 - INFO - 	 ROC-AUC: 0.720
2024-01-17 02:31 - INFO - 	 PR-AUC: 0.434
2024-01-17 02:31 - INFO - 	 Recall for 0.4 precision: 0.618
2024-01-17 02:31 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 02:31 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 02:31 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 02:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-17 02:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 02:31 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 02:31 - INFO - ---------------------------------------------
2024-01-17 02:36 - INFO - Fit the preprocessing pipeline
2024-01-17 02:36 - INFO - Training using device: cuda
2024-01-17 02:36 - INFO - Creating generators
2024-01-17 02:36 - INFO - The model has 651,257 trainable parameters
2024-01-17 02:36 - INFO - * Model:
2024-01-17 02:36 - INFO - * -----------
2024-01-17 02:36 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 02:36 - INFO - * -----------
2024-01-17 02:36 - INFO - Evaluating model based on: rocauc
2024-01-17 02:36 - INFO - Training..

2024-01-17 02:42 - INFO - ---------------------------------------------
2024-01-17 02:42 - INFO - Epoch: 01 | Time: 6m 17s
2024-01-17 02:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.62873
2024-01-17 02:42 - INFO - 	 Train Loss: 0.567
2024-01-17 02:42 - INFO - 	 Val. Loss: 0.537
2024-01-17 02:42 - INFO - 	 ROC-AUC: 0.629
2024-01-17 02:42 - INFO - 	 PR-AUC: 0.355
2024-01-17 02:42 - INFO - 	 Recall for 0.4 precision: 0.290
2024-01-17 02:42 - INFO - 	 Best Val. Loss: 0.537
2024-01-17 02:42 - INFO - 	 Best ROC-AUC: 0.629
2024-01-17 02:42 - INFO - 	 Best PR-AUC: 0.355
2024-01-17 02:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.608
2024-01-17 02:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.338
2024-01-17 02:42 - INFO - 	 Best Recall for 0.4 precision: 0.290
2024-01-17 02:42 - INFO - ---------------------------------------------
2024-01-17 02:49 - INFO - ---------------------------------------------
2024-01-17 02:49 - INFO - Epoch: 02 | Time: 7m 0s
2024-01-17 02:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.69995
2024-01-17 02:49 - INFO - 	 Train Loss: 0.523
2024-01-17 02:49 - INFO - 	 Val. Loss: 0.510
2024-01-17 02:49 - INFO - 	 ROC-AUC: 0.700
2024-01-17 02:49 - INFO - 	 PR-AUC: 0.422
2024-01-17 02:49 - INFO - 	 Recall for 0.4 precision: 0.000
2024-01-17 02:49 - INFO - 	 Best Val. Loss: 0.510
2024-01-17 02:49 - INFO - 	 Best ROC-AUC: 0.700
2024-01-17 02:49 - INFO - 	 Best PR-AUC: 0.422
2024-01-17 02:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.668
2024-01-17 02:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.391
2024-01-17 02:49 - INFO - 	 Best Recall for 0.4 precision: 0.290
2024-01-17 02:49 - INFO - ---------------------------------------------
2024-01-17 02:56 - INFO - ---------------------------------------------
2024-01-17 02:56 - INFO - Epoch: 03 | Time: 6m 55s
2024-01-17 02:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71539
2024-01-17 02:56 - INFO - 	 Train Loss: 0.505
2024-01-17 02:56 - INFO - 	 Val. Loss: 0.502
2024-01-17 02:56 - INFO - 	 ROC-AUC: 0.715
2024-01-17 02:56 - INFO - 	 PR-AUC: 0.434
2024-01-17 02:56 - INFO - 	 Recall for 0.4 precision: 0.612
2024-01-17 02:56 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 02:56 - INFO - 	 Best ROC-AUC: 0.715
2024-01-17 02:56 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 02:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.687
2024-01-17 02:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.404
2024-01-17 02:56 - INFO - 	 Best Recall for 0.4 precision: 0.612
2024-01-17 02:56 - INFO - ---------------------------------------------
2024-01-17 03:02 - INFO - ---------------------------------------------
2024-01-17 03:02 - INFO - Epoch: 04 | Time: 6m 24s
2024-01-17 03:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72069
2024-01-17 03:02 - INFO - 	 Train Loss: 0.498
2024-01-17 03:02 - INFO - 	 Val. Loss: 0.499
2024-01-17 03:02 - INFO - 	 ROC-AUC: 0.721
2024-01-17 03:02 - INFO - 	 PR-AUC: 0.444
2024-01-17 03:02 - INFO - 	 Recall for 0.4 precision: 0.624
2024-01-17 03:02 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 03:02 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 03:02 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 03:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.692
2024-01-17 03:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.420
2024-01-17 03:02 - INFO - 	 Best Recall for 0.4 precision: 0.624
2024-01-17 03:02 - INFO - ---------------------------------------------
2024-01-17 03:08 - INFO - ---------------------------------------------
2024-01-17 03:08 - INFO - Epoch: 05 | Time: 5m 16s
2024-01-17 03:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72281
2024-01-17 03:08 - INFO - 	 Train Loss: 0.493
2024-01-17 03:08 - INFO - 	 Val. Loss: 0.498
2024-01-17 03:08 - INFO - 	 ROC-AUC: 0.723
2024-01-17 03:08 - INFO - 	 PR-AUC: 0.442
2024-01-17 03:08 - INFO - 	 Recall for 0.4 precision: 0.631
2024-01-17 03:08 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 03:08 - INFO - 	 Best ROC-AUC: 0.723
2024-01-17 03:08 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 03:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 03:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.420
2024-01-17 03:08 - INFO - 	 Best Recall for 0.4 precision: 0.631
2024-01-17 03:08 - INFO - ---------------------------------------------
2024-01-17 03:14 - INFO - ---------------------------------------------
2024-01-17 03:14 - INFO - Epoch: 06 | Time: 6m 19s
2024-01-17 03:14 - INFO - 	 Train Loss: 0.490
2024-01-17 03:14 - INFO - 	 Val. Loss: 0.500
2024-01-17 03:14 - INFO - 	 ROC-AUC: 0.720
2024-01-17 03:14 - INFO - 	 PR-AUC: 0.439
2024-01-17 03:14 - INFO - 	 Recall for 0.4 precision: 0.625
2024-01-17 03:14 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 03:14 - INFO - 	 Best ROC-AUC: 0.723
2024-01-17 03:14 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 03:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 03:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.420
2024-01-17 03:14 - INFO - 	 Best Recall for 0.4 precision: 0.631
2024-01-17 03:14 - INFO - ---------------------------------------------
2024-01-17 03:21 - INFO - ---------------------------------------------
2024-01-17 03:21 - INFO - Epoch: 07 | Time: 6m 53s
2024-01-17 03:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72524
2024-01-17 03:21 - INFO - 	 Train Loss: 0.488
2024-01-17 03:21 - INFO - 	 Val. Loss: 0.496
2024-01-17 03:21 - INFO - 	 ROC-AUC: 0.725
2024-01-17 03:21 - INFO - 	 PR-AUC: 0.446
2024-01-17 03:21 - INFO - 	 Recall for 0.4 precision: 0.646
2024-01-17 03:21 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 03:21 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 03:21 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 03:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 03:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.426
2024-01-17 03:21 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 03:21 - INFO - ---------------------------------------------
2024-01-17 03:26 - INFO - ---------------------------------------------
2024-01-17 03:26 - INFO - Epoch: 08 | Time: 4m 53s
2024-01-17 03:26 - INFO - 	 Train Loss: 0.486
2024-01-17 03:26 - INFO - 	 Val. Loss: 0.496
2024-01-17 03:26 - INFO - 	 ROC-AUC: 0.725
2024-01-17 03:26 - INFO - 	 PR-AUC: 0.440
2024-01-17 03:26 - INFO - 	 Recall for 0.4 precision: 0.643
2024-01-17 03:26 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 03:26 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 03:26 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 03:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 03:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.426
2024-01-17 03:26 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 03:26 - INFO - ---------------------------------------------
2024-01-17 03:32 - INFO - ---------------------------------------------
2024-01-17 03:32 - INFO - Epoch: 09 | Time: 6m 34s
2024-01-17 03:32 - INFO - 	 Train Loss: 0.485
2024-01-17 03:32 - INFO - 	 Val. Loss: 0.497
2024-01-17 03:32 - INFO - 	 ROC-AUC: 0.723
2024-01-17 03:32 - INFO - 	 PR-AUC: 0.441
2024-01-17 03:32 - INFO - 	 Recall for 0.4 precision: 0.635
2024-01-17 03:32 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 03:32 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 03:32 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 03:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 03:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.426
2024-01-17 03:32 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 03:32 - INFO - ---------------------------------------------
2024-01-17 03:40 - INFO - ---------------------------------------------
2024-01-17 03:40 - INFO - Epoch: 10 | Time: 7m 11s
2024-01-17 03:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72619
2024-01-17 03:40 - INFO - 	 Train Loss: 0.484
2024-01-17 03:40 - INFO - 	 Val. Loss: 0.495
2024-01-17 03:40 - INFO - 	 ROC-AUC: 0.726
2024-01-17 03:40 - INFO - 	 PR-AUC: 0.446
2024-01-17 03:40 - INFO - 	 Recall for 0.4 precision: 0.638
2024-01-17 03:40 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 03:40 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 03:40 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 03:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 03:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.432
2024-01-17 03:40 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 03:40 - INFO - ---------------------------------------------
2024-01-17 03:45 - INFO - Fit the preprocessing pipeline
2024-01-17 03:45 - INFO - Training using device: cuda
2024-01-17 03:45 - INFO - Creating generators
2024-01-17 03:45 - INFO - The model has 651,257 trainable parameters
2024-01-17 03:45 - INFO - * Model:
2024-01-17 03:45 - INFO - * -----------
2024-01-17 03:45 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 03:45 - INFO - * -----------
2024-01-17 03:45 - INFO - Evaluating model based on: rocauc
2024-01-17 03:45 - INFO - Training..

2024-01-17 03:50 - INFO - ---------------------------------------------
2024-01-17 03:50 - INFO - Epoch: 01 | Time: 5m 28s
2024-01-17 03:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.59688
2024-01-17 03:50 - INFO - 	 Train Loss: 0.568
2024-01-17 03:50 - INFO - 	 Val. Loss: 0.549
2024-01-17 03:50 - INFO - 	 ROC-AUC: 0.597
2024-01-17 03:50 - INFO - 	 PR-AUC: 0.327
2024-01-17 03:50 - INFO - 	 Recall for 0.4 precision: 0.162
2024-01-17 03:50 - INFO - 	 Best Val. Loss: 0.549
2024-01-17 03:50 - INFO - 	 Best ROC-AUC: 0.597
2024-01-17 03:50 - INFO - 	 Best PR-AUC: 0.327
2024-01-17 03:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.567
2024-01-17 03:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.310
2024-01-17 03:50 - INFO - 	 Best Recall for 0.4 precision: 0.162
2024-01-17 03:50 - INFO - ---------------------------------------------
2024-01-17 03:57 - INFO - ---------------------------------------------
2024-01-17 03:57 - INFO - Epoch: 02 | Time: 6m 31s
2024-01-17 03:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.69947
2024-01-17 03:57 - INFO - 	 Train Loss: 0.528
2024-01-17 03:57 - INFO - 	 Val. Loss: 0.510
2024-01-17 03:57 - INFO - 	 ROC-AUC: 0.699
2024-01-17 03:57 - INFO - 	 PR-AUC: 0.422
2024-01-17 03:57 - INFO - 	 Recall for 0.4 precision: 0.532
2024-01-17 03:57 - INFO - 	 Best Val. Loss: 0.510
2024-01-17 03:57 - INFO - 	 Best ROC-AUC: 0.699
2024-01-17 03:57 - INFO - 	 Best PR-AUC: 0.422
2024-01-17 03:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.665
2024-01-17 03:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.389
2024-01-17 03:57 - INFO - 	 Best Recall for 0.4 precision: 0.532
2024-01-17 03:57 - INFO - ---------------------------------------------
2024-01-17 04:02 - INFO - ---------------------------------------------
2024-01-17 04:02 - INFO - Epoch: 03 | Time: 4m 49s
2024-01-17 04:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71252
2024-01-17 04:02 - INFO - 	 Train Loss: 0.506
2024-01-17 04:02 - INFO - 	 Val. Loss: 0.503
2024-01-17 04:02 - INFO - 	 ROC-AUC: 0.713
2024-01-17 04:02 - INFO - 	 PR-AUC: 0.433
2024-01-17 04:02 - INFO - 	 Recall for 0.4 precision: 0.591
2024-01-17 04:02 - INFO - 	 Best Val. Loss: 0.503
2024-01-17 04:02 - INFO - 	 Best ROC-AUC: 0.713
2024-01-17 04:02 - INFO - 	 Best PR-AUC: 0.433
2024-01-17 04:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.683
2024-01-17 04:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.408
2024-01-17 04:02 - INFO - 	 Best Recall for 0.4 precision: 0.591
2024-01-17 04:02 - INFO - ---------------------------------------------
2024-01-17 04:09 - INFO - ---------------------------------------------
2024-01-17 04:09 - INFO - Epoch: 04 | Time: 6m 49s
2024-01-17 04:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72197
2024-01-17 04:09 - INFO - 	 Train Loss: 0.497
2024-01-17 04:09 - INFO - 	 Val. Loss: 0.498
2024-01-17 04:09 - INFO - 	 ROC-AUC: 0.722
2024-01-17 04:09 - INFO - 	 PR-AUC: 0.439
2024-01-17 04:09 - INFO - 	 Recall for 0.4 precision: 0.620
2024-01-17 04:09 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 04:09 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 04:09 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 04:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.692
2024-01-17 04:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 04:09 - INFO - 	 Best Recall for 0.4 precision: 0.620
2024-01-17 04:09 - INFO - ---------------------------------------------
2024-01-17 04:15 - INFO - ---------------------------------------------
2024-01-17 04:15 - INFO - Epoch: 05 | Time: 6m 25s
2024-01-17 04:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72215
2024-01-17 04:15 - INFO - 	 Train Loss: 0.492
2024-01-17 04:15 - INFO - 	 Val. Loss: 0.499
2024-01-17 04:15 - INFO - 	 ROC-AUC: 0.722
2024-01-17 04:15 - INFO - 	 PR-AUC: 0.438
2024-01-17 04:15 - INFO - 	 Recall for 0.4 precision: 0.635
2024-01-17 04:15 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 04:15 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 04:15 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 04:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.697
2024-01-17 04:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 04:15 - INFO - 	 Best Recall for 0.4 precision: 0.635
2024-01-17 04:15 - INFO - ---------------------------------------------
2024-01-17 04:20 - INFO - ---------------------------------------------
2024-01-17 04:20 - INFO - Epoch: 06 | Time: 4m 49s
2024-01-17 04:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72714
2024-01-17 04:20 - INFO - 	 Train Loss: 0.489
2024-01-17 04:20 - INFO - 	 Val. Loss: 0.498
2024-01-17 04:20 - INFO - 	 ROC-AUC: 0.727
2024-01-17 04:20 - INFO - 	 PR-AUC: 0.453
2024-01-17 04:20 - INFO - 	 Recall for 0.4 precision: 0.641
2024-01-17 04:20 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 04:20 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 04:20 - INFO - 	 Best PR-AUC: 0.453
2024-01-17 04:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 04:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 04:20 - INFO - 	 Best Recall for 0.4 precision: 0.641
2024-01-17 04:20 - INFO - ---------------------------------------------
2024-01-17 04:27 - INFO - ---------------------------------------------
2024-01-17 04:27 - INFO - Epoch: 07 | Time: 6m 47s
2024-01-17 04:27 - INFO - 	 Train Loss: 0.487
2024-01-17 04:27 - INFO - 	 Val. Loss: 0.497
2024-01-17 04:27 - INFO - 	 ROC-AUC: 0.725
2024-01-17 04:27 - INFO - 	 PR-AUC: 0.443
2024-01-17 04:27 - INFO - 	 Recall for 0.4 precision: 0.637
2024-01-17 04:27 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 04:27 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 04:27 - INFO - 	 Best PR-AUC: 0.453
2024-01-17 04:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 04:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 04:27 - INFO - 	 Best Recall for 0.4 precision: 0.641
2024-01-17 04:27 - INFO - ---------------------------------------------
2024-01-17 04:34 - INFO - ---------------------------------------------
2024-01-17 04:34 - INFO - Epoch: 08 | Time: 6m 50s
2024-01-17 04:34 - INFO - 	 Train Loss: 0.485
2024-01-17 04:34 - INFO - 	 Val. Loss: 0.497
2024-01-17 04:34 - INFO - 	 ROC-AUC: 0.725
2024-01-17 04:34 - INFO - 	 PR-AUC: 0.438
2024-01-17 04:34 - INFO - 	 Recall for 0.4 precision: 0.638
2024-01-17 04:34 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 04:34 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 04:34 - INFO - 	 Best PR-AUC: 0.453
2024-01-17 04:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 04:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 04:34 - INFO - 	 Best Recall for 0.4 precision: 0.641
2024-01-17 04:34 - INFO - ---------------------------------------------
2024-01-17 04:40 - INFO - ---------------------------------------------
2024-01-17 04:40 - INFO - Epoch: 09 | Time: 6m 48s
2024-01-17 04:40 - INFO - 	 Train Loss: 0.484
2024-01-17 04:40 - INFO - 	 Val. Loss: 0.501
2024-01-17 04:40 - INFO - 	 ROC-AUC: 0.723
2024-01-17 04:40 - INFO - 	 PR-AUC: 0.439
2024-01-17 04:40 - INFO - 	 Recall for 0.4 precision: 0.631
2024-01-17 04:40 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 04:40 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 04:40 - INFO - 	 Best PR-AUC: 0.453
2024-01-17 04:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 04:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 04:40 - INFO - 	 Best Recall for 0.4 precision: 0.641
2024-01-17 04:40 - INFO - ---------------------------------------------
2024-01-17 04:51 - INFO - Fit the preprocessing pipeline
2024-01-17 04:51 - INFO - Training using device: cuda
2024-01-17 04:51 - INFO - Creating generators
2024-01-17 04:51 - INFO - The model has 651,257 trainable parameters
2024-01-17 04:51 - INFO - * Model:
2024-01-17 04:51 - INFO - * -----------
2024-01-17 04:51 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 04:51 - INFO - * -----------
2024-01-17 04:51 - INFO - Evaluating model based on: rocauc
2024-01-17 04:51 - INFO - Training..

2024-01-17 04:56 - INFO - ---------------------------------------------
2024-01-17 04:56 - INFO - Epoch: 01 | Time: 4m 35s
2024-01-17 04:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.62141
2024-01-17 04:56 - INFO - 	 Train Loss: 0.568
2024-01-17 04:56 - INFO - 	 Val. Loss: 0.555
2024-01-17 04:56 - INFO - 	 ROC-AUC: 0.621
2024-01-17 04:56 - INFO - 	 PR-AUC: 0.349
2024-01-17 04:56 - INFO - 	 Recall for 0.4 precision: 0.249
2024-01-17 04:56 - INFO - 	 Best Val. Loss: 0.555
2024-01-17 04:56 - INFO - 	 Best ROC-AUC: 0.621
2024-01-17 04:56 - INFO - 	 Best PR-AUC: 0.349
2024-01-17 04:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.609
2024-01-17 04:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.339
2024-01-17 04:56 - INFO - 	 Best Recall for 0.4 precision: 0.249
2024-01-17 04:56 - INFO - ---------------------------------------------
2024-01-17 05:02 - INFO - ---------------------------------------------
2024-01-17 05:02 - INFO - Epoch: 02 | Time: 6m 37s
2024-01-17 05:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70872
2024-01-17 05:02 - INFO - 	 Train Loss: 0.523
2024-01-17 05:02 - INFO - 	 Val. Loss: 0.505
2024-01-17 05:02 - INFO - 	 ROC-AUC: 0.709
2024-01-17 05:02 - INFO - 	 PR-AUC: 0.428
2024-01-17 05:02 - INFO - 	 Recall for 0.4 precision: 0.582
2024-01-17 05:02 - INFO - 	 Best Val. Loss: 0.505
2024-01-17 05:02 - INFO - 	 Best ROC-AUC: 0.709
2024-01-17 05:02 - INFO - 	 Best PR-AUC: 0.428
2024-01-17 05:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.672
2024-01-17 05:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.393
2024-01-17 05:02 - INFO - 	 Best Recall for 0.4 precision: 0.582
2024-01-17 05:02 - INFO - ---------------------------------------------
2024-01-17 05:09 - INFO - ---------------------------------------------
2024-01-17 05:09 - INFO - Epoch: 03 | Time: 6m 10s
2024-01-17 05:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71244
2024-01-17 05:09 - INFO - 	 Train Loss: 0.504
2024-01-17 05:09 - INFO - 	 Val. Loss: 0.502
2024-01-17 05:09 - INFO - 	 ROC-AUC: 0.712
2024-01-17 05:09 - INFO - 	 PR-AUC: 0.432
2024-01-17 05:09 - INFO - 	 Recall for 0.4 precision: 0.577
2024-01-17 05:09 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 05:09 - INFO - 	 Best ROC-AUC: 0.712
2024-01-17 05:09 - INFO - 	 Best PR-AUC: 0.432
2024-01-17 05:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.683
2024-01-17 05:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.404
2024-01-17 05:09 - INFO - 	 Best Recall for 0.4 precision: 0.582
2024-01-17 05:09 - INFO - ---------------------------------------------
2024-01-17 05:14 - INFO - ---------------------------------------------
2024-01-17 05:14 - INFO - Epoch: 04 | Time: 5m 37s
2024-01-17 05:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71285
2024-01-17 05:14 - INFO - 	 Train Loss: 0.497
2024-01-17 05:14 - INFO - 	 Val. Loss: 0.505
2024-01-17 05:14 - INFO - 	 ROC-AUC: 0.713
2024-01-17 05:14 - INFO - 	 PR-AUC: 0.430
2024-01-17 05:14 - INFO - 	 Recall for 0.4 precision: 0.585
2024-01-17 05:14 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 05:14 - INFO - 	 Best ROC-AUC: 0.713
2024-01-17 05:14 - INFO - 	 Best PR-AUC: 0.432
2024-01-17 05:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.683
2024-01-17 05:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.404
2024-01-17 05:14 - INFO - 	 Best Recall for 0.4 precision: 0.585
2024-01-17 05:14 - INFO - ---------------------------------------------
2024-01-17 05:21 - INFO - ---------------------------------------------
2024-01-17 05:21 - INFO - Epoch: 05 | Time: 6m 33s
2024-01-17 05:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7194
2024-01-17 05:21 - INFO - 	 Train Loss: 0.492
2024-01-17 05:21 - INFO - 	 Val. Loss: 0.499
2024-01-17 05:21 - INFO - 	 ROC-AUC: 0.719
2024-01-17 05:21 - INFO - 	 PR-AUC: 0.435
2024-01-17 05:21 - INFO - 	 Recall for 0.4 precision: 0.610
2024-01-17 05:21 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 05:21 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 05:21 - INFO - 	 Best PR-AUC: 0.435
2024-01-17 05:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.688
2024-01-17 05:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 05:21 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 05:21 - INFO - ---------------------------------------------
2024-01-17 05:27 - INFO - ---------------------------------------------
2024-01-17 05:27 - INFO - Epoch: 06 | Time: 6m 22s
2024-01-17 05:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71965
2024-01-17 05:27 - INFO - 	 Train Loss: 0.489
2024-01-17 05:27 - INFO - 	 Val. Loss: 0.501
2024-01-17 05:27 - INFO - 	 ROC-AUC: 0.720
2024-01-17 05:27 - INFO - 	 PR-AUC: 0.436
2024-01-17 05:27 - INFO - 	 Recall for 0.4 precision: 0.606
2024-01-17 05:27 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 05:27 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 05:27 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 05:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.691
2024-01-17 05:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-17 05:27 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 05:27 - INFO - ---------------------------------------------
2024-01-17 05:33 - INFO - ---------------------------------------------
2024-01-17 05:33 - INFO - Epoch: 07 | Time: 5m 20s
2024-01-17 05:33 - INFO - 	 Train Loss: 0.487
2024-01-17 05:33 - INFO - 	 Val. Loss: 0.499
2024-01-17 05:33 - INFO - 	 ROC-AUC: 0.718
2024-01-17 05:33 - INFO - 	 PR-AUC: 0.435
2024-01-17 05:33 - INFO - 	 Recall for 0.4 precision: 0.613
2024-01-17 05:33 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 05:33 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 05:33 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 05:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.691
2024-01-17 05:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-17 05:33 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 05:33 - INFO - ---------------------------------------------
2024-01-17 05:39 - INFO - ---------------------------------------------
2024-01-17 05:39 - INFO - Epoch: 08 | Time: 6m 49s
2024-01-17 05:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72452
2024-01-17 05:39 - INFO - 	 Train Loss: 0.485
2024-01-17 05:39 - INFO - 	 Val. Loss: 0.498
2024-01-17 05:39 - INFO - 	 ROC-AUC: 0.725
2024-01-17 05:39 - INFO - 	 PR-AUC: 0.440
2024-01-17 05:39 - INFO - 	 Recall for 0.4 precision: 0.629
2024-01-17 05:39 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 05:39 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 05:39 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 05:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 05:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.423
2024-01-17 05:39 - INFO - 	 Best Recall for 0.4 precision: 0.629
2024-01-17 05:39 - INFO - ---------------------------------------------
2024-01-17 05:46 - INFO - ---------------------------------------------
2024-01-17 05:46 - INFO - Epoch: 09 | Time: 6m 22s
2024-01-17 05:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7257
2024-01-17 05:46 - INFO - 	 Train Loss: 0.484
2024-01-17 05:46 - INFO - 	 Val. Loss: 0.495
2024-01-17 05:46 - INFO - 	 ROC-AUC: 0.726
2024-01-17 05:46 - INFO - 	 PR-AUC: 0.446
2024-01-17 05:46 - INFO - 	 Recall for 0.4 precision: 0.646
2024-01-17 05:46 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 05:46 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 05:46 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 05:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.712
2024-01-17 05:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.437
2024-01-17 05:46 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 05:46 - INFO - ---------------------------------------------
2024-01-17 05:51 - INFO - ---------------------------------------------
2024-01-17 05:51 - INFO - Epoch: 10 | Time: 4m 59s
2024-01-17 05:51 - INFO - 	 Train Loss: 0.483
2024-01-17 05:51 - INFO - 	 Val. Loss: 0.495
2024-01-17 05:51 - INFO - 	 ROC-AUC: 0.726
2024-01-17 05:51 - INFO - 	 PR-AUC: 0.447
2024-01-17 05:51 - INFO - 	 Recall for 0.4 precision: 0.634
2024-01-17 05:51 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 05:51 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 05:51 - INFO - 	 Best PR-AUC: 0.447
2024-01-17 05:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.712
2024-01-17 05:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.435
2024-01-17 05:51 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 05:51 - INFO - ---------------------------------------------
2024-01-17 05:55 - INFO - Fit the preprocessing pipeline
2024-01-17 05:55 - INFO - Training using device: cuda
2024-01-17 05:55 - INFO - Creating generators
2024-01-17 05:55 - INFO - The model has 651,257 trainable parameters
2024-01-17 05:55 - INFO - * Model:
2024-01-17 05:55 - INFO - * -----------
2024-01-17 05:55 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 05:55 - INFO - * -----------
2024-01-17 05:55 - INFO - Evaluating model based on: rocauc
2024-01-17 05:55 - INFO - Training..

2024-01-17 06:01 - INFO - ---------------------------------------------
2024-01-17 06:01 - INFO - Epoch: 01 | Time: 6m 14s
2024-01-17 06:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.59008
2024-01-17 06:01 - INFO - 	 Train Loss: 0.570
2024-01-17 06:01 - INFO - 	 Val. Loss: 0.552
2024-01-17 06:01 - INFO - 	 ROC-AUC: 0.590
2024-01-17 06:01 - INFO - 	 PR-AUC: 0.319
2024-01-17 06:01 - INFO - 	 Recall for 0.4 precision: 0.139
2024-01-17 06:01 - INFO - 	 Best Val. Loss: 0.552
2024-01-17 06:01 - INFO - 	 Best ROC-AUC: 0.590
2024-01-17 06:01 - INFO - 	 Best PR-AUC: 0.319
2024-01-17 06:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.569
2024-01-17 06:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.307
2024-01-17 06:01 - INFO - 	 Best Recall for 0.4 precision: 0.139
2024-01-17 06:01 - INFO - ---------------------------------------------
2024-01-17 06:07 - INFO - ---------------------------------------------
2024-01-17 06:07 - INFO - Epoch: 02 | Time: 5m 23s
2024-01-17 06:07 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70164
2024-01-17 06:07 - INFO - 	 Train Loss: 0.529
2024-01-17 06:07 - INFO - 	 Val. Loss: 0.508
2024-01-17 06:07 - INFO - 	 ROC-AUC: 0.702
2024-01-17 06:07 - INFO - 	 PR-AUC: 0.424
2024-01-17 06:07 - INFO - 	 Recall for 0.4 precision: 0.544
2024-01-17 06:07 - INFO - 	 Best Val. Loss: 0.508
2024-01-17 06:07 - INFO - 	 Best ROC-AUC: 0.702
2024-01-17 06:07 - INFO - 	 Best PR-AUC: 0.424
2024-01-17 06:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.666
2024-01-17 06:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.385
2024-01-17 06:07 - INFO - 	 Best Recall for 0.4 precision: 0.544
2024-01-17 06:07 - INFO - ---------------------------------------------
2024-01-17 06:14 - INFO - ---------------------------------------------
2024-01-17 06:14 - INFO - Epoch: 03 | Time: 7m 28s
2024-01-17 06:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71737
2024-01-17 06:14 - INFO - 	 Train Loss: 0.505
2024-01-17 06:14 - INFO - 	 Val. Loss: 0.500
2024-01-17 06:14 - INFO - 	 ROC-AUC: 0.717
2024-01-17 06:14 - INFO - 	 PR-AUC: 0.442
2024-01-17 06:14 - INFO - 	 Recall for 0.4 precision: 0.595
2024-01-17 06:14 - INFO - 	 Best Val. Loss: 0.500
2024-01-17 06:14 - INFO - 	 Best ROC-AUC: 0.717
2024-01-17 06:14 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 06:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.688
2024-01-17 06:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 06:14 - INFO - 	 Best Recall for 0.4 precision: 0.595
2024-01-17 06:14 - INFO - ---------------------------------------------
2024-01-17 06:21 - INFO - ---------------------------------------------
2024-01-17 06:21 - INFO - Epoch: 04 | Time: 6m 33s
2024-01-17 06:21 - INFO - 	 Train Loss: 0.497
2024-01-17 06:21 - INFO - 	 Val. Loss: 0.500
2024-01-17 06:21 - INFO - 	 ROC-AUC: 0.717
2024-01-17 06:21 - INFO - 	 PR-AUC: 0.437
2024-01-17 06:21 - INFO - 	 Recall for 0.4 precision: 0.601
2024-01-17 06:21 - INFO - 	 Best Val. Loss: 0.500
2024-01-17 06:21 - INFO - 	 Best ROC-AUC: 0.717
2024-01-17 06:21 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 06:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.688
2024-01-17 06:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 06:21 - INFO - 	 Best Recall for 0.4 precision: 0.601
2024-01-17 06:21 - INFO - ---------------------------------------------
2024-01-17 06:27 - INFO - ---------------------------------------------
2024-01-17 06:27 - INFO - Epoch: 05 | Time: 6m 23s
2024-01-17 06:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7199
2024-01-17 06:27 - INFO - 	 Train Loss: 0.493
2024-01-17 06:27 - INFO - 	 Val. Loss: 0.498
2024-01-17 06:27 - INFO - 	 ROC-AUC: 0.720
2024-01-17 06:27 - INFO - 	 PR-AUC: 0.437
2024-01-17 06:27 - INFO - 	 Recall for 0.4 precision: 0.613
2024-01-17 06:27 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 06:27 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 06:27 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 06:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.697
2024-01-17 06:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 06:27 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 06:27 - INFO - ---------------------------------------------
2024-01-17 06:33 - INFO - ---------------------------------------------
2024-01-17 06:33 - INFO - Epoch: 06 | Time: 5m 43s
2024-01-17 06:33 - INFO - 	 Train Loss: 0.489
2024-01-17 06:33 - INFO - 	 Val. Loss: 0.499
2024-01-17 06:33 - INFO - 	 ROC-AUC: 0.719
2024-01-17 06:33 - INFO - 	 PR-AUC: 0.435
2024-01-17 06:33 - INFO - 	 Recall for 0.4 precision: 0.612
2024-01-17 06:33 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 06:33 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 06:33 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 06:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.697
2024-01-17 06:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 06:33 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 06:33 - INFO - ---------------------------------------------
2024-01-17 06:39 - INFO - ---------------------------------------------
2024-01-17 06:39 - INFO - Epoch: 07 | Time: 6m 23s
2024-01-17 06:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72142
2024-01-17 06:39 - INFO - 	 Train Loss: 0.487
2024-01-17 06:39 - INFO - 	 Val. Loss: 0.498
2024-01-17 06:39 - INFO - 	 ROC-AUC: 0.721
2024-01-17 06:39 - INFO - 	 PR-AUC: 0.439
2024-01-17 06:39 - INFO - 	 Recall for 0.4 precision: 0.622
2024-01-17 06:39 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 06:39 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 06:39 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 06:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 06:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.412
2024-01-17 06:39 - INFO - 	 Best Recall for 0.4 precision: 0.622
2024-01-17 06:39 - INFO - ---------------------------------------------
2024-01-17 06:47 - INFO - ---------------------------------------------
2024-01-17 06:47 - INFO - Epoch: 08 | Time: 7m 11s
2024-01-17 06:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72806
2024-01-17 06:47 - INFO - 	 Train Loss: 0.485
2024-01-17 06:47 - INFO - 	 Val. Loss: 0.495
2024-01-17 06:47 - INFO - 	 ROC-AUC: 0.728
2024-01-17 06:47 - INFO - 	 PR-AUC: 0.449
2024-01-17 06:47 - INFO - 	 Recall for 0.4 precision: 0.644
2024-01-17 06:47 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 06:47 - INFO - 	 Best ROC-AUC: 0.728
2024-01-17 06:47 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 06:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 06:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.431
2024-01-17 06:47 - INFO - 	 Best Recall for 0.4 precision: 0.644
2024-01-17 06:47 - INFO - ---------------------------------------------
2024-01-17 06:52 - INFO - ---------------------------------------------
2024-01-17 06:52 - INFO - Epoch: 09 | Time: 5m 29s
2024-01-17 06:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72916
2024-01-17 06:52 - INFO - 	 Train Loss: 0.484
2024-01-17 06:52 - INFO - 	 Val. Loss: 0.496
2024-01-17 06:52 - INFO - 	 ROC-AUC: 0.729
2024-01-17 06:52 - INFO - 	 PR-AUC: 0.448
2024-01-17 06:52 - INFO - 	 Recall for 0.4 precision: 0.662
2024-01-17 06:52 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 06:52 - INFO - 	 Best ROC-AUC: 0.729
2024-01-17 06:52 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 06:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.705
2024-01-17 06:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.431
2024-01-17 06:52 - INFO - 	 Best Recall for 0.4 precision: 0.662
2024-01-17 06:52 - INFO - ---------------------------------------------
2024-01-17 06:58 - INFO - ---------------------------------------------
2024-01-17 06:58 - INFO - Epoch: 10 | Time: 5m 33s
2024-01-17 06:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72929
2024-01-17 06:58 - INFO - 	 Train Loss: 0.483
2024-01-17 06:58 - INFO - 	 Val. Loss: 0.494
2024-01-17 06:58 - INFO - 	 ROC-AUC: 0.729
2024-01-17 06:58 - INFO - 	 PR-AUC: 0.448
2024-01-17 06:58 - INFO - 	 Recall for 0.4 precision: 0.658
2024-01-17 06:58 - INFO - 	 Best Val. Loss: 0.494
2024-01-17 06:58 - INFO - 	 Best ROC-AUC: 0.729
2024-01-17 06:58 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 06:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.704
2024-01-17 06:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.431
2024-01-17 06:58 - INFO - 	 Best Recall for 0.4 precision: 0.662
2024-01-17 06:58 - INFO - ---------------------------------------------
2024-01-17 07:03 - INFO - Fit the preprocessing pipeline
2024-01-17 07:03 - INFO - Training using device: cuda
2024-01-17 07:03 - INFO - Creating generators
2024-01-17 07:03 - INFO - The model has 651,257 trainable parameters
2024-01-17 07:03 - INFO - * Model:
2024-01-17 07:03 - INFO - * -----------
2024-01-17 07:03 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 07:03 - INFO - * -----------
2024-01-17 07:03 - INFO - Evaluating model based on: rocauc
2024-01-17 07:03 - INFO - Training..

2024-01-17 07:07 - INFO - ---------------------------------------------
2024-01-17 07:07 - INFO - Epoch: 01 | Time: 4m 47s
2024-01-17 07:07 - INFO - 	 New best val_rocauc loss was found, current best value is 0.62174
2024-01-17 07:07 - INFO - 	 Train Loss: 0.566
2024-01-17 07:07 - INFO - 	 Val. Loss: 0.537
2024-01-17 07:07 - INFO - 	 ROC-AUC: 0.622
2024-01-17 07:07 - INFO - 	 PR-AUC: 0.348
2024-01-17 07:07 - INFO - 	 Recall for 0.4 precision: 0.001
2024-01-17 07:07 - INFO - 	 Best Val. Loss: 0.537
2024-01-17 07:07 - INFO - 	 Best ROC-AUC: 0.622
2024-01-17 07:07 - INFO - 	 Best PR-AUC: 0.348
2024-01-17 07:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.598
2024-01-17 07:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.334
2024-01-17 07:07 - INFO - 	 Best Recall for 0.4 precision: 0.001
2024-01-17 07:07 - INFO - ---------------------------------------------
2024-01-17 07:14 - INFO - ---------------------------------------------
2024-01-17 07:14 - INFO - Epoch: 02 | Time: 6m 49s
2024-01-17 07:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70014
2024-01-17 07:14 - INFO - 	 Train Loss: 0.523
2024-01-17 07:14 - INFO - 	 Val. Loss: 0.510
2024-01-17 07:14 - INFO - 	 ROC-AUC: 0.700
2024-01-17 07:14 - INFO - 	 PR-AUC: 0.417
2024-01-17 07:14 - INFO - 	 Recall for 0.4 precision: 0.545
2024-01-17 07:14 - INFO - 	 Best Val. Loss: 0.510
2024-01-17 07:14 - INFO - 	 Best ROC-AUC: 0.700
2024-01-17 07:14 - INFO - 	 Best PR-AUC: 0.417
2024-01-17 07:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.662
2024-01-17 07:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.383
2024-01-17 07:14 - INFO - 	 Best Recall for 0.4 precision: 0.545
2024-01-17 07:14 - INFO - ---------------------------------------------
2024-01-17 07:20 - INFO - ---------------------------------------------
2024-01-17 07:20 - INFO - Epoch: 03 | Time: 5m 22s
2024-01-17 07:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70681
2024-01-17 07:20 - INFO - 	 Train Loss: 0.506
2024-01-17 07:20 - INFO - 	 Val. Loss: 0.505
2024-01-17 07:20 - INFO - 	 ROC-AUC: 0.707
2024-01-17 07:20 - INFO - 	 PR-AUC: 0.421
2024-01-17 07:20 - INFO - 	 Recall for 0.4 precision: 0.570
2024-01-17 07:20 - INFO - 	 Best Val. Loss: 0.505
2024-01-17 07:20 - INFO - 	 Best ROC-AUC: 0.707
2024-01-17 07:20 - INFO - 	 Best PR-AUC: 0.421
2024-01-17 07:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.674
2024-01-17 07:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.396
2024-01-17 07:20 - INFO - 	 Best Recall for 0.4 precision: 0.570
2024-01-17 07:20 - INFO - ---------------------------------------------
2024-01-17 07:26 - INFO - ---------------------------------------------
2024-01-17 07:26 - INFO - Epoch: 04 | Time: 6m 47s
2024-01-17 07:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71792
2024-01-17 07:26 - INFO - 	 Train Loss: 0.499
2024-01-17 07:26 - INFO - 	 Val. Loss: 0.502
2024-01-17 07:26 - INFO - 	 ROC-AUC: 0.718
2024-01-17 07:26 - INFO - 	 PR-AUC: 0.434
2024-01-17 07:26 - INFO - 	 Recall for 0.4 precision: 0.613
2024-01-17 07:26 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 07:26 - INFO - 	 Best ROC-AUC: 0.718
2024-01-17 07:26 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 07:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.698
2024-01-17 07:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.423
2024-01-17 07:26 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 07:26 - INFO - ---------------------------------------------
2024-01-17 07:33 - INFO - ---------------------------------------------
2024-01-17 07:33 - INFO - Epoch: 05 | Time: 6m 47s
2024-01-17 07:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71814
2024-01-17 07:33 - INFO - 	 Train Loss: 0.493
2024-01-17 07:33 - INFO - 	 Val. Loss: 0.503
2024-01-17 07:33 - INFO - 	 ROC-AUC: 0.718
2024-01-17 07:33 - INFO - 	 PR-AUC: 0.434
2024-01-17 07:33 - INFO - 	 Recall for 0.4 precision: 0.608
2024-01-17 07:33 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 07:33 - INFO - 	 Best ROC-AUC: 0.718
2024-01-17 07:33 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 07:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 07:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 07:33 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 07:33 - INFO - ---------------------------------------------
2024-01-17 07:38 - INFO - ---------------------------------------------
2024-01-17 07:38 - INFO - Epoch: 06 | Time: 4m 51s
2024-01-17 07:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71912
2024-01-17 07:38 - INFO - 	 Train Loss: 0.489
2024-01-17 07:38 - INFO - 	 Val. Loss: 0.501
2024-01-17 07:38 - INFO - 	 ROC-AUC: 0.719
2024-01-17 07:38 - INFO - 	 PR-AUC: 0.433
2024-01-17 07:38 - INFO - 	 Recall for 0.4 precision: 0.607
2024-01-17 07:38 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 07:38 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 07:38 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 07:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 07:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 07:38 - INFO - 	 Best Recall for 0.4 precision: 0.613
2024-01-17 07:38 - INFO - ---------------------------------------------
2024-01-17 07:45 - INFO - ---------------------------------------------
2024-01-17 07:45 - INFO - Epoch: 07 | Time: 6m 25s
2024-01-17 07:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72614
2024-01-17 07:45 - INFO - 	 Train Loss: 0.487
2024-01-17 07:45 - INFO - 	 Val. Loss: 0.498
2024-01-17 07:45 - INFO - 	 ROC-AUC: 0.726
2024-01-17 07:45 - INFO - 	 PR-AUC: 0.436
2024-01-17 07:45 - INFO - 	 Recall for 0.4 precision: 0.649
2024-01-17 07:45 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 07:45 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 07:45 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 07:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 07:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 07:45 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 07:45 - INFO - ---------------------------------------------
2024-01-17 07:50 - INFO - ---------------------------------------------
2024-01-17 07:50 - INFO - Epoch: 08 | Time: 5m 43s
2024-01-17 07:50 - INFO - 	 Train Loss: 0.486
2024-01-17 07:50 - INFO - 	 Val. Loss: 0.498
2024-01-17 07:50 - INFO - 	 ROC-AUC: 0.722
2024-01-17 07:50 - INFO - 	 PR-AUC: 0.432
2024-01-17 07:50 - INFO - 	 Recall for 0.4 precision: 0.633
2024-01-17 07:50 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 07:50 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 07:50 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 07:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 07:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.434
2024-01-17 07:50 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 07:50 - INFO - ---------------------------------------------
2024-01-17 07:57 - INFO - ---------------------------------------------
2024-01-17 07:57 - INFO - Epoch: 09 | Time: 6m 28s
2024-01-17 07:57 - INFO - 	 Train Loss: 0.485
2024-01-17 07:57 - INFO - 	 Val. Loss: 0.497
2024-01-17 07:57 - INFO - 	 ROC-AUC: 0.725
2024-01-17 07:57 - INFO - 	 PR-AUC: 0.437
2024-01-17 07:57 - INFO - 	 Recall for 0.4 precision: 0.651
2024-01-17 07:57 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 07:57 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 07:57 - INFO - 	 Best PR-AUC: 0.437
2024-01-17 07:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 07:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.439
2024-01-17 07:57 - INFO - 	 Best Recall for 0.4 precision: 0.651
2024-01-17 07:57 - INFO - ---------------------------------------------
2024-01-17 08:02 - INFO - ---------------------------------------------
2024-01-17 08:02 - INFO - Epoch: 10 | Time: 5m 27s
2024-01-17 08:02 - INFO - 	 Train Loss: 0.484
2024-01-17 08:02 - INFO - 	 Val. Loss: 0.498
2024-01-17 08:02 - INFO - 	 ROC-AUC: 0.723
2024-01-17 08:02 - INFO - 	 PR-AUC: 0.436
2024-01-17 08:02 - INFO - 	 Recall for 0.4 precision: 0.622
2024-01-17 08:02 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 08:02 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 08:02 - INFO - 	 Best PR-AUC: 0.437
2024-01-17 08:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 08:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.439
2024-01-17 08:02 - INFO - 	 Best Recall for 0.4 precision: 0.651
2024-01-17 08:02 - INFO - ---------------------------------------------
2024-01-17 08:07 - INFO - Fit the preprocessing pipeline
2024-01-17 08:07 - INFO - Training using device: cuda
2024-01-17 08:07 - INFO - Creating generators
2024-01-17 08:07 - INFO - The model has 651,257 trainable parameters
2024-01-17 08:07 - INFO - * Model:
2024-01-17 08:07 - INFO - * -----------
2024-01-17 08:07 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 08:07 - INFO - * -----------
2024-01-17 08:07 - INFO - Evaluating model based on: rocauc
2024-01-17 08:07 - INFO - Training..

2024-01-17 08:12 - INFO - ---------------------------------------------
2024-01-17 08:12 - INFO - Epoch: 01 | Time: 4m 19s
2024-01-17 08:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.61543
2024-01-17 08:12 - INFO - 	 Train Loss: 0.562
2024-01-17 08:12 - INFO - 	 Val. Loss: 0.543
2024-01-17 08:12 - INFO - 	 ROC-AUC: 0.615
2024-01-17 08:12 - INFO - 	 PR-AUC: 0.338
2024-01-17 08:12 - INFO - 	 Recall for 0.4 precision: 0.178
2024-01-17 08:12 - INFO - 	 Best Val. Loss: 0.543
2024-01-17 08:12 - INFO - 	 Best ROC-AUC: 0.615
2024-01-17 08:12 - INFO - 	 Best PR-AUC: 0.338
2024-01-17 08:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.588
2024-01-17 08:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.322
2024-01-17 08:12 - INFO - 	 Best Recall for 0.4 precision: 0.178
2024-01-17 08:12 - INFO - ---------------------------------------------
2024-01-17 08:18 - INFO - ---------------------------------------------
2024-01-17 08:18 - INFO - Epoch: 02 | Time: 6m 53s
2024-01-17 08:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71672
2024-01-17 08:18 - INFO - 	 Train Loss: 0.516
2024-01-17 08:18 - INFO - 	 Val. Loss: 0.502
2024-01-17 08:18 - INFO - 	 ROC-AUC: 0.717
2024-01-17 08:18 - INFO - 	 PR-AUC: 0.439
2024-01-17 08:18 - INFO - 	 Recall for 0.4 precision: 0.609
2024-01-17 08:18 - INFO - 	 Best Val. Loss: 0.502
2024-01-17 08:18 - INFO - 	 Best ROC-AUC: 0.717
2024-01-17 08:18 - INFO - 	 Best PR-AUC: 0.439
2024-01-17 08:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.684
2024-01-17 08:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.405
2024-01-17 08:18 - INFO - 	 Best Recall for 0.4 precision: 0.609
2024-01-17 08:18 - INFO - ---------------------------------------------
2024-01-17 08:25 - INFO - ---------------------------------------------
2024-01-17 08:25 - INFO - Epoch: 03 | Time: 6m 56s
2024-01-17 08:25 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71845
2024-01-17 08:25 - INFO - 	 Train Loss: 0.500
2024-01-17 08:25 - INFO - 	 Val. Loss: 0.500
2024-01-17 08:25 - INFO - 	 ROC-AUC: 0.718
2024-01-17 08:25 - INFO - 	 PR-AUC: 0.440
2024-01-17 08:25 - INFO - 	 Recall for 0.4 precision: 0.617
2024-01-17 08:25 - INFO - 	 Best Val. Loss: 0.500
2024-01-17 08:25 - INFO - 	 Best ROC-AUC: 0.718
2024-01-17 08:25 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 08:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-17 08:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.410
2024-01-17 08:25 - INFO - 	 Best Recall for 0.4 precision: 0.617
2024-01-17 08:25 - INFO - ---------------------------------------------
2024-01-17 08:32 - INFO - ---------------------------------------------
2024-01-17 08:32 - INFO - Epoch: 04 | Time: 6m 20s
2024-01-17 08:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72323
2024-01-17 08:32 - INFO - 	 Train Loss: 0.494
2024-01-17 08:32 - INFO - 	 Val. Loss: 0.497
2024-01-17 08:32 - INFO - 	 ROC-AUC: 0.723
2024-01-17 08:32 - INFO - 	 PR-AUC: 0.446
2024-01-17 08:32 - INFO - 	 Recall for 0.4 precision: 0.635
2024-01-17 08:32 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 08:32 - INFO - 	 Best ROC-AUC: 0.723
2024-01-17 08:32 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 08:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-17 08:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 08:32 - INFO - 	 Best Recall for 0.4 precision: 0.635
2024-01-17 08:32 - INFO - ---------------------------------------------
2024-01-17 08:39 - INFO - ---------------------------------------------
2024-01-17 08:39 - INFO - Epoch: 05 | Time: 6m 51s
2024-01-17 08:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72356
2024-01-17 08:39 - INFO - 	 Train Loss: 0.490
2024-01-17 08:39 - INFO - 	 Val. Loss: 0.497
2024-01-17 08:39 - INFO - 	 ROC-AUC: 0.724
2024-01-17 08:39 - INFO - 	 PR-AUC: 0.443
2024-01-17 08:39 - INFO - 	 Recall for 0.4 precision: 0.626
2024-01-17 08:39 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 08:39 - INFO - 	 Best ROC-AUC: 0.724
2024-01-17 08:39 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 08:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 08:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 08:39 - INFO - 	 Best Recall for 0.4 precision: 0.635
2024-01-17 08:39 - INFO - ---------------------------------------------
2024-01-17 08:45 - INFO - ---------------------------------------------
2024-01-17 08:45 - INFO - Epoch: 06 | Time: 6m 5s
2024-01-17 08:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72461
2024-01-17 08:45 - INFO - 	 Train Loss: 0.487
2024-01-17 08:45 - INFO - 	 Val. Loss: 0.498
2024-01-17 08:45 - INFO - 	 ROC-AUC: 0.725
2024-01-17 08:45 - INFO - 	 PR-AUC: 0.446
2024-01-17 08:45 - INFO - 	 Recall for 0.4 precision: 0.642
2024-01-17 08:45 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 08:45 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 08:45 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 08:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 08:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 08:45 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 08:45 - INFO - ---------------------------------------------
2024-01-17 08:51 - INFO - ---------------------------------------------
2024-01-17 08:51 - INFO - Epoch: 07 | Time: 6m 23s
2024-01-17 08:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7263
2024-01-17 08:51 - INFO - 	 Train Loss: 0.486
2024-01-17 08:51 - INFO - 	 Val. Loss: 0.495
2024-01-17 08:51 - INFO - 	 ROC-AUC: 0.726
2024-01-17 08:51 - INFO - 	 PR-AUC: 0.449
2024-01-17 08:51 - INFO - 	 Recall for 0.4 precision: 0.641
2024-01-17 08:51 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 08:51 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 08:51 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 08:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 08:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 08:51 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 08:51 - INFO - ---------------------------------------------
2024-01-17 08:57 - INFO - ---------------------------------------------
2024-01-17 08:57 - INFO - Epoch: 08 | Time: 5m 59s
2024-01-17 08:57 - INFO - 	 Train Loss: 0.484
2024-01-17 08:57 - INFO - 	 Val. Loss: 0.497
2024-01-17 08:57 - INFO - 	 ROC-AUC: 0.724
2024-01-17 08:57 - INFO - 	 PR-AUC: 0.444
2024-01-17 08:57 - INFO - 	 Recall for 0.4 precision: 0.628
2024-01-17 08:57 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 08:57 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 08:57 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 08:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 08:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 08:57 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 08:57 - INFO - ---------------------------------------------
2024-01-17 09:04 - INFO - ---------------------------------------------
2024-01-17 09:04 - INFO - Epoch: 09 | Time: 7m 14s
2024-01-17 09:04 - INFO - 	 Train Loss: 0.483
2024-01-17 09:04 - INFO - 	 Val. Loss: 0.498
2024-01-17 09:04 - INFO - 	 ROC-AUC: 0.722
2024-01-17 09:04 - INFO - 	 PR-AUC: 0.445
2024-01-17 09:04 - INFO - 	 Recall for 0.4 precision: 0.630
2024-01-17 09:04 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 09:04 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 09:04 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 09:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 09:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 09:04 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 09:04 - INFO - ---------------------------------------------
2024-01-17 09:11 - INFO - ---------------------------------------------
2024-01-17 09:11 - INFO - Epoch: 10 | Time: 6m 19s
2024-01-17 09:11 - INFO - 	 Train Loss: 0.481
2024-01-17 09:11 - INFO - 	 Val. Loss: 0.498
2024-01-17 09:11 - INFO - 	 ROC-AUC: 0.723
2024-01-17 09:11 - INFO - 	 PR-AUC: 0.446
2024-01-17 09:11 - INFO - 	 Recall for 0.4 precision: 0.633
2024-01-17 09:11 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 09:11 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 09:11 - INFO - 	 Best PR-AUC: 0.449
2024-01-17 09:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 09:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 09:11 - INFO - 	 Best Recall for 0.4 precision: 0.642
2024-01-17 09:11 - INFO - ---------------------------------------------
2024-01-17 09:16 - INFO - Fit the preprocessing pipeline
2024-01-17 09:16 - INFO - Training using device: cuda
2024-01-17 09:16 - INFO - Creating generators
2024-01-17 09:16 - INFO - The model has 651,257 trainable parameters
2024-01-17 09:16 - INFO - * Model:
2024-01-17 09:16 - INFO - * -----------
2024-01-17 09:16 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 09:16 - INFO - * -----------
2024-01-17 09:16 - INFO - Evaluating model based on: rocauc
2024-01-17 09:16 - INFO - Training..

2024-01-17 09:23 - INFO - ---------------------------------------------
2024-01-17 09:23 - INFO - Epoch: 01 | Time: 6m 58s
2024-01-17 09:23 - INFO - 	 New best val_rocauc loss was found, current best value is 0.60283
2024-01-17 09:23 - INFO - 	 Train Loss: 0.568
2024-01-17 09:23 - INFO - 	 Val. Loss: 0.549
2024-01-17 09:23 - INFO - 	 ROC-AUC: 0.603
2024-01-17 09:23 - INFO - 	 PR-AUC: 0.332
2024-01-17 09:23 - INFO - 	 Recall for 0.4 precision: 0.186
2024-01-17 09:23 - INFO - 	 Best Val. Loss: 0.549
2024-01-17 09:23 - INFO - 	 Best ROC-AUC: 0.603
2024-01-17 09:23 - INFO - 	 Best PR-AUC: 0.332
2024-01-17 09:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.572
2024-01-17 09:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.309
2024-01-17 09:23 - INFO - 	 Best Recall for 0.4 precision: 0.186
2024-01-17 09:23 - INFO - ---------------------------------------------
2024-01-17 09:30 - INFO - ---------------------------------------------
2024-01-17 09:30 - INFO - Epoch: 02 | Time: 6m 47s
2024-01-17 09:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71024
2024-01-17 09:30 - INFO - 	 Train Loss: 0.524
2024-01-17 09:30 - INFO - 	 Val. Loss: 0.523
2024-01-17 09:30 - INFO - 	 ROC-AUC: 0.710
2024-01-17 09:30 - INFO - 	 PR-AUC: 0.431
2024-01-17 09:30 - INFO - 	 Recall for 0.4 precision: 0.572
2024-01-17 09:30 - INFO - 	 Best Val. Loss: 0.523
2024-01-17 09:30 - INFO - 	 Best ROC-AUC: 0.710
2024-01-17 09:30 - INFO - 	 Best PR-AUC: 0.431
2024-01-17 09:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.670
2024-01-17 09:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.390
2024-01-17 09:30 - INFO - 	 Best Recall for 0.4 precision: 0.572
2024-01-17 09:30 - INFO - ---------------------------------------------
2024-01-17 09:35 - INFO - ---------------------------------------------
2024-01-17 09:35 - INFO - Epoch: 03 | Time: 5m 10s
2024-01-17 09:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71504
2024-01-17 09:35 - INFO - 	 Train Loss: 0.502
2024-01-17 09:35 - INFO - 	 Val. Loss: 0.506
2024-01-17 09:35 - INFO - 	 ROC-AUC: 0.715
2024-01-17 09:35 - INFO - 	 PR-AUC: 0.434
2024-01-17 09:35 - INFO - 	 Recall for 0.4 precision: 0.593
2024-01-17 09:35 - INFO - 	 Best Val. Loss: 0.506
2024-01-17 09:35 - INFO - 	 Best ROC-AUC: 0.715
2024-01-17 09:35 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 09:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.679
2024-01-17 09:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.399
2024-01-17 09:35 - INFO - 	 Best Recall for 0.4 precision: 0.593
2024-01-17 09:35 - INFO - ---------------------------------------------
2024-01-17 09:42 - INFO - ---------------------------------------------
2024-01-17 09:42 - INFO - Epoch: 04 | Time: 6m 20s
2024-01-17 09:42 - INFO - 	 Train Loss: 0.495
2024-01-17 09:42 - INFO - 	 Val. Loss: 0.503
2024-01-17 09:42 - INFO - 	 ROC-AUC: 0.713
2024-01-17 09:42 - INFO - 	 PR-AUC: 0.429
2024-01-17 09:42 - INFO - 	 Recall for 0.4 precision: 0.000
2024-01-17 09:42 - INFO - 	 Best Val. Loss: 0.503
2024-01-17 09:42 - INFO - 	 Best ROC-AUC: 0.715
2024-01-17 09:42 - INFO - 	 Best PR-AUC: 0.434
2024-01-17 09:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.679
2024-01-17 09:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.399
2024-01-17 09:42 - INFO - 	 Best Recall for 0.4 precision: 0.593
2024-01-17 09:42 - INFO - ---------------------------------------------
2024-01-17 09:47 - INFO - ---------------------------------------------
2024-01-17 09:47 - INFO - Epoch: 05 | Time: 5m 48s
2024-01-17 09:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71859
2024-01-17 09:47 - INFO - 	 Train Loss: 0.492
2024-01-17 09:47 - INFO - 	 Val. Loss: 0.499
2024-01-17 09:47 - INFO - 	 ROC-AUC: 0.719
2024-01-17 09:47 - INFO - 	 PR-AUC: 0.438
2024-01-17 09:47 - INFO - 	 Recall for 0.4 precision: 0.605
2024-01-17 09:47 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 09:47 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 09:47 - INFO - 	 Best PR-AUC: 0.438
2024-01-17 09:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-17 09:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.414
2024-01-17 09:47 - INFO - 	 Best Recall for 0.4 precision: 0.605
2024-01-17 09:47 - INFO - ---------------------------------------------
2024-01-17 09:54 - INFO - ---------------------------------------------
2024-01-17 09:54 - INFO - Epoch: 06 | Time: 6m 9s
2024-01-17 09:54 - INFO - 	 Train Loss: 0.489
2024-01-17 09:54 - INFO - 	 Val. Loss: 0.499
2024-01-17 09:54 - INFO - 	 ROC-AUC: 0.718
2024-01-17 09:54 - INFO - 	 PR-AUC: 0.434
2024-01-17 09:54 - INFO - 	 Recall for 0.4 precision: 0.600
2024-01-17 09:54 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 09:54 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 09:54 - INFO - 	 Best PR-AUC: 0.438
2024-01-17 09:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-17 09:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.414
2024-01-17 09:54 - INFO - 	 Best Recall for 0.4 precision: 0.605
2024-01-17 09:54 - INFO - ---------------------------------------------
2024-01-17 09:59 - INFO - ---------------------------------------------
2024-01-17 09:59 - INFO - Epoch: 07 | Time: 5m 50s
2024-01-17 09:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72087
2024-01-17 09:59 - INFO - 	 Train Loss: 0.487
2024-01-17 09:59 - INFO - 	 Val. Loss: 0.499
2024-01-17 09:59 - INFO - 	 ROC-AUC: 0.721
2024-01-17 09:59 - INFO - 	 PR-AUC: 0.440
2024-01-17 09:59 - INFO - 	 Recall for 0.4 precision: 0.622
2024-01-17 09:59 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 09:59 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 09:59 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 09:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.696
2024-01-17 09:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.419
2024-01-17 09:59 - INFO - 	 Best Recall for 0.4 precision: 0.622
2024-01-17 09:59 - INFO - ---------------------------------------------
2024-01-17 10:06 - INFO - ---------------------------------------------
2024-01-17 10:06 - INFO - Epoch: 08 | Time: 6m 18s
2024-01-17 10:06 - INFO - 	 Train Loss: 0.485
2024-01-17 10:06 - INFO - 	 Val. Loss: 0.499
2024-01-17 10:06 - INFO - 	 ROC-AUC: 0.720
2024-01-17 10:06 - INFO - 	 PR-AUC: 0.439
2024-01-17 10:06 - INFO - 	 Recall for 0.4 precision: 0.617
2024-01-17 10:06 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 10:06 - INFO - 	 Best ROC-AUC: 0.721
2024-01-17 10:06 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 10:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.696
2024-01-17 10:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.419
2024-01-17 10:06 - INFO - 	 Best Recall for 0.4 precision: 0.622
2024-01-17 10:06 - INFO - ---------------------------------------------
2024-01-17 10:11 - INFO - ---------------------------------------------
2024-01-17 10:11 - INFO - Epoch: 09 | Time: 5m 35s
2024-01-17 10:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72174
2024-01-17 10:11 - INFO - 	 Train Loss: 0.484
2024-01-17 10:11 - INFO - 	 Val. Loss: 0.498
2024-01-17 10:11 - INFO - 	 ROC-AUC: 0.722
2024-01-17 10:11 - INFO - 	 PR-AUC: 0.438
2024-01-17 10:11 - INFO - 	 Recall for 0.4 precision: 0.622
2024-01-17 10:11 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 10:11 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 10:11 - INFO - 	 Best PR-AUC: 0.440
2024-01-17 10:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 10:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.419
2024-01-17 10:11 - INFO - 	 Best Recall for 0.4 precision: 0.622
2024-01-17 10:11 - INFO - ---------------------------------------------
2024-01-17 10:19 - INFO - ---------------------------------------------
2024-01-17 10:19 - INFO - Epoch: 10 | Time: 7m 16s
2024-01-17 10:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72447
2024-01-17 10:19 - INFO - 	 Train Loss: 0.484
2024-01-17 10:19 - INFO - 	 Val. Loss: 0.497
2024-01-17 10:19 - INFO - 	 ROC-AUC: 0.724
2024-01-17 10:19 - INFO - 	 PR-AUC: 0.442
2024-01-17 10:19 - INFO - 	 Recall for 0.4 precision: 0.639
2024-01-17 10:19 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 10:19 - INFO - 	 Best ROC-AUC: 0.724
2024-01-17 10:19 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 10:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 10:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.429
2024-01-17 10:19 - INFO - 	 Best Recall for 0.4 precision: 0.639
2024-01-17 10:19 - INFO - ---------------------------------------------
2024-01-17 10:24 - INFO - Fit the preprocessing pipeline
2024-01-17 10:24 - INFO - Training using device: cuda
2024-01-17 10:24 - INFO - Creating generators
2024-01-17 10:24 - INFO - The model has 651,257 trainable parameters
2024-01-17 10:24 - INFO - * Model:
2024-01-17 10:24 - INFO - * -----------
2024-01-17 10:24 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 10:24 - INFO - * -----------
2024-01-17 10:24 - INFO - Evaluating model based on: rocauc
2024-01-17 10:24 - INFO - Training..

2024-01-17 10:31 - INFO - ---------------------------------------------
2024-01-17 10:31 - INFO - Epoch: 01 | Time: 6m 15s
2024-01-17 10:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.60138
2024-01-17 10:31 - INFO - 	 Train Loss: 0.568
2024-01-17 10:31 - INFO - 	 Val. Loss: 0.544
2024-01-17 10:31 - INFO - 	 ROC-AUC: 0.601
2024-01-17 10:31 - INFO - 	 PR-AUC: 0.333
2024-01-17 10:31 - INFO - 	 Recall for 0.4 precision: 0.194
2024-01-17 10:31 - INFO - 	 Best Val. Loss: 0.544
2024-01-17 10:31 - INFO - 	 Best ROC-AUC: 0.601
2024-01-17 10:31 - INFO - 	 Best PR-AUC: 0.333
2024-01-17 10:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.583
2024-01-17 10:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.319
2024-01-17 10:31 - INFO - 	 Best Recall for 0.4 precision: 0.194
2024-01-17 10:31 - INFO - ---------------------------------------------
2024-01-17 10:37 - INFO - ---------------------------------------------
2024-01-17 10:37 - INFO - Epoch: 02 | Time: 6m 21s
2024-01-17 10:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71142
2024-01-17 10:37 - INFO - 	 Train Loss: 0.524
2024-01-17 10:37 - INFO - 	 Val. Loss: 0.505
2024-01-17 10:37 - INFO - 	 ROC-AUC: 0.711
2024-01-17 10:37 - INFO - 	 PR-AUC: 0.433
2024-01-17 10:37 - INFO - 	 Recall for 0.4 precision: 0.593
2024-01-17 10:37 - INFO - 	 Best Val. Loss: 0.505
2024-01-17 10:37 - INFO - 	 Best ROC-AUC: 0.711
2024-01-17 10:37 - INFO - 	 Best PR-AUC: 0.433
2024-01-17 10:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.675
2024-01-17 10:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.400
2024-01-17 10:37 - INFO - 	 Best Recall for 0.4 precision: 0.593
2024-01-17 10:37 - INFO - ---------------------------------------------
2024-01-17 10:43 - INFO - ---------------------------------------------
2024-01-17 10:43 - INFO - Epoch: 03 | Time: 6m 21s
2024-01-17 10:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72177
2024-01-17 10:43 - INFO - 	 Train Loss: 0.504
2024-01-17 10:43 - INFO - 	 Val. Loss: 0.498
2024-01-17 10:43 - INFO - 	 ROC-AUC: 0.722
2024-01-17 10:43 - INFO - 	 PR-AUC: 0.441
2024-01-17 10:43 - INFO - 	 Recall for 0.4 precision: 0.626
2024-01-17 10:43 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 10:43 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 10:43 - INFO - 	 Best PR-AUC: 0.441
2024-01-17 10:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.686
2024-01-17 10:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.411
2024-01-17 10:43 - INFO - 	 Best Recall for 0.4 precision: 0.626
2024-01-17 10:43 - INFO - ---------------------------------------------
2024-01-17 10:49 - INFO - ---------------------------------------------
2024-01-17 10:49 - INFO - Epoch: 04 | Time: 5m 37s
2024-01-17 10:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72412
2024-01-17 10:49 - INFO - 	 Train Loss: 0.496
2024-01-17 10:49 - INFO - 	 Val. Loss: 0.497
2024-01-17 10:49 - INFO - 	 ROC-AUC: 0.724
2024-01-17 10:49 - INFO - 	 PR-AUC: 0.442
2024-01-17 10:49 - INFO - 	 Recall for 0.4 precision: 0.632
2024-01-17 10:49 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 10:49 - INFO - 	 Best ROC-AUC: 0.724
2024-01-17 10:49 - INFO - 	 Best PR-AUC: 0.442
2024-01-17 10:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.695
2024-01-17 10:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.422
2024-01-17 10:49 - INFO - 	 Best Recall for 0.4 precision: 0.632
2024-01-17 10:49 - INFO - ---------------------------------------------
2024-01-17 10:55 - INFO - ---------------------------------------------
2024-01-17 10:55 - INFO - Epoch: 05 | Time: 6m 11s
2024-01-17 10:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72466
2024-01-17 10:55 - INFO - 	 Train Loss: 0.492
2024-01-17 10:55 - INFO - 	 Val. Loss: 0.496
2024-01-17 10:55 - INFO - 	 ROC-AUC: 0.725
2024-01-17 10:55 - INFO - 	 PR-AUC: 0.445
2024-01-17 10:55 - INFO - 	 Recall for 0.4 precision: 0.646
2024-01-17 10:55 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 10:55 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 10:55 - INFO - 	 Best PR-AUC: 0.445
2024-01-17 10:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.698
2024-01-17 10:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 10:55 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 10:55 - INFO - ---------------------------------------------
2024-01-17 11:02 - INFO - ---------------------------------------------
2024-01-17 11:02 - INFO - Epoch: 06 | Time: 6m 33s
2024-01-17 11:02 - INFO - 	 Train Loss: 0.489
2024-01-17 11:02 - INFO - 	 Val. Loss: 0.499
2024-01-17 11:02 - INFO - 	 ROC-AUC: 0.720
2024-01-17 11:02 - INFO - 	 PR-AUC: 0.429
2024-01-17 11:02 - INFO - 	 Recall for 0.4 precision: 0.610
2024-01-17 11:02 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 11:02 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 11:02 - INFO - 	 Best PR-AUC: 0.445
2024-01-17 11:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.698
2024-01-17 11:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 11:02 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 11:02 - INFO - ---------------------------------------------
2024-01-17 11:08 - INFO - ---------------------------------------------
2024-01-17 11:08 - INFO - Epoch: 07 | Time: 6m 12s
2024-01-17 11:08 - INFO - 	 Train Loss: 0.487
2024-01-17 11:08 - INFO - 	 Val. Loss: 0.501
2024-01-17 11:08 - INFO - 	 ROC-AUC: 0.724
2024-01-17 11:08 - INFO - 	 PR-AUC: 0.443
2024-01-17 11:08 - INFO - 	 Recall for 0.4 precision: 0.626
2024-01-17 11:08 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 11:08 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 11:08 - INFO - 	 Best PR-AUC: 0.445
2024-01-17 11:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.698
2024-01-17 11:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.427
2024-01-17 11:08 - INFO - 	 Best Recall for 0.4 precision: 0.646
2024-01-17 11:08 - INFO - ---------------------------------------------
2024-01-17 11:15 - INFO - ---------------------------------------------
2024-01-17 11:15 - INFO - Epoch: 08 | Time: 6m 45s
2024-01-17 11:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72707
2024-01-17 11:15 - INFO - 	 Train Loss: 0.485
2024-01-17 11:15 - INFO - 	 Val. Loss: 0.495
2024-01-17 11:15 - INFO - 	 ROC-AUC: 0.727
2024-01-17 11:15 - INFO - 	 PR-AUC: 0.446
2024-01-17 11:15 - INFO - 	 Recall for 0.4 precision: 0.647
2024-01-17 11:15 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 11:15 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 11:15 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 11:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.709
2024-01-17 11:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.436
2024-01-17 11:15 - INFO - 	 Best Recall for 0.4 precision: 0.647
2024-01-17 11:15 - INFO - ---------------------------------------------
2024-01-17 11:21 - INFO - ---------------------------------------------
2024-01-17 11:21 - INFO - Epoch: 09 | Time: 6m 34s
2024-01-17 11:21 - INFO - 	 Train Loss: 0.484
2024-01-17 11:21 - INFO - 	 Val. Loss: 0.498
2024-01-17 11:21 - INFO - 	 ROC-AUC: 0.721
2024-01-17 11:21 - INFO - 	 PR-AUC: 0.440
2024-01-17 11:21 - INFO - 	 Recall for 0.4 precision: 0.623
2024-01-17 11:21 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 11:21 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 11:21 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 11:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.709
2024-01-17 11:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.436
2024-01-17 11:21 - INFO - 	 Best Recall for 0.4 precision: 0.647
2024-01-17 11:21 - INFO - ---------------------------------------------
2024-01-17 11:26 - INFO - ---------------------------------------------
2024-01-17 11:26 - INFO - Epoch: 10 | Time: 5m 11s
2024-01-17 11:26 - INFO - 	 Train Loss: 0.483
2024-01-17 11:26 - INFO - 	 Val. Loss: 0.495
2024-01-17 11:26 - INFO - 	 ROC-AUC: 0.727
2024-01-17 11:26 - INFO - 	 PR-AUC: 0.445
2024-01-17 11:26 - INFO - 	 Recall for 0.4 precision: 0.636
2024-01-17 11:26 - INFO - 	 Best Val. Loss: 0.495
2024-01-17 11:26 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 11:26 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 11:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.709
2024-01-17 11:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.436
2024-01-17 11:26 - INFO - 	 Best Recall for 0.4 precision: 0.647
2024-01-17 11:26 - INFO - ---------------------------------------------
2024-01-17 11:32 - INFO - Fit the preprocessing pipeline
2024-01-17 11:32 - INFO - Training using device: cuda
2024-01-17 11:32 - INFO - Creating generators
2024-01-17 11:32 - INFO - The model has 651,257 trainable parameters
2024-01-17 11:32 - INFO - * Model:
2024-01-17 11:32 - INFO - * -----------
2024-01-17 11:32 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 11:32 - INFO - * -----------
2024-01-17 11:32 - INFO - Evaluating model based on: rocauc
2024-01-17 11:32 - INFO - Training..

2024-01-17 11:38 - INFO - ---------------------------------------------
2024-01-17 11:38 - INFO - Epoch: 01 | Time: 5m 49s
2024-01-17 11:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.60664
2024-01-17 11:38 - INFO - 	 Train Loss: 0.568
2024-01-17 11:38 - INFO - 	 Val. Loss: 0.572
2024-01-17 11:38 - INFO - 	 ROC-AUC: 0.607
2024-01-17 11:38 - INFO - 	 PR-AUC: 0.341
2024-01-17 11:38 - INFO - 	 Recall for 0.4 precision: 0.222
2024-01-17 11:38 - INFO - 	 Best Val. Loss: 0.572
2024-01-17 11:38 - INFO - 	 Best ROC-AUC: 0.607
2024-01-17 11:38 - INFO - 	 Best PR-AUC: 0.341
2024-01-17 11:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.578
2024-01-17 11:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.323
2024-01-17 11:38 - INFO - 	 Best Recall for 0.4 precision: 0.222
2024-01-17 11:38 - INFO - ---------------------------------------------
2024-01-17 11:44 - INFO - ---------------------------------------------
2024-01-17 11:44 - INFO - Epoch: 02 | Time: 6m 17s
2024-01-17 11:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70766
2024-01-17 11:44 - INFO - 	 Train Loss: 0.525
2024-01-17 11:44 - INFO - 	 Val. Loss: 0.506
2024-01-17 11:44 - INFO - 	 ROC-AUC: 0.708
2024-01-17 11:44 - INFO - 	 PR-AUC: 0.424
2024-01-17 11:44 - INFO - 	 Recall for 0.4 precision: 0.001
2024-01-17 11:44 - INFO - 	 Best Val. Loss: 0.506
2024-01-17 11:44 - INFO - 	 Best ROC-AUC: 0.708
2024-01-17 11:44 - INFO - 	 Best PR-AUC: 0.424
2024-01-17 11:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.673
2024-01-17 11:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.393
2024-01-17 11:44 - INFO - 	 Best Recall for 0.4 precision: 0.222
2024-01-17 11:44 - INFO - ---------------------------------------------
2024-01-17 11:50 - INFO - ---------------------------------------------
2024-01-17 11:50 - INFO - Epoch: 03 | Time: 5m 54s
2024-01-17 11:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71877
2024-01-17 11:50 - INFO - 	 Train Loss: 0.504
2024-01-17 11:50 - INFO - 	 Val. Loss: 0.501
2024-01-17 11:50 - INFO - 	 ROC-AUC: 0.719
2024-01-17 11:50 - INFO - 	 PR-AUC: 0.436
2024-01-17 11:50 - INFO - 	 Recall for 0.4 precision: 0.610
2024-01-17 11:50 - INFO - 	 Best Val. Loss: 0.501
2024-01-17 11:50 - INFO - 	 Best ROC-AUC: 0.719
2024-01-17 11:50 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 11:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.685
2024-01-17 11:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.401
2024-01-17 11:50 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 11:50 - INFO - ---------------------------------------------
2024-01-17 11:56 - INFO - ---------------------------------------------
2024-01-17 11:56 - INFO - Epoch: 04 | Time: 5m 51s
2024-01-17 11:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72021
2024-01-17 11:56 - INFO - 	 Train Loss: 0.496
2024-01-17 11:56 - INFO - 	 Val. Loss: 0.498
2024-01-17 11:56 - INFO - 	 ROC-AUC: 0.720
2024-01-17 11:56 - INFO - 	 PR-AUC: 0.436
2024-01-17 11:56 - INFO - 	 Recall for 0.4 precision: 0.601
2024-01-17 11:56 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 11:56 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 11:56 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 11:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-17 11:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.401
2024-01-17 11:56 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 11:56 - INFO - ---------------------------------------------
2024-01-17 12:02 - INFO - ---------------------------------------------
2024-01-17 12:02 - INFO - Epoch: 05 | Time: 5m 57s
2024-01-17 12:02 - INFO - 	 Train Loss: 0.492
2024-01-17 12:02 - INFO - 	 Val. Loss: 0.500
2024-01-17 12:02 - INFO - 	 ROC-AUC: 0.719
2024-01-17 12:02 - INFO - 	 PR-AUC: 0.432
2024-01-17 12:02 - INFO - 	 Recall for 0.4 precision: 0.609
2024-01-17 12:02 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 12:02 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 12:02 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 12:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-17 12:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.401
2024-01-17 12:02 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 12:02 - INFO - ---------------------------------------------
2024-01-17 12:08 - INFO - ---------------------------------------------
2024-01-17 12:08 - INFO - Epoch: 06 | Time: 6m 9s
2024-01-17 12:08 - INFO - 	 Train Loss: 0.489
2024-01-17 12:08 - INFO - 	 Val. Loss: 0.502
2024-01-17 12:08 - INFO - 	 ROC-AUC: 0.715
2024-01-17 12:08 - INFO - 	 PR-AUC: 0.428
2024-01-17 12:08 - INFO - 	 Recall for 0.4 precision: 0.589
2024-01-17 12:08 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 12:08 - INFO - 	 Best ROC-AUC: 0.720
2024-01-17 12:08 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 12:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.689
2024-01-17 12:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.401
2024-01-17 12:08 - INFO - 	 Best Recall for 0.4 precision: 0.610
2024-01-17 12:08 - INFO - ---------------------------------------------
2024-01-17 12:14 - INFO - ---------------------------------------------
2024-01-17 12:14 - INFO - Epoch: 07 | Time: 6m 5s
2024-01-17 12:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72465
2024-01-17 12:14 - INFO - 	 Train Loss: 0.488
2024-01-17 12:14 - INFO - 	 Val. Loss: 0.497
2024-01-17 12:14 - INFO - 	 ROC-AUC: 0.725
2024-01-17 12:14 - INFO - 	 PR-AUC: 0.444
2024-01-17 12:14 - INFO - 	 Recall for 0.4 precision: 0.626
2024-01-17 12:14 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 12:14 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 12:14 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 12:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 12:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.432
2024-01-17 12:14 - INFO - 	 Best Recall for 0.4 precision: 0.626
2024-01-17 12:14 - INFO - ---------------------------------------------
2024-01-17 12:21 - INFO - ---------------------------------------------
2024-01-17 12:21 - INFO - Epoch: 08 | Time: 6m 20s
2024-01-17 12:21 - INFO - 	 Train Loss: 0.486
2024-01-17 12:21 - INFO - 	 Val. Loss: 0.497
2024-01-17 12:21 - INFO - 	 ROC-AUC: 0.722
2024-01-17 12:21 - INFO - 	 PR-AUC: 0.437
2024-01-17 12:21 - INFO - 	 Recall for 0.4 precision: 0.627
2024-01-17 12:21 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 12:21 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 12:21 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 12:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 12:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.432
2024-01-17 12:21 - INFO - 	 Best Recall for 0.4 precision: 0.627
2024-01-17 12:21 - INFO - ---------------------------------------------
2024-01-17 12:26 - INFO - ---------------------------------------------
2024-01-17 12:26 - INFO - Epoch: 09 | Time: 5m 41s
2024-01-17 12:26 - INFO - 	 Train Loss: 0.485
2024-01-17 12:26 - INFO - 	 Val. Loss: 0.499
2024-01-17 12:26 - INFO - 	 ROC-AUC: 0.721
2024-01-17 12:26 - INFO - 	 PR-AUC: 0.433
2024-01-17 12:26 - INFO - 	 Recall for 0.4 precision: 0.620
2024-01-17 12:26 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 12:26 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 12:26 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 12:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.702
2024-01-17 12:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.432
2024-01-17 12:26 - INFO - 	 Best Recall for 0.4 precision: 0.627
2024-01-17 12:26 - INFO - ---------------------------------------------
2024-01-17 12:33 - INFO - ---------------------------------------------
2024-01-17 12:33 - INFO - Epoch: 10 | Time: 6m 21s
2024-01-17 12:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72522
2024-01-17 12:33 - INFO - 	 Train Loss: 0.484
2024-01-17 12:33 - INFO - 	 Val. Loss: 0.497
2024-01-17 12:33 - INFO - 	 ROC-AUC: 0.725
2024-01-17 12:33 - INFO - 	 PR-AUC: 0.439
2024-01-17 12:33 - INFO - 	 Recall for 0.4 precision: 0.634
2024-01-17 12:33 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 12:33 - INFO - 	 Best ROC-AUC: 0.725
2024-01-17 12:33 - INFO - 	 Best PR-AUC: 0.444
2024-01-17 12:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.706
2024-01-17 12:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.432
2024-01-17 12:33 - INFO - 	 Best Recall for 0.4 precision: 0.634
2024-01-17 12:33 - INFO - ---------------------------------------------
2024-01-17 12:38 - INFO - Fit the preprocessing pipeline
2024-01-17 12:38 - INFO - Training using device: cuda
2024-01-17 12:38 - INFO - Creating generators
2024-01-17 12:38 - INFO - The model has 651,257 trainable parameters
2024-01-17 12:38 - INFO - * Model:
2024-01-17 12:38 - INFO - * -----------
2024-01-17 12:38 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 12:38 - INFO - * -----------
2024-01-17 12:38 - INFO - Evaluating model based on: rocauc
2024-01-17 12:38 - INFO - Training..

2024-01-17 12:44 - INFO - ---------------------------------------------
2024-01-17 12:44 - INFO - Epoch: 01 | Time: 6m 3s
2024-01-17 12:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.6851
2024-01-17 12:44 - INFO - 	 Train Loss: 0.555
2024-01-17 12:44 - INFO - 	 Val. Loss: 0.517
2024-01-17 12:44 - INFO - 	 ROC-AUC: 0.685
2024-01-17 12:44 - INFO - 	 PR-AUC: 0.405
2024-01-17 12:44 - INFO - 	 Recall for 0.4 precision: 0.465
2024-01-17 12:44 - INFO - 	 Best Val. Loss: 0.517
2024-01-17 12:44 - INFO - 	 Best ROC-AUC: 0.685
2024-01-17 12:44 - INFO - 	 Best PR-AUC: 0.405
2024-01-17 12:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.648
2024-01-17 12:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.373
2024-01-17 12:44 - INFO - 	 Best Recall for 0.4 precision: 0.465
2024-01-17 12:44 - INFO - ---------------------------------------------
2024-01-17 12:51 - INFO - ---------------------------------------------
2024-01-17 12:51 - INFO - Epoch: 02 | Time: 6m 15s
2024-01-17 12:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72268
2024-01-17 12:51 - INFO - 	 Train Loss: 0.509
2024-01-17 12:51 - INFO - 	 Val. Loss: 0.498
2024-01-17 12:51 - INFO - 	 ROC-AUC: 0.723
2024-01-17 12:51 - INFO - 	 PR-AUC: 0.443
2024-01-17 12:51 - INFO - 	 Recall for 0.4 precision: 0.620
2024-01-17 12:51 - INFO - 	 Best Val. Loss: 0.498
2024-01-17 12:51 - INFO - 	 Best ROC-AUC: 0.723
2024-01-17 12:51 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 12:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.683
2024-01-17 12:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.411
2024-01-17 12:51 - INFO - 	 Best Recall for 0.4 precision: 0.620
2024-01-17 12:51 - INFO - ---------------------------------------------
2024-01-17 12:57 - INFO - ---------------------------------------------
2024-01-17 12:57 - INFO - Epoch: 03 | Time: 5m 55s
2024-01-17 12:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7264
2024-01-17 12:57 - INFO - 	 Train Loss: 0.498
2024-01-17 12:57 - INFO - 	 Val. Loss: 0.497
2024-01-17 12:57 - INFO - 	 ROC-AUC: 0.726
2024-01-17 12:57 - INFO - 	 PR-AUC: 0.443
2024-01-17 12:57 - INFO - 	 Recall for 0.4 precision: 0.641
2024-01-17 12:57 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 12:57 - INFO - 	 Best ROC-AUC: 0.726
2024-01-17 12:57 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 12:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-17 12:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.411
2024-01-17 12:57 - INFO - 	 Best Recall for 0.4 precision: 0.641
2024-01-17 12:57 - INFO - ---------------------------------------------
2024-01-17 13:03 - INFO - ---------------------------------------------
2024-01-17 13:03 - INFO - Epoch: 04 | Time: 6m 6s
2024-01-17 13:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.73168
2024-01-17 13:03 - INFO - 	 Train Loss: 0.492
2024-01-17 13:03 - INFO - 	 Val. Loss: 0.493
2024-01-17 13:03 - INFO - 	 ROC-AUC: 0.732
2024-01-17 13:03 - INFO - 	 PR-AUC: 0.451
2024-01-17 13:03 - INFO - 	 Recall for 0.4 precision: 0.654
2024-01-17 13:03 - INFO - 	 Best Val. Loss: 0.493
2024-01-17 13:03 - INFO - 	 Best ROC-AUC: 0.732
2024-01-17 13:03 - INFO - 	 Best PR-AUC: 0.451
2024-01-17 13:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 13:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 13:03 - INFO - 	 Best Recall for 0.4 precision: 0.654
2024-01-17 13:03 - INFO - ---------------------------------------------
2024-01-17 13:09 - INFO - ---------------------------------------------
2024-01-17 13:09 - INFO - Epoch: 05 | Time: 6m 22s
2024-01-17 13:09 - INFO - 	 Train Loss: 0.489
2024-01-17 13:09 - INFO - 	 Val. Loss: 0.494
2024-01-17 13:09 - INFO - 	 ROC-AUC: 0.729
2024-01-17 13:09 - INFO - 	 PR-AUC: 0.447
2024-01-17 13:09 - INFO - 	 Recall for 0.4 precision: 0.655
2024-01-17 13:09 - INFO - 	 Best Val. Loss: 0.493
2024-01-17 13:09 - INFO - 	 Best ROC-AUC: 0.732
2024-01-17 13:09 - INFO - 	 Best PR-AUC: 0.451
2024-01-17 13:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 13:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 13:09 - INFO - 	 Best Recall for 0.4 precision: 0.655
2024-01-17 13:09 - INFO - ---------------------------------------------
2024-01-17 13:15 - INFO - ---------------------------------------------
2024-01-17 13:15 - INFO - Epoch: 06 | Time: 5m 39s
2024-01-17 13:15 - INFO - 	 Train Loss: 0.486
2024-01-17 13:15 - INFO - 	 Val. Loss: 0.500
2024-01-17 13:15 - INFO - 	 ROC-AUC: 0.719
2024-01-17 13:15 - INFO - 	 PR-AUC: 0.435
2024-01-17 13:15 - INFO - 	 Recall for 0.4 precision: 0.613
2024-01-17 13:15 - INFO - 	 Best Val. Loss: 0.493
2024-01-17 13:15 - INFO - 	 Best ROC-AUC: 0.732
2024-01-17 13:15 - INFO - 	 Best PR-AUC: 0.451
2024-01-17 13:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 13:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 13:15 - INFO - 	 Best Recall for 0.4 precision: 0.655
2024-01-17 13:15 - INFO - ---------------------------------------------
2024-01-17 13:21 - INFO - ---------------------------------------------
2024-01-17 13:21 - INFO - Epoch: 07 | Time: 6m 41s
2024-01-17 13:21 - INFO - 	 Train Loss: 0.484
2024-01-17 13:21 - INFO - 	 Val. Loss: 0.496
2024-01-17 13:21 - INFO - 	 ROC-AUC: 0.727
2024-01-17 13:21 - INFO - 	 PR-AUC: 0.441
2024-01-17 13:21 - INFO - 	 Recall for 0.4 precision: 0.643
2024-01-17 13:21 - INFO - 	 Best Val. Loss: 0.493
2024-01-17 13:21 - INFO - 	 Best ROC-AUC: 0.732
2024-01-17 13:21 - INFO - 	 Best PR-AUC: 0.451
2024-01-17 13:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.699
2024-01-17 13:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.428
2024-01-17 13:21 - INFO - 	 Best Recall for 0.4 precision: 0.655
2024-01-17 13:21 - INFO - ---------------------------------------------
2024-01-17 13:33 - INFO - Fit the preprocessing pipeline
2024-01-17 13:33 - INFO - Training using device: cuda
2024-01-17 13:33 - INFO - Creating generators
2024-01-17 13:33 - INFO - The model has 651,257 trainable parameters
2024-01-17 13:33 - INFO - * Model:
2024-01-17 13:33 - INFO - * -----------
2024-01-17 13:33 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 13:33 - INFO - * -----------
2024-01-17 13:33 - INFO - Evaluating model based on: rocauc
2024-01-17 13:33 - INFO - Training..

2024-01-17 13:39 - INFO - ---------------------------------------------
2024-01-17 13:39 - INFO - Epoch: 01 | Time: 5m 50s
2024-01-17 13:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.60267
2024-01-17 13:39 - INFO - 	 Train Loss: 0.570
2024-01-17 13:39 - INFO - 	 Val. Loss: 0.544
2024-01-17 13:39 - INFO - 	 ROC-AUC: 0.603
2024-01-17 13:39 - INFO - 	 PR-AUC: 0.332
2024-01-17 13:39 - INFO - 	 Recall for 0.4 precision: 0.173
2024-01-17 13:39 - INFO - 	 Best Val. Loss: 0.544
2024-01-17 13:39 - INFO - 	 Best ROC-AUC: 0.603
2024-01-17 13:39 - INFO - 	 Best PR-AUC: 0.332
2024-01-17 13:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.575
2024-01-17 13:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.312
2024-01-17 13:39 - INFO - 	 Best Recall for 0.4 precision: 0.173
2024-01-17 13:39 - INFO - ---------------------------------------------
2024-01-17 13:46 - INFO - ---------------------------------------------
2024-01-17 13:46 - INFO - Epoch: 02 | Time: 6m 53s
2024-01-17 13:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.6985
2024-01-17 13:46 - INFO - 	 Train Loss: 0.524
2024-01-17 13:46 - INFO - 	 Val. Loss: 0.510
2024-01-17 13:46 - INFO - 	 ROC-AUC: 0.698
2024-01-17 13:46 - INFO - 	 PR-AUC: 0.419
2024-01-17 13:46 - INFO - 	 Recall for 0.4 precision: 0.542
2024-01-17 13:46 - INFO - 	 Best Val. Loss: 0.510
2024-01-17 13:46 - INFO - 	 Best ROC-AUC: 0.698
2024-01-17 13:46 - INFO - 	 Best PR-AUC: 0.419
2024-01-17 13:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.663
2024-01-17 13:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.385
2024-01-17 13:46 - INFO - 	 Best Recall for 0.4 precision: 0.542
2024-01-17 13:46 - INFO - ---------------------------------------------
2024-01-17 13:51 - INFO - ---------------------------------------------
2024-01-17 13:51 - INFO - Epoch: 03 | Time: 5m 11s
2024-01-17 13:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71409
2024-01-17 13:51 - INFO - 	 Train Loss: 0.505
2024-01-17 13:51 - INFO - 	 Val. Loss: 0.509
2024-01-17 13:51 - INFO - 	 ROC-AUC: 0.714
2024-01-17 13:51 - INFO - 	 PR-AUC: 0.432
2024-01-17 13:51 - INFO - 	 Recall for 0.4 precision: 0.588
2024-01-17 13:51 - INFO - 	 Best Val. Loss: 0.509
2024-01-17 13:51 - INFO - 	 Best ROC-AUC: 0.714
2024-01-17 13:51 - INFO - 	 Best PR-AUC: 0.432
2024-01-17 13:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.680
2024-01-17 13:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.400
2024-01-17 13:51 - INFO - 	 Best Recall for 0.4 precision: 0.588
2024-01-17 13:51 - INFO - ---------------------------------------------
2024-01-17 13:57 - INFO - ---------------------------------------------
2024-01-17 13:57 - INFO - Epoch: 04 | Time: 6m 20s
2024-01-17 13:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71498
2024-01-17 13:57 - INFO - 	 Train Loss: 0.498
2024-01-17 13:57 - INFO - 	 Val. Loss: 0.503
2024-01-17 13:57 - INFO - 	 ROC-AUC: 0.715
2024-01-17 13:57 - INFO - 	 PR-AUC: 0.436
2024-01-17 13:57 - INFO - 	 Recall for 0.4 precision: 0.597
2024-01-17 13:57 - INFO - 	 Best Val. Loss: 0.503
2024-01-17 13:57 - INFO - 	 Best ROC-AUC: 0.715
2024-01-17 13:57 - INFO - 	 Best PR-AUC: 0.436
2024-01-17 13:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.693
2024-01-17 13:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.415
2024-01-17 13:57 - INFO - 	 Best Recall for 0.4 precision: 0.597
2024-01-17 13:57 - INFO - ---------------------------------------------
2024-01-17 14:03 - INFO - ---------------------------------------------
2024-01-17 14:03 - INFO - Epoch: 05 | Time: 5m 39s
2024-01-17 14:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.722
2024-01-17 14:03 - INFO - 	 Train Loss: 0.493
2024-01-17 14:03 - INFO - 	 Val. Loss: 0.499
2024-01-17 14:03 - INFO - 	 ROC-AUC: 0.722
2024-01-17 14:03 - INFO - 	 PR-AUC: 0.437
2024-01-17 14:03 - INFO - 	 Recall for 0.4 precision: 0.621
2024-01-17 14:03 - INFO - 	 Best Val. Loss: 0.499
2024-01-17 14:03 - INFO - 	 Best ROC-AUC: 0.722
2024-01-17 14:03 - INFO - 	 Best PR-AUC: 0.437
2024-01-17 14:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.696
2024-01-17 14:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.418
2024-01-17 14:03 - INFO - 	 Best Recall for 0.4 precision: 0.621
2024-01-17 14:03 - INFO - ---------------------------------------------
2024-01-17 14:09 - INFO - ---------------------------------------------
2024-01-17 14:09 - INFO - Epoch: 06 | Time: 5m 45s
2024-01-17 14:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72364
2024-01-17 14:09 - INFO - 	 Train Loss: 0.489
2024-01-17 14:09 - INFO - 	 Val. Loss: 0.497
2024-01-17 14:09 - INFO - 	 ROC-AUC: 0.724
2024-01-17 14:09 - INFO - 	 PR-AUC: 0.443
2024-01-17 14:09 - INFO - 	 Recall for 0.4 precision: 0.000
2024-01-17 14:09 - INFO - 	 Best Val. Loss: 0.497
2024-01-17 14:09 - INFO - 	 Best ROC-AUC: 0.724
2024-01-17 14:09 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 14:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.701
2024-01-17 14:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.430
2024-01-17 14:09 - INFO - 	 Best Recall for 0.4 precision: 0.621
2024-01-17 14:09 - INFO - ---------------------------------------------
2024-01-17 14:15 - INFO - ---------------------------------------------
2024-01-17 14:15 - INFO - Epoch: 07 | Time: 5m 56s
2024-01-17 14:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72732
2024-01-17 14:15 - INFO - 	 Train Loss: 0.487
2024-01-17 14:15 - INFO - 	 Val. Loss: 0.496
2024-01-17 14:15 - INFO - 	 ROC-AUC: 0.727
2024-01-17 14:15 - INFO - 	 PR-AUC: 0.442
2024-01-17 14:15 - INFO - 	 Recall for 0.4 precision: 0.649
2024-01-17 14:15 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 14:15 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 14:15 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 14:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 14:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.430
2024-01-17 14:15 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 14:15 - INFO - ---------------------------------------------
2024-01-17 14:21 - INFO - ---------------------------------------------
2024-01-17 14:21 - INFO - Epoch: 08 | Time: 6m 1s
2024-01-17 14:21 - INFO - 	 Train Loss: 0.484
2024-01-17 14:21 - INFO - 	 Val. Loss: 0.497
2024-01-17 14:21 - INFO - 	 ROC-AUC: 0.725
2024-01-17 14:21 - INFO - 	 PR-AUC: 0.442
2024-01-17 14:21 - INFO - 	 Recall for 0.4 precision: 0.631
2024-01-17 14:21 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 14:21 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 14:21 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 14:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 14:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.430
2024-01-17 14:21 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 14:21 - INFO - ---------------------------------------------
2024-01-17 14:27 - INFO - ---------------------------------------------
2024-01-17 14:27 - INFO - Epoch: 09 | Time: 6m 23s
2024-01-17 14:27 - INFO - 	 Train Loss: 0.483
2024-01-17 14:27 - INFO - 	 Val. Loss: 0.498
2024-01-17 14:27 - INFO - 	 ROC-AUC: 0.721
2024-01-17 14:27 - INFO - 	 PR-AUC: 0.439
2024-01-17 14:27 - INFO - 	 Recall for 0.4 precision: 0.616
2024-01-17 14:27 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 14:27 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 14:27 - INFO - 	 Best PR-AUC: 0.443
2024-01-17 14:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 14:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.430
2024-01-17 14:27 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 14:27 - INFO - ---------------------------------------------
2024-01-17 14:33 - INFO - ---------------------------------------------
2024-01-17 14:33 - INFO - Epoch: 10 | Time: 5m 53s
2024-01-17 14:33 - INFO - 	 Train Loss: 0.482
2024-01-17 14:33 - INFO - 	 Val. Loss: 0.496
2024-01-17 14:33 - INFO - 	 ROC-AUC: 0.725
2024-01-17 14:33 - INFO - 	 PR-AUC: 0.446
2024-01-17 14:33 - INFO - 	 Recall for 0.4 precision: 0.625
2024-01-17 14:33 - INFO - 	 Best Val. Loss: 0.496
2024-01-17 14:33 - INFO - 	 Best ROC-AUC: 0.727
2024-01-17 14:33 - INFO - 	 Best PR-AUC: 0.446
2024-01-17 14:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.700
2024-01-17 14:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.435
2024-01-17 14:33 - INFO - 	 Best Recall for 0.4 precision: 0.649
2024-01-17 14:33 - INFO - ---------------------------------------------
2024-01-17 14:39 - INFO - Fit the preprocessing pipeline
2024-01-17 14:39 - INFO - Training using device: cuda
2024-01-17 14:39 - INFO - Creating generators
2024-01-17 14:39 - INFO - The model has 651,257 trainable parameters
2024-01-17 14:39 - INFO - * Model:
2024-01-17 14:39 - INFO - * -----------
2024-01-17 14:39 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-17 14:39 - INFO - * -----------
2024-01-17 14:39 - INFO - Evaluating model based on: rocauc
2024-01-17 14:39 - INFO - Training..

2024-01-17 14:44 - INFO - ---------------------------------------------
2024-01-17 14:44 - INFO - Epoch: 01 | Time: 5m 28s
2024-01-17 14:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.5763
2024-01-17 14:44 - INFO - 	 Train Loss: 0.570
2024-01-17 14:44 - INFO - 	 Val. Loss: 0.550
2024-01-17 14:44 - INFO - 	 ROC-AUC: 0.576
2024-01-17 14:44 - INFO - 	 PR-AUC: 0.311
2024-01-17 14:44 - INFO - 	 Recall for 0.4 precision: 0.125
2024-01-17 14:44 - INFO - 	 Best Val. Loss: 0.550
2024-01-17 14:44 - INFO - 	 Best ROC-AUC: 0.576
2024-01-17 14:44 - INFO - 	 Best PR-AUC: 0.311
2024-01-17 14:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.548
2024-01-17 14:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.293
2024-01-17 14:44 - INFO - 	 Best Recall for 0.4 precision: 0.125
2024-01-17 14:44 - INFO - ---------------------------------------------
2024-01-17 14:50 - INFO - ---------------------------------------------
2024-01-17 14:50 - INFO - Epoch: 02 | Time: 5m 48s
2024-01-17 14:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.70705
2024-01-17 14:50 - INFO - 	 Train Loss: 0.525
2024-01-17 14:50 - INFO - 	 Val. Loss: 0.507
2024-01-17 14:50 - INFO - 	 ROC-AUC: 0.707
2024-01-17 14:50 - INFO - 	 PR-AUC: 0.429
2024-01-17 14:50 - INFO - 	 Recall for 0.4 precision: 0.570
2024-01-17 14:50 - INFO - 	 Best Val. Loss: 0.507
2024-01-17 14:50 - INFO - 	 Best ROC-AUC: 0.707
2024-01-17 14:50 - INFO - 	 Best PR-AUC: 0.429
2024-01-17 14:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.671
2024-01-17 14:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.392
2024-01-17 14:50 - INFO - 	 Best Recall for 0.4 precision: 0.570
2024-01-17 14:50 - INFO - ---------------------------------------------
