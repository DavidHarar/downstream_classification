2024-10-12 19:53 - INFO - Fit the preprocessing pipeline
2024-10-12 19:53 - INFO - Training using device: cuda
2024-10-12 19:53 - INFO - Creating generators
2024-10-12 19:53 - INFO - The model has 651,257 trainable parameters
2024-10-12 19:53 - INFO - * Model:
2024-10-12 19:53 - INFO - * -----------
2024-10-12 19:53 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 19:53 - INFO - * -----------
2024-10-12 19:53 - INFO - Evaluating model based on: rocauc
2024-10-12 19:53 - INFO - Training..

2024-10-12 19:54 - INFO - ---------------------------------------------
2024-10-12 19:54 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 19:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97817
2024-10-12 19:54 - INFO - 	 Train Loss: 0.156
2024-10-12 19:54 - INFO - 	 Val. Loss: 0.083
2024-10-12 19:54 - INFO - 	 ROC-AUC: 0.978
2024-10-12 19:54 - INFO - 	 PR-AUC: 0.810
2024-10-12 19:54 - INFO - 	 Recall for 0.4 precision: 0.966
2024-10-12 19:54 - INFO - 	 Best Val. Loss: 0.083
2024-10-12 19:54 - INFO - 	 Best ROC-AUC: 0.978
2024-10-12 19:54 - INFO - 	 Best PR-AUC: 0.810
2024-10-12 19:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.975
2024-10-12 19:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.768
2024-10-12 19:54 - INFO - 	 Best Recall for 0.4 precision: 0.966
2024-10-12 19:54 - INFO - ---------------------------------------------
2024-10-12 19:55 - INFO - ---------------------------------------------
2024-10-12 19:55 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 19:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98493
2024-10-12 19:55 - INFO - 	 Train Loss: 0.084
2024-10-12 19:55 - INFO - 	 Val. Loss: 0.070
2024-10-12 19:55 - INFO - 	 ROC-AUC: 0.985
2024-10-12 19:55 - INFO - 	 PR-AUC: 0.861
2024-10-12 19:55 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 19:55 - INFO - 	 Best Val. Loss: 0.070
2024-10-12 19:55 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 19:55 - INFO - 	 Best PR-AUC: 0.861
2024-10-12 19:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 19:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.837
2024-10-12 19:55 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 19:55 - INFO - ---------------------------------------------
2024-10-12 19:55 - INFO - ---------------------------------------------
2024-10-12 19:55 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 19:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98549
2024-10-12 19:55 - INFO - 	 Train Loss: 0.073
2024-10-12 19:55 - INFO - 	 Val. Loss: 0.067
2024-10-12 19:55 - INFO - 	 ROC-AUC: 0.985
2024-10-12 19:55 - INFO - 	 PR-AUC: 0.869
2024-10-12 19:55 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 19:55 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 19:55 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 19:55 - INFO - 	 Best PR-AUC: 0.869
2024-10-12 19:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 19:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.850
2024-10-12 19:55 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 19:55 - INFO - ---------------------------------------------
2024-10-12 19:56 - INFO - ---------------------------------------------
2024-10-12 19:56 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 19:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98703
2024-10-12 19:56 - INFO - 	 Train Loss: 0.068
2024-10-12 19:56 - INFO - 	 Val. Loss: 0.063
2024-10-12 19:56 - INFO - 	 ROC-AUC: 0.987
2024-10-12 19:56 - INFO - 	 PR-AUC: 0.885
2024-10-12 19:56 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 19:56 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 19:56 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 19:56 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 19:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 19:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 19:56 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 19:56 - INFO - ---------------------------------------------
2024-10-12 19:56 - INFO - ---------------------------------------------
2024-10-12 19:56 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 19:56 - INFO - 	 Train Loss: 0.064
2024-10-12 19:56 - INFO - 	 Val. Loss: 0.066
2024-10-12 19:56 - INFO - 	 ROC-AUC: 0.987
2024-10-12 19:56 - INFO - 	 PR-AUC: 0.875
2024-10-12 19:56 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 19:56 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 19:56 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 19:56 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 19:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 19:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 19:56 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 19:56 - INFO - ---------------------------------------------
2024-10-12 19:57 - INFO - ---------------------------------------------
2024-10-12 19:57 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 19:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98754
2024-10-12 19:57 - INFO - 	 Train Loss: 0.062
2024-10-12 19:57 - INFO - 	 Val. Loss: 0.061
2024-10-12 19:57 - INFO - 	 ROC-AUC: 0.988
2024-10-12 19:57 - INFO - 	 PR-AUC: 0.879
2024-10-12 19:57 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 19:57 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 19:57 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 19:57 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 19:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 19:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 19:57 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 19:57 - INFO - ---------------------------------------------
2024-10-12 19:57 - INFO - ---------------------------------------------
2024-10-12 19:57 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 19:57 - INFO - 	 Train Loss: 0.060
2024-10-12 19:57 - INFO - 	 Val. Loss: 0.062
2024-10-12 19:57 - INFO - 	 ROC-AUC: 0.987
2024-10-12 19:57 - INFO - 	 PR-AUC: 0.877
2024-10-12 19:57 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 19:57 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 19:57 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 19:57 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 19:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 19:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 19:57 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 19:57 - INFO - ---------------------------------------------
2024-10-12 19:58 - INFO - ---------------------------------------------
2024-10-12 19:58 - INFO - Epoch: 08 | Time: 0m 32s
2024-10-12 19:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9886
2024-10-12 19:58 - INFO - 	 Train Loss: 0.058
2024-10-12 19:58 - INFO - 	 Val. Loss: 0.057
2024-10-12 19:58 - INFO - 	 ROC-AUC: 0.989
2024-10-12 19:58 - INFO - 	 PR-AUC: 0.897
2024-10-12 19:58 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 19:58 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 19:58 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 19:58 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 19:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 19:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.896
2024-10-12 19:58 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 19:58 - INFO - ---------------------------------------------
2024-10-12 19:58 - INFO - ---------------------------------------------
2024-10-12 19:58 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 19:58 - INFO - 	 Train Loss: 0.057
2024-10-12 19:58 - INFO - 	 Val. Loss: 0.057
2024-10-12 19:58 - INFO - 	 ROC-AUC: 0.988
2024-10-12 19:58 - INFO - 	 PR-AUC: 0.898
2024-10-12 19:58 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 19:58 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 19:58 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 19:58 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 19:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 19:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 19:58 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 19:58 - INFO - ---------------------------------------------
2024-10-12 19:59 - INFO - ---------------------------------------------
2024-10-12 19:59 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 19:59 - INFO - 	 Train Loss: 0.055
2024-10-12 19:59 - INFO - 	 Val. Loss: 0.059
2024-10-12 19:59 - INFO - 	 ROC-AUC: 0.988
2024-10-12 19:59 - INFO - 	 PR-AUC: 0.894
2024-10-12 19:59 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 19:59 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 19:59 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 19:59 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 19:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 19:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 19:59 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 19:59 - INFO - ---------------------------------------------
2024-10-12 20:00 - INFO - Fit the preprocessing pipeline
2024-10-12 20:00 - INFO - Training using device: cuda
2024-10-12 20:00 - INFO - Creating generators
2024-10-12 20:00 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:00 - INFO - * Model:
2024-10-12 20:00 - INFO - * -----------
2024-10-12 20:00 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:00 - INFO - * -----------
2024-10-12 20:00 - INFO - Evaluating model based on: rocauc
2024-10-12 20:00 - INFO - Training..

2024-10-12 20:01 - INFO - ---------------------------------------------
2024-10-12 20:01 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 20:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97928
2024-10-12 20:01 - INFO - 	 Train Loss: 0.152
2024-10-12 20:01 - INFO - 	 Val. Loss: 0.080
2024-10-12 20:01 - INFO - 	 ROC-AUC: 0.979
2024-10-12 20:01 - INFO - 	 PR-AUC: 0.806
2024-10-12 20:01 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:01 - INFO - 	 Best Val. Loss: 0.080
2024-10-12 20:01 - INFO - 	 Best ROC-AUC: 0.979
2024-10-12 20:01 - INFO - 	 Best PR-AUC: 0.806
2024-10-12 20:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 20:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.787
2024-10-12 20:01 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 20:01 - INFO - ---------------------------------------------
2024-10-12 20:01 - INFO - ---------------------------------------------
2024-10-12 20:01 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98437
2024-10-12 20:01 - INFO - 	 Train Loss: 0.082
2024-10-12 20:01 - INFO - 	 Val. Loss: 0.068
2024-10-12 20:01 - INFO - 	 ROC-AUC: 0.984
2024-10-12 20:01 - INFO - 	 PR-AUC: 0.861
2024-10-12 20:01 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:01 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 20:01 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 20:01 - INFO - 	 Best PR-AUC: 0.861
2024-10-12 20:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.839
2024-10-12 20:01 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 20:01 - INFO - ---------------------------------------------
2024-10-12 20:02 - INFO - ---------------------------------------------
2024-10-12 20:02 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98666
2024-10-12 20:02 - INFO - 	 Train Loss: 0.073
2024-10-12 20:02 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:02 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:02 - INFO - 	 PR-AUC: 0.866
2024-10-12 20:02 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:02 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:02 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:02 - INFO - 	 Best PR-AUC: 0.866
2024-10-12 20:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.856
2024-10-12 20:02 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 20:02 - INFO - ---------------------------------------------
2024-10-12 20:02 - INFO - ---------------------------------------------
2024-10-12 20:02 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98711
2024-10-12 20:02 - INFO - 	 Train Loss: 0.068
2024-10-12 20:02 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:02 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:02 - INFO - 	 PR-AUC: 0.883
2024-10-12 20:02 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:02 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:02 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:02 - INFO - 	 Best PR-AUC: 0.883
2024-10-12 20:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 20:02 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 20:02 - INFO - ---------------------------------------------
2024-10-12 20:03 - INFO - ---------------------------------------------
2024-10-12 20:03 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:03 - INFO - 	 Train Loss: 0.065
2024-10-12 20:03 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:03 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:03 - INFO - 	 PR-AUC: 0.884
2024-10-12 20:03 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:03 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:03 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:03 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 20:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.872
2024-10-12 20:03 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:03 - INFO - ---------------------------------------------
2024-10-12 20:04 - INFO - ---------------------------------------------
2024-10-12 20:04 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98732
2024-10-12 20:04 - INFO - 	 Train Loss: 0.062
2024-10-12 20:04 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:04 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:04 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:04 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:04 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 20:04 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:04 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 20:04 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:04 - INFO - ---------------------------------------------
2024-10-12 20:04 - INFO - ---------------------------------------------
2024-10-12 20:04 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98758
2024-10-12 20:04 - INFO - 	 Train Loss: 0.061
2024-10-12 20:04 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:04 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:04 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:04 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:04 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:04 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:04 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 20:04 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:04 - INFO - ---------------------------------------------
2024-10-12 20:05 - INFO - ---------------------------------------------
2024-10-12 20:05 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9876
2024-10-12 20:05 - INFO - 	 Train Loss: 0.059
2024-10-12 20:05 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:05 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:05 - INFO - 	 PR-AUC: 0.894
2024-10-12 20:05 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:05 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:05 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:05 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 20:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 20:05 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:05 - INFO - ---------------------------------------------
2024-10-12 20:05 - INFO - ---------------------------------------------
2024-10-12 20:05 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 20:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98822
2024-10-12 20:05 - INFO - 	 Train Loss: 0.057
2024-10-12 20:05 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:05 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:05 - INFO - 	 PR-AUC: 0.899
2024-10-12 20:05 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:05 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:05 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:05 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 20:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.899
2024-10-12 20:05 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:05 - INFO - ---------------------------------------------
2024-10-12 20:06 - INFO - ---------------------------------------------
2024-10-12 20:06 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 20:06 - INFO - 	 Train Loss: 0.056
2024-10-12 20:06 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:06 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:06 - INFO - 	 PR-AUC: 0.892
2024-10-12 20:06 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:06 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:06 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:06 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 20:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.899
2024-10-12 20:06 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:06 - INFO - ---------------------------------------------
2024-10-12 20:07 - INFO - Fit the preprocessing pipeline
2024-10-12 20:07 - INFO - Training using device: cuda
2024-10-12 20:07 - INFO - Creating generators
2024-10-12 20:07 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:07 - INFO - * Model:
2024-10-12 20:07 - INFO - * -----------
2024-10-12 20:07 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:07 - INFO - * -----------
2024-10-12 20:07 - INFO - Evaluating model based on: rocauc
2024-10-12 20:07 - INFO - Training..

2024-10-12 20:08 - INFO - ---------------------------------------------
2024-10-12 20:08 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97771
2024-10-12 20:08 - INFO - 	 Train Loss: 0.159
2024-10-12 20:08 - INFO - 	 Val. Loss: 0.084
2024-10-12 20:08 - INFO - 	 ROC-AUC: 0.978
2024-10-12 20:08 - INFO - 	 PR-AUC: 0.781
2024-10-12 20:08 - INFO - 	 Recall for 0.4 precision: 0.963
2024-10-12 20:08 - INFO - 	 Best Val. Loss: 0.084
2024-10-12 20:08 - INFO - 	 Best ROC-AUC: 0.978
2024-10-12 20:08 - INFO - 	 Best PR-AUC: 0.781
2024-10-12 20:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 20:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.783
2024-10-12 20:08 - INFO - 	 Best Recall for 0.4 precision: 0.963
2024-10-12 20:08 - INFO - ---------------------------------------------
2024-10-12 20:08 - INFO - ---------------------------------------------
2024-10-12 20:08 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98516
2024-10-12 20:08 - INFO - 	 Train Loss: 0.083
2024-10-12 20:08 - INFO - 	 Val. Loss: 0.069
2024-10-12 20:08 - INFO - 	 ROC-AUC: 0.985
2024-10-12 20:08 - INFO - 	 PR-AUC: 0.861
2024-10-12 20:08 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:08 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 20:08 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 20:08 - INFO - 	 Best PR-AUC: 0.861
2024-10-12 20:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.842
2024-10-12 20:08 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 20:08 - INFO - ---------------------------------------------
2024-10-12 20:09 - INFO - ---------------------------------------------
2024-10-12 20:09 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98772
2024-10-12 20:09 - INFO - 	 Train Loss: 0.073
2024-10-12 20:09 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:09 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:09 - INFO - 	 PR-AUC: 0.878
2024-10-12 20:09 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:09 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 20:09 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:09 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 20:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.850
2024-10-12 20:09 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:09 - INFO - ---------------------------------------------
2024-10-12 20:09 - INFO - ---------------------------------------------
2024-10-12 20:09 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:09 - INFO - 	 Train Loss: 0.068
2024-10-12 20:09 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:09 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:09 - INFO - 	 PR-AUC: 0.875
2024-10-12 20:09 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:09 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 20:09 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:09 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 20:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.850
2024-10-12 20:09 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:09 - INFO - ---------------------------------------------
2024-10-12 20:10 - INFO - ---------------------------------------------
2024-10-12 20:10 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:10 - INFO - 	 Train Loss: 0.065
2024-10-12 20:10 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:10 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:10 - INFO - 	 PR-AUC: 0.878
2024-10-12 20:10 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:10 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:10 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:10 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 20:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.876
2024-10-12 20:10 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:10 - INFO - ---------------------------------------------
2024-10-12 20:10 - INFO - ---------------------------------------------
2024-10-12 20:10 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:10 - INFO - 	 Train Loss: 0.062
2024-10-12 20:10 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:10 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:10 - INFO - 	 PR-AUC: 0.876
2024-10-12 20:10 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:10 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:10 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:10 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 20:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.876
2024-10-12 20:10 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:10 - INFO - ---------------------------------------------
2024-10-12 20:12 - INFO - Fit the preprocessing pipeline
2024-10-12 20:12 - INFO - Training using device: cuda
2024-10-12 20:12 - INFO - Creating generators
2024-10-12 20:12 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:12 - INFO - * Model:
2024-10-12 20:12 - INFO - * -----------
2024-10-12 20:12 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:12 - INFO - * -----------
2024-10-12 20:12 - INFO - Evaluating model based on: rocauc
2024-10-12 20:12 - INFO - Training..

2024-10-12 20:13 - INFO - ---------------------------------------------
2024-10-12 20:13 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 20:13 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9816
2024-10-12 20:13 - INFO - 	 Train Loss: 0.153
2024-10-12 20:13 - INFO - 	 Val. Loss: 0.076
2024-10-12 20:13 - INFO - 	 ROC-AUC: 0.982
2024-10-12 20:13 - INFO - 	 PR-AUC: 0.819
2024-10-12 20:13 - INFO - 	 Recall for 0.4 precision: 0.972
2024-10-12 20:13 - INFO - 	 Best Val. Loss: 0.076
2024-10-12 20:13 - INFO - 	 Best ROC-AUC: 0.982
2024-10-12 20:13 - INFO - 	 Best PR-AUC: 0.819
2024-10-12 20:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 20:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.790
2024-10-12 20:13 - INFO - 	 Best Recall for 0.4 precision: 0.972
2024-10-12 20:13 - INFO - ---------------------------------------------
2024-10-12 20:13 - INFO - ---------------------------------------------
2024-10-12 20:13 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 20:13 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98647
2024-10-12 20:13 - INFO - 	 Train Loss: 0.080
2024-10-12 20:13 - INFO - 	 Val. Loss: 0.065
2024-10-12 20:13 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:13 - INFO - 	 PR-AUC: 0.879
2024-10-12 20:13 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:13 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 20:13 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:13 - INFO - 	 Best PR-AUC: 0.879
2024-10-12 20:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.842
2024-10-12 20:13 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:13 - INFO - ---------------------------------------------
2024-10-12 20:14 - INFO - ---------------------------------------------
2024-10-12 20:14 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98762
2024-10-12 20:14 - INFO - 	 Train Loss: 0.073
2024-10-12 20:14 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:14 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:14 - INFO - 	 PR-AUC: 0.884
2024-10-12 20:14 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:14 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:14 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:14 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 20:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.861
2024-10-12 20:14 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:14 - INFO - ---------------------------------------------
2024-10-12 20:15 - INFO - ---------------------------------------------
2024-10-12 20:15 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 20:15 - INFO - 	 Train Loss: 0.068
2024-10-12 20:15 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:15 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:15 - INFO - 	 PR-AUC: 0.883
2024-10-12 20:15 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:15 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:15 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:15 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 20:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.861
2024-10-12 20:15 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:15 - INFO - ---------------------------------------------
2024-10-12 20:15 - INFO - ---------------------------------------------
2024-10-12 20:15 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98824
2024-10-12 20:15 - INFO - 	 Train Loss: 0.064
2024-10-12 20:15 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:15 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:15 - INFO - 	 PR-AUC: 0.889
2024-10-12 20:15 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:15 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 20:15 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:15 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 20:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.870
2024-10-12 20:15 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:15 - INFO - ---------------------------------------------
2024-10-12 20:16 - INFO - ---------------------------------------------
2024-10-12 20:16 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98865
2024-10-12 20:16 - INFO - 	 Train Loss: 0.061
2024-10-12 20:16 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:16 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:16 - INFO - 	 PR-AUC: 0.895
2024-10-12 20:16 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 20:16 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:16 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:16 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 20:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 20:16 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:16 - INFO - ---------------------------------------------
2024-10-12 20:16 - INFO - ---------------------------------------------
2024-10-12 20:16 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:16 - INFO - 	 Train Loss: 0.059
2024-10-12 20:16 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:16 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:16 - INFO - 	 PR-AUC: 0.892
2024-10-12 20:16 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 20:16 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:16 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:16 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 20:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 20:16 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:16 - INFO - ---------------------------------------------
2024-10-12 20:17 - INFO - ---------------------------------------------
2024-10-12 20:17 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98985
2024-10-12 20:17 - INFO - 	 Train Loss: 0.057
2024-10-12 20:17 - INFO - 	 Val. Loss: 0.055
2024-10-12 20:17 - INFO - 	 ROC-AUC: 0.990
2024-10-12 20:17 - INFO - 	 PR-AUC: 0.903
2024-10-12 20:17 - INFO - 	 Recall for 0.4 precision: 0.982
2024-10-12 20:17 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 20:17 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 20:17 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 20:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 20:17 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 20:17 - INFO - ---------------------------------------------
2024-10-12 20:17 - INFO - ---------------------------------------------
2024-10-12 20:17 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 20:17 - INFO - 	 Train Loss: 0.056
2024-10-12 20:17 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:17 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:17 - INFO - 	 PR-AUC: 0.892
2024-10-12 20:17 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:17 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 20:17 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 20:17 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 20:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 20:17 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 20:17 - INFO - ---------------------------------------------
2024-10-12 20:18 - INFO - ---------------------------------------------
2024-10-12 20:18 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 20:18 - INFO - 	 Train Loss: 0.055
2024-10-12 20:18 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:18 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:18 - INFO - 	 PR-AUC: 0.896
2024-10-12 20:18 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:18 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 20:18 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 20:18 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 20:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 20:18 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 20:18 - INFO - ---------------------------------------------
2024-10-12 20:19 - INFO - Fit the preprocessing pipeline
2024-10-12 20:19 - INFO - Training using device: cuda
2024-10-12 20:19 - INFO - Creating generators
2024-10-12 20:19 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:19 - INFO - * Model:
2024-10-12 20:19 - INFO - * -----------
2024-10-12 20:19 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:19 - INFO - * -----------
2024-10-12 20:19 - INFO - Evaluating model based on: rocauc
2024-10-12 20:19 - INFO - Training..

2024-10-12 20:20 - INFO - ---------------------------------------------
2024-10-12 20:20 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97872
2024-10-12 20:20 - INFO - 	 Train Loss: 0.156
2024-10-12 20:20 - INFO - 	 Val. Loss: 0.081
2024-10-12 20:20 - INFO - 	 ROC-AUC: 0.979
2024-10-12 20:20 - INFO - 	 PR-AUC: 0.827
2024-10-12 20:20 - INFO - 	 Recall for 0.4 precision: 0.960
2024-10-12 20:20 - INFO - 	 Best Val. Loss: 0.081
2024-10-12 20:20 - INFO - 	 Best ROC-AUC: 0.979
2024-10-12 20:20 - INFO - 	 Best PR-AUC: 0.827
2024-10-12 20:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.975
2024-10-12 20:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.792
2024-10-12 20:20 - INFO - 	 Best Recall for 0.4 precision: 0.960
2024-10-12 20:20 - INFO - ---------------------------------------------
2024-10-12 20:20 - INFO - ---------------------------------------------
2024-10-12 20:20 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.986
2024-10-12 20:20 - INFO - 	 Train Loss: 0.083
2024-10-12 20:20 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:20 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:20 - INFO - 	 PR-AUC: 0.878
2024-10-12 20:20 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:20 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:20 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:20 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 20:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.832
2024-10-12 20:20 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:20 - INFO - ---------------------------------------------
2024-10-12 20:21 - INFO - ---------------------------------------------
2024-10-12 20:21 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98605
2024-10-12 20:21 - INFO - 	 Train Loss: 0.074
2024-10-12 20:21 - INFO - 	 Val. Loss: 0.067
2024-10-12 20:21 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:21 - INFO - 	 PR-AUC: 0.880
2024-10-12 20:21 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:21 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:21 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:21 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 20:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 20:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.857
2024-10-12 20:21 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:21 - INFO - ---------------------------------------------
2024-10-12 20:21 - INFO - ---------------------------------------------
2024-10-12 20:21 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98662
2024-10-12 20:21 - INFO - 	 Train Loss: 0.067
2024-10-12 20:21 - INFO - 	 Val. Loss: 0.063
2024-10-12 20:21 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:21 - INFO - 	 PR-AUC: 0.886
2024-10-12 20:21 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:21 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 20:21 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:21 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.866
2024-10-12 20:21 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:21 - INFO - ---------------------------------------------
2024-10-12 20:22 - INFO - ---------------------------------------------
2024-10-12 20:22 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98717
2024-10-12 20:22 - INFO - 	 Train Loss: 0.064
2024-10-12 20:22 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:22 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:22 - INFO - 	 PR-AUC: 0.887
2024-10-12 20:22 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:22 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:22 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:22 - INFO - 	 Best PR-AUC: 0.887
2024-10-12 20:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 20:22 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:22 - INFO - ---------------------------------------------
2024-10-12 20:22 - INFO - ---------------------------------------------
2024-10-12 20:22 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:22 - INFO - 	 Train Loss: 0.062
2024-10-12 20:22 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:22 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:22 - INFO - 	 PR-AUC: 0.878
2024-10-12 20:22 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:22 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:22 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:22 - INFO - 	 Best PR-AUC: 0.887
2024-10-12 20:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 20:22 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 20:22 - INFO - ---------------------------------------------
2024-10-12 20:23 - INFO - ---------------------------------------------
2024-10-12 20:23 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:23 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98742
2024-10-12 20:23 - INFO - 	 Train Loss: 0.060
2024-10-12 20:23 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:23 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:23 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:23 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:23 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:23 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:23 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.869
2024-10-12 20:23 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 20:23 - INFO - ---------------------------------------------
2024-10-12 20:24 - INFO - ---------------------------------------------
2024-10-12 20:24 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:24 - INFO - 	 Train Loss: 0.059
2024-10-12 20:24 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:24 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:24 - INFO - 	 PR-AUC: 0.885
2024-10-12 20:24 - INFO - 	 Recall for 0.4 precision: 0.972
2024-10-12 20:24 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:24 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:24 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.869
2024-10-12 20:24 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 20:24 - INFO - ---------------------------------------------
2024-10-12 20:24 - INFO - ---------------------------------------------
2024-10-12 20:24 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 20:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98799
2024-10-12 20:24 - INFO - 	 Train Loss: 0.056
2024-10-12 20:24 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:24 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:24 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:24 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:24 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:24 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:24 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.869
2024-10-12 20:24 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 20:24 - INFO - ---------------------------------------------
2024-10-12 20:25 - INFO - ---------------------------------------------
2024-10-12 20:25 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 20:25 - INFO - 	 New best val_rocauc loss was found, current best value is 0.988
2024-10-12 20:25 - INFO - 	 Train Loss: 0.056
2024-10-12 20:25 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:25 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:25 - INFO - 	 PR-AUC: 0.897
2024-10-12 20:25 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:25 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:25 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:25 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 20:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.888
2024-10-12 20:25 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 20:25 - INFO - ---------------------------------------------
2024-10-12 20:26 - INFO - Fit the preprocessing pipeline
2024-10-12 20:26 - INFO - Training using device: cuda
2024-10-12 20:26 - INFO - Creating generators
2024-10-12 20:26 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:26 - INFO - * Model:
2024-10-12 20:26 - INFO - * -----------
2024-10-12 20:26 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:26 - INFO - * -----------
2024-10-12 20:26 - INFO - Evaluating model based on: rocauc
2024-10-12 20:26 - INFO - Training..

2024-10-12 20:27 - INFO - ---------------------------------------------
2024-10-12 20:27 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97713
2024-10-12 20:27 - INFO - 	 Train Loss: 0.163
2024-10-12 20:27 - INFO - 	 Val. Loss: 0.085
2024-10-12 20:27 - INFO - 	 ROC-AUC: 0.977
2024-10-12 20:27 - INFO - 	 PR-AUC: 0.791
2024-10-12 20:27 - INFO - 	 Recall for 0.4 precision: 0.965
2024-10-12 20:27 - INFO - 	 Best Val. Loss: 0.085
2024-10-12 20:27 - INFO - 	 Best ROC-AUC: 0.977
2024-10-12 20:27 - INFO - 	 Best PR-AUC: 0.791
2024-10-12 20:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.973
2024-10-12 20:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.760
2024-10-12 20:27 - INFO - 	 Best Recall for 0.4 precision: 0.965
2024-10-12 20:27 - INFO - ---------------------------------------------
2024-10-12 20:27 - INFO - ---------------------------------------------
2024-10-12 20:27 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98499
2024-10-12 20:27 - INFO - 	 Train Loss: 0.084
2024-10-12 20:27 - INFO - 	 Val. Loss: 0.068
2024-10-12 20:27 - INFO - 	 ROC-AUC: 0.985
2024-10-12 20:27 - INFO - 	 PR-AUC: 0.863
2024-10-12 20:27 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:27 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 20:27 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 20:27 - INFO - 	 Best PR-AUC: 0.863
2024-10-12 20:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 20:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.831
2024-10-12 20:27 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:27 - INFO - ---------------------------------------------
2024-10-12 20:28 - INFO - ---------------------------------------------
2024-10-12 20:28 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98556
2024-10-12 20:28 - INFO - 	 Train Loss: 0.075
2024-10-12 20:28 - INFO - 	 Val. Loss: 0.067
2024-10-12 20:28 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:28 - INFO - 	 PR-AUC: 0.872
2024-10-12 20:28 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:28 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 20:28 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:28 - INFO - 	 Best PR-AUC: 0.872
2024-10-12 20:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.844
2024-10-12 20:28 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:28 - INFO - ---------------------------------------------
2024-10-12 20:28 - INFO - ---------------------------------------------
2024-10-12 20:28 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 20:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98737
2024-10-12 20:28 - INFO - 	 Train Loss: 0.069
2024-10-12 20:28 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:28 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:28 - INFO - 	 PR-AUC: 0.886
2024-10-12 20:28 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:28 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:28 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:28 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.860
2024-10-12 20:28 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:28 - INFO - ---------------------------------------------
2024-10-12 20:29 - INFO - ---------------------------------------------
2024-10-12 20:29 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:29 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98758
2024-10-12 20:29 - INFO - 	 Train Loss: 0.066
2024-10-12 20:29 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:29 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:29 - INFO - 	 PR-AUC: 0.884
2024-10-12 20:29 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:29 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 20:29 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:29 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.860
2024-10-12 20:29 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:29 - INFO - ---------------------------------------------
2024-10-12 20:29 - INFO - ---------------------------------------------
2024-10-12 20:29 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:29 - INFO - 	 Train Loss: 0.062
2024-10-12 20:29 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:29 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:29 - INFO - 	 PR-AUC: 0.889
2024-10-12 20:29 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:29 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 20:29 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:29 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 20:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 20:29 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:29 - INFO - ---------------------------------------------
2024-10-12 20:30 - INFO - ---------------------------------------------
2024-10-12 20:30 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:30 - INFO - 	 Train Loss: 0.060
2024-10-12 20:30 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:30 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:30 - INFO - 	 PR-AUC: 0.883
2024-10-12 20:30 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:30 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 20:30 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:30 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 20:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 20:30 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:30 - INFO - ---------------------------------------------
2024-10-12 20:30 - INFO - ---------------------------------------------
2024-10-12 20:30 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98762
2024-10-12 20:30 - INFO - 	 Train Loss: 0.059
2024-10-12 20:30 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:30 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:30 - INFO - 	 PR-AUC: 0.895
2024-10-12 20:30 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:30 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 20:30 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:30 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 20:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 20:30 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:30 - INFO - ---------------------------------------------
2024-10-12 20:31 - INFO - ---------------------------------------------
2024-10-12 20:31 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 20:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98849
2024-10-12 20:31 - INFO - 	 Train Loss: 0.058
2024-10-12 20:31 - INFO - 	 Val. Loss: 0.056
2024-10-12 20:31 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:31 - INFO - 	 PR-AUC: 0.900
2024-10-12 20:31 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:31 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:31 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:31 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 20:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 20:31 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:31 - INFO - ---------------------------------------------
2024-10-12 20:31 - INFO - ---------------------------------------------
2024-10-12 20:31 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 20:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98907
2024-10-12 20:31 - INFO - 	 Train Loss: 0.057
2024-10-12 20:31 - INFO - 	 Val. Loss: 0.057
2024-10-12 20:31 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:31 - INFO - 	 PR-AUC: 0.899
2024-10-12 20:31 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 20:31 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:31 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:31 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 20:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 20:31 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:31 - INFO - ---------------------------------------------
2024-10-12 20:33 - INFO - Fit the preprocessing pipeline
2024-10-12 20:33 - INFO - Training using device: cuda
2024-10-12 20:33 - INFO - Creating generators
2024-10-12 20:33 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:33 - INFO - * Model:
2024-10-12 20:33 - INFO - * -----------
2024-10-12 20:33 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:33 - INFO - * -----------
2024-10-12 20:33 - INFO - Evaluating model based on: rocauc
2024-10-12 20:33 - INFO - Training..

2024-10-12 20:33 - INFO - ---------------------------------------------
2024-10-12 20:33 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97627
2024-10-12 20:33 - INFO - 	 Train Loss: 0.158
2024-10-12 20:33 - INFO - 	 Val. Loss: 0.088
2024-10-12 20:33 - INFO - 	 ROC-AUC: 0.976
2024-10-12 20:33 - INFO - 	 PR-AUC: 0.796
2024-10-12 20:33 - INFO - 	 Recall for 0.4 precision: 0.959
2024-10-12 20:33 - INFO - 	 Best Val. Loss: 0.088
2024-10-12 20:33 - INFO - 	 Best ROC-AUC: 0.976
2024-10-12 20:33 - INFO - 	 Best PR-AUC: 0.796
2024-10-12 20:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.972
2024-10-12 20:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.757
2024-10-12 20:33 - INFO - 	 Best Recall for 0.4 precision: 0.959
2024-10-12 20:33 - INFO - ---------------------------------------------
2024-10-12 20:34 - INFO - ---------------------------------------------
2024-10-12 20:34 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:34 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9847
2024-10-12 20:34 - INFO - 	 Train Loss: 0.084
2024-10-12 20:34 - INFO - 	 Val. Loss: 0.074
2024-10-12 20:34 - INFO - 	 ROC-AUC: 0.985
2024-10-12 20:34 - INFO - 	 PR-AUC: 0.854
2024-10-12 20:34 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:34 - INFO - 	 Best Val. Loss: 0.074
2024-10-12 20:34 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 20:34 - INFO - 	 Best PR-AUC: 0.854
2024-10-12 20:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 20:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.822
2024-10-12 20:34 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 20:34 - INFO - ---------------------------------------------
2024-10-12 20:35 - INFO - ---------------------------------------------
2024-10-12 20:35 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98696
2024-10-12 20:35 - INFO - 	 Train Loss: 0.073
2024-10-12 20:35 - INFO - 	 Val. Loss: 0.067
2024-10-12 20:35 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:35 - INFO - 	 PR-AUC: 0.873
2024-10-12 20:35 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 20:35 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 20:35 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:35 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 20:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.841
2024-10-12 20:35 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:35 - INFO - ---------------------------------------------
2024-10-12 20:35 - INFO - ---------------------------------------------
2024-10-12 20:35 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98697
2024-10-12 20:35 - INFO - 	 Train Loss: 0.068
2024-10-12 20:35 - INFO - 	 Val. Loss: 0.065
2024-10-12 20:35 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:35 - INFO - 	 PR-AUC: 0.871
2024-10-12 20:35 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:35 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 20:35 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:35 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 20:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.841
2024-10-12 20:35 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:35 - INFO - ---------------------------------------------
2024-10-12 20:36 - INFO - ---------------------------------------------
2024-10-12 20:36 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:36 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98699
2024-10-12 20:36 - INFO - 	 Train Loss: 0.066
2024-10-12 20:36 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:36 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:36 - INFO - 	 PR-AUC: 0.879
2024-10-12 20:36 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:36 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:36 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:36 - INFO - 	 Best PR-AUC: 0.879
2024-10-12 20:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 20:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.869
2024-10-12 20:36 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:36 - INFO - ---------------------------------------------
2024-10-12 20:36 - INFO - ---------------------------------------------
2024-10-12 20:36 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:36 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98806
2024-10-12 20:36 - INFO - 	 Train Loss: 0.064
2024-10-12 20:36 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:36 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:36 - INFO - 	 PR-AUC: 0.893
2024-10-12 20:36 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:36 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 20:36 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:36 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 20:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.875
2024-10-12 20:36 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:36 - INFO - ---------------------------------------------
2024-10-12 20:37 - INFO - ---------------------------------------------
2024-10-12 20:37 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:37 - INFO - 	 Train Loss: 0.060
2024-10-12 20:37 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:37 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:37 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:37 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:37 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 20:37 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:37 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 20:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.875
2024-10-12 20:37 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:37 - INFO - ---------------------------------------------
2024-10-12 20:37 - INFO - ---------------------------------------------
2024-10-12 20:37 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98837
2024-10-12 20:37 - INFO - 	 Train Loss: 0.060
2024-10-12 20:37 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:37 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:37 - INFO - 	 PR-AUC: 0.893
2024-10-12 20:37 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:37 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 20:37 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:37 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 20:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.890
2024-10-12 20:37 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:37 - INFO - ---------------------------------------------
2024-10-12 20:38 - INFO - ---------------------------------------------
2024-10-12 20:38 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 20:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98906
2024-10-12 20:38 - INFO - 	 Train Loss: 0.056
2024-10-12 20:38 - INFO - 	 Val. Loss: 0.057
2024-10-12 20:38 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:38 - INFO - 	 PR-AUC: 0.901
2024-10-12 20:38 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:38 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 20:38 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:38 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 20:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.901
2024-10-12 20:38 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:38 - INFO - ---------------------------------------------
2024-10-12 20:38 - INFO - ---------------------------------------------
2024-10-12 20:38 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 20:38 - INFO - 	 Train Loss: 0.056
2024-10-12 20:38 - INFO - 	 Val. Loss: 0.057
2024-10-12 20:38 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:38 - INFO - 	 PR-AUC: 0.897
2024-10-12 20:38 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:38 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 20:38 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:38 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 20:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.901
2024-10-12 20:38 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:38 - INFO - ---------------------------------------------
2024-10-12 20:40 - INFO - Fit the preprocessing pipeline
2024-10-12 20:40 - INFO - Training using device: cuda
2024-10-12 20:40 - INFO - Creating generators
2024-10-12 20:40 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:40 - INFO - * Model:
2024-10-12 20:40 - INFO - * -----------
2024-10-12 20:40 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:40 - INFO - * -----------
2024-10-12 20:40 - INFO - Evaluating model based on: rocauc
2024-10-12 20:40 - INFO - Training..

2024-10-12 20:40 - INFO - ---------------------------------------------
2024-10-12 20:40 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97938
2024-10-12 20:40 - INFO - 	 Train Loss: 0.161
2024-10-12 20:40 - INFO - 	 Val. Loss: 0.082
2024-10-12 20:40 - INFO - 	 ROC-AUC: 0.979
2024-10-12 20:40 - INFO - 	 PR-AUC: 0.807
2024-10-12 20:40 - INFO - 	 Recall for 0.4 precision: 0.966
2024-10-12 20:40 - INFO - 	 Best Val. Loss: 0.082
2024-10-12 20:40 - INFO - 	 Best ROC-AUC: 0.979
2024-10-12 20:40 - INFO - 	 Best PR-AUC: 0.807
2024-10-12 20:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.976
2024-10-12 20:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.791
2024-10-12 20:40 - INFO - 	 Best Recall for 0.4 precision: 0.966
2024-10-12 20:40 - INFO - ---------------------------------------------
2024-10-12 20:41 - INFO - ---------------------------------------------
2024-10-12 20:41 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 20:41 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98417
2024-10-12 20:41 - INFO - 	 Train Loss: 0.085
2024-10-12 20:41 - INFO - 	 Val. Loss: 0.070
2024-10-12 20:41 - INFO - 	 ROC-AUC: 0.984
2024-10-12 20:41 - INFO - 	 PR-AUC: 0.858
2024-10-12 20:41 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:41 - INFO - 	 Best Val. Loss: 0.070
2024-10-12 20:41 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 20:41 - INFO - 	 Best PR-AUC: 0.858
2024-10-12 20:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 20:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.831
2024-10-12 20:41 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:41 - INFO - ---------------------------------------------
2024-10-12 20:41 - INFO - ---------------------------------------------
2024-10-12 20:41 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:41 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98573
2024-10-12 20:41 - INFO - 	 Train Loss: 0.075
2024-10-12 20:41 - INFO - 	 Val. Loss: 0.065
2024-10-12 20:41 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:41 - INFO - 	 PR-AUC: 0.869
2024-10-12 20:41 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:41 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 20:41 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:41 - INFO - 	 Best PR-AUC: 0.869
2024-10-12 20:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 20:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.836
2024-10-12 20:41 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:41 - INFO - ---------------------------------------------
2024-10-12 20:42 - INFO - ---------------------------------------------
2024-10-12 20:42 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98764
2024-10-12 20:42 - INFO - 	 Train Loss: 0.069
2024-10-12 20:42 - INFO - 	 Val. Loss: 0.064
2024-10-12 20:42 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:42 - INFO - 	 PR-AUC: 0.880
2024-10-12 20:42 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 20:42 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 20:42 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:42 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 20:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.850
2024-10-12 20:42 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:42 - INFO - ---------------------------------------------
2024-10-12 20:42 - INFO - ---------------------------------------------
2024-10-12 20:42 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:42 - INFO - 	 Train Loss: 0.065
2024-10-12 20:42 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:42 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:42 - INFO - 	 PR-AUC: 0.874
2024-10-12 20:42 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:42 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 20:42 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:42 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 20:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.850
2024-10-12 20:42 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:42 - INFO - ---------------------------------------------
2024-10-12 20:43 - INFO - ---------------------------------------------
2024-10-12 20:43 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 20:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98815
2024-10-12 20:43 - INFO - 	 Train Loss: 0.063
2024-10-12 20:43 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:43 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:43 - INFO - 	 PR-AUC: 0.886
2024-10-12 20:43 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:43 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:43 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:43 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 20:43 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:43 - INFO - ---------------------------------------------
2024-10-12 20:44 - INFO - ---------------------------------------------
2024-10-12 20:44 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:44 - INFO - 	 Train Loss: 0.061
2024-10-12 20:44 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:44 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:44 - INFO - 	 PR-AUC: 0.876
2024-10-12 20:44 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:44 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:44 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:44 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 20:44 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:44 - INFO - ---------------------------------------------
2024-10-12 20:44 - INFO - ---------------------------------------------
2024-10-12 20:44 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:44 - INFO - 	 Train Loss: 0.058
2024-10-12 20:44 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:44 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:44 - INFO - 	 PR-AUC: 0.883
2024-10-12 20:44 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 20:44 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:44 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:44 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 20:44 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:44 - INFO - ---------------------------------------------
2024-10-12 20:45 - INFO - ---------------------------------------------
2024-10-12 20:45 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 20:45 - INFO - 	 Train Loss: 0.057
2024-10-12 20:45 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:45 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:45 - INFO - 	 PR-AUC: 0.883
2024-10-12 20:45 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:45 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:45 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:45 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 20:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 20:45 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:45 - INFO - ---------------------------------------------
2024-10-12 20:45 - INFO - ---------------------------------------------
2024-10-12 20:45 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 20:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98901
2024-10-12 20:45 - INFO - 	 Train Loss: 0.056
2024-10-12 20:45 - INFO - 	 Val. Loss: 0.055
2024-10-12 20:45 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:45 - INFO - 	 PR-AUC: 0.904
2024-10-12 20:45 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:45 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 20:45 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:45 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 20:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.897
2024-10-12 20:45 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 20:45 - INFO - ---------------------------------------------
2024-10-12 20:47 - INFO - Fit the preprocessing pipeline
2024-10-12 20:47 - INFO - Training using device: cuda
2024-10-12 20:47 - INFO - Creating generators
2024-10-12 20:47 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:47 - INFO - * Model:
2024-10-12 20:47 - INFO - * -----------
2024-10-12 20:47 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:47 - INFO - * -----------
2024-10-12 20:47 - INFO - Evaluating model based on: rocauc
2024-10-12 20:47 - INFO - Training..

2024-10-12 20:47 - INFO - ---------------------------------------------
2024-10-12 20:47 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 20:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9803
2024-10-12 20:47 - INFO - 	 Train Loss: 0.151
2024-10-12 20:47 - INFO - 	 Val. Loss: 0.081
2024-10-12 20:47 - INFO - 	 ROC-AUC: 0.980
2024-10-12 20:47 - INFO - 	 PR-AUC: 0.820
2024-10-12 20:47 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 20:47 - INFO - 	 Best Val. Loss: 0.081
2024-10-12 20:47 - INFO - 	 Best ROC-AUC: 0.980
2024-10-12 20:47 - INFO - 	 Best PR-AUC: 0.820
2024-10-12 20:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 20:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.779
2024-10-12 20:47 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:47 - INFO - ---------------------------------------------
2024-10-12 20:48 - INFO - ---------------------------------------------
2024-10-12 20:48 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 20:48 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9848
2024-10-12 20:48 - INFO - 	 Train Loss: 0.083
2024-10-12 20:48 - INFO - 	 Val. Loss: 0.069
2024-10-12 20:48 - INFO - 	 ROC-AUC: 0.985
2024-10-12 20:48 - INFO - 	 PR-AUC: 0.869
2024-10-12 20:48 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:48 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 20:48 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 20:48 - INFO - 	 Best PR-AUC: 0.869
2024-10-12 20:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.979
2024-10-12 20:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.827
2024-10-12 20:48 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 20:48 - INFO - ---------------------------------------------
2024-10-12 20:48 - INFO - ---------------------------------------------
2024-10-12 20:48 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 20:48 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98676
2024-10-12 20:48 - INFO - 	 Train Loss: 0.073
2024-10-12 20:48 - INFO - 	 Val. Loss: 0.062
2024-10-12 20:48 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:48 - INFO - 	 PR-AUC: 0.876
2024-10-12 20:48 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:48 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 20:48 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:48 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 20:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.854
2024-10-12 20:48 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 20:48 - INFO - ---------------------------------------------
2024-10-12 20:49 - INFO - ---------------------------------------------
2024-10-12 20:49 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 20:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98695
2024-10-12 20:49 - INFO - 	 Train Loss: 0.068
2024-10-12 20:49 - INFO - 	 Val. Loss: 0.063
2024-10-12 20:49 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:49 - INFO - 	 PR-AUC: 0.880
2024-10-12 20:49 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:49 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 20:49 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:49 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 20:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.867
2024-10-12 20:49 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 20:49 - INFO - ---------------------------------------------
2024-10-12 20:49 - INFO - ---------------------------------------------
2024-10-12 20:49 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98806
2024-10-12 20:49 - INFO - 	 Train Loss: 0.065
2024-10-12 20:49 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:49 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:49 - INFO - 	 PR-AUC: 0.894
2024-10-12 20:49 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:49 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 20:49 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:49 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 20:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.883
2024-10-12 20:49 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 20:49 - INFO - ---------------------------------------------
2024-10-12 20:50 - INFO - ---------------------------------------------
2024-10-12 20:50 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 20:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98923
2024-10-12 20:50 - INFO - 	 Train Loss: 0.061
2024-10-12 20:50 - INFO - 	 Val. Loss: 0.056
2024-10-12 20:50 - INFO - 	 ROC-AUC: 0.989
2024-10-12 20:50 - INFO - 	 PR-AUC: 0.897
2024-10-12 20:50 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 20:50 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:50 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:50 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 20:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 20:50 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:50 - INFO - ---------------------------------------------
2024-10-12 20:50 - INFO - ---------------------------------------------
2024-10-12 20:50 - INFO - Epoch: 07 | Time: 0m 32s
2024-10-12 20:50 - INFO - 	 Train Loss: 0.060
2024-10-12 20:50 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:50 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:50 - INFO - 	 PR-AUC: 0.892
2024-10-12 20:50 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:50 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:50 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:50 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 20:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 20:50 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:50 - INFO - ---------------------------------------------
2024-10-12 20:51 - INFO - ---------------------------------------------
2024-10-12 20:51 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:51 - INFO - 	 Train Loss: 0.058
2024-10-12 20:51 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:51 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:51 - INFO - 	 PR-AUC: 0.888
2024-10-12 20:51 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:51 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:51 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:51 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 20:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 20:51 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:51 - INFO - ---------------------------------------------
2024-10-12 20:52 - INFO - ---------------------------------------------
2024-10-12 20:52 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 20:52 - INFO - 	 Train Loss: 0.056
2024-10-12 20:52 - INFO - 	 Val. Loss: 0.060
2024-10-12 20:52 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:52 - INFO - 	 PR-AUC: 0.892
2024-10-12 20:52 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 20:52 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 20:52 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 20:52 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 20:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 20:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 20:52 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 20:52 - INFO - ---------------------------------------------
2024-10-12 20:54 - INFO - Fit the preprocessing pipeline
2024-10-12 20:54 - INFO - Training using device: cuda
2024-10-12 20:54 - INFO - Creating generators
2024-10-12 20:54 - INFO - The model has 651,257 trainable parameters
2024-10-12 20:54 - INFO - * Model:
2024-10-12 20:54 - INFO - * -----------
2024-10-12 20:54 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 20:54 - INFO - * -----------
2024-10-12 20:54 - INFO - Evaluating model based on: rocauc
2024-10-12 20:54 - INFO - Training..

2024-10-12 20:54 - INFO - ---------------------------------------------
2024-10-12 20:54 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 20:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97925
2024-10-12 20:54 - INFO - 	 Train Loss: 0.156
2024-10-12 20:54 - INFO - 	 Val. Loss: 0.081
2024-10-12 20:54 - INFO - 	 ROC-AUC: 0.979
2024-10-12 20:54 - INFO - 	 PR-AUC: 0.801
2024-10-12 20:54 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 20:54 - INFO - 	 Best Val. Loss: 0.081
2024-10-12 20:54 - INFO - 	 Best ROC-AUC: 0.979
2024-10-12 20:54 - INFO - 	 Best PR-AUC: 0.801
2024-10-12 20:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 20:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.797
2024-10-12 20:54 - INFO - 	 Best Recall for 0.4 precision: 0.968
2024-10-12 20:54 - INFO - ---------------------------------------------
2024-10-12 20:55 - INFO - ---------------------------------------------
2024-10-12 20:55 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 20:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98318
2024-10-12 20:55 - INFO - 	 Train Loss: 0.085
2024-10-12 20:55 - INFO - 	 Val. Loss: 0.073
2024-10-12 20:55 - INFO - 	 ROC-AUC: 0.983
2024-10-12 20:55 - INFO - 	 PR-AUC: 0.828
2024-10-12 20:55 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 20:55 - INFO - 	 Best Val. Loss: 0.073
2024-10-12 20:55 - INFO - 	 Best ROC-AUC: 0.983
2024-10-12 20:55 - INFO - 	 Best PR-AUC: 0.828
2024-10-12 20:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.826
2024-10-12 20:55 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 20:55 - INFO - ---------------------------------------------
2024-10-12 20:55 - INFO - ---------------------------------------------
2024-10-12 20:55 - INFO - Epoch: 03 | Time: 0m 32s
2024-10-12 20:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98512
2024-10-12 20:55 - INFO - 	 Train Loss: 0.074
2024-10-12 20:55 - INFO - 	 Val. Loss: 0.069
2024-10-12 20:55 - INFO - 	 ROC-AUC: 0.985
2024-10-12 20:55 - INFO - 	 PR-AUC: 0.846
2024-10-12 20:55 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:55 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 20:55 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 20:55 - INFO - 	 Best PR-AUC: 0.846
2024-10-12 20:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 20:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.858
2024-10-12 20:55 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:55 - INFO - ---------------------------------------------
2024-10-12 20:56 - INFO - ---------------------------------------------
2024-10-12 20:56 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 20:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98603
2024-10-12 20:56 - INFO - 	 Train Loss: 0.068
2024-10-12 20:56 - INFO - 	 Val. Loss: 0.070
2024-10-12 20:56 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:56 - INFO - 	 PR-AUC: 0.853
2024-10-12 20:56 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:56 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 20:56 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 20:56 - INFO - 	 Best PR-AUC: 0.853
2024-10-12 20:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 20:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.855
2024-10-12 20:56 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:56 - INFO - ---------------------------------------------
2024-10-12 20:56 - INFO - ---------------------------------------------
2024-10-12 20:56 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 20:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98731
2024-10-12 20:56 - INFO - 	 Train Loss: 0.065
2024-10-12 20:56 - INFO - 	 Val. Loss: 0.065
2024-10-12 20:56 - INFO - 	 ROC-AUC: 0.987
2024-10-12 20:56 - INFO - 	 PR-AUC: 0.868
2024-10-12 20:56 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:56 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 20:56 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:56 - INFO - 	 Best PR-AUC: 0.868
2024-10-12 20:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.867
2024-10-12 20:56 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:56 - INFO - ---------------------------------------------
2024-10-12 20:57 - INFO - ---------------------------------------------
2024-10-12 20:57 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 20:57 - INFO - 	 Train Loss: 0.062
2024-10-12 20:57 - INFO - 	 Val. Loss: 0.065
2024-10-12 20:57 - INFO - 	 ROC-AUC: 0.986
2024-10-12 20:57 - INFO - 	 PR-AUC: 0.865
2024-10-12 20:57 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 20:57 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 20:57 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 20:57 - INFO - 	 Best PR-AUC: 0.868
2024-10-12 20:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.867
2024-10-12 20:57 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:57 - INFO - ---------------------------------------------
2024-10-12 20:57 - INFO - ---------------------------------------------
2024-10-12 20:57 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 20:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98807
2024-10-12 20:57 - INFO - 	 Train Loss: 0.060
2024-10-12 20:57 - INFO - 	 Val. Loss: 0.058
2024-10-12 20:57 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:57 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:57 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:57 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:57 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:57 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 20:57 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:57 - INFO - ---------------------------------------------
2024-10-12 20:58 - INFO - ---------------------------------------------
2024-10-12 20:58 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 20:58 - INFO - 	 Train Loss: 0.058
2024-10-12 20:58 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:58 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:58 - INFO - 	 PR-AUC: 0.881
2024-10-12 20:58 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:58 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:58 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:58 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 20:58 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:58 - INFO - ---------------------------------------------
2024-10-12 20:58 - INFO - ---------------------------------------------
2024-10-12 20:58 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 20:58 - INFO - 	 Train Loss: 0.057
2024-10-12 20:58 - INFO - 	 Val. Loss: 0.061
2024-10-12 20:58 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:58 - INFO - 	 PR-AUC: 0.874
2024-10-12 20:58 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 20:58 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:58 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:58 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 20:58 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:58 - INFO - ---------------------------------------------
2024-10-12 20:59 - INFO - ---------------------------------------------
2024-10-12 20:59 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 20:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98825
2024-10-12 20:59 - INFO - 	 Train Loss: 0.056
2024-10-12 20:59 - INFO - 	 Val. Loss: 0.059
2024-10-12 20:59 - INFO - 	 ROC-AUC: 0.988
2024-10-12 20:59 - INFO - 	 PR-AUC: 0.891
2024-10-12 20:59 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 20:59 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 20:59 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 20:59 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 20:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 20:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 20:59 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 20:59 - INFO - ---------------------------------------------
2024-10-12 21:00 - INFO - Fit the preprocessing pipeline
2024-10-12 21:00 - INFO - Training using device: cuda
2024-10-12 21:00 - INFO - Creating generators
2024-10-12 21:00 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:00 - INFO - * Model:
2024-10-12 21:00 - INFO - * -----------
2024-10-12 21:00 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:00 - INFO - * -----------
2024-10-12 21:00 - INFO - Evaluating model based on: rocauc
2024-10-12 21:00 - INFO - Training..

2024-10-12 21:01 - INFO - ---------------------------------------------
2024-10-12 21:01 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97717
2024-10-12 21:01 - INFO - 	 Train Loss: 0.160
2024-10-12 21:01 - INFO - 	 Val. Loss: 0.085
2024-10-12 21:01 - INFO - 	 ROC-AUC: 0.977
2024-10-12 21:01 - INFO - 	 PR-AUC: 0.808
2024-10-12 21:01 - INFO - 	 Recall for 0.4 precision: 0.961
2024-10-12 21:01 - INFO - 	 Best Val. Loss: 0.085
2024-10-12 21:01 - INFO - 	 Best ROC-AUC: 0.977
2024-10-12 21:01 - INFO - 	 Best PR-AUC: 0.808
2024-10-12 21:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 21:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.785
2024-10-12 21:01 - INFO - 	 Best Recall for 0.4 precision: 0.961
2024-10-12 21:01 - INFO - ---------------------------------------------
2024-10-12 21:02 - INFO - ---------------------------------------------
2024-10-12 21:02 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98323
2024-10-12 21:02 - INFO - 	 Train Loss: 0.083
2024-10-12 21:02 - INFO - 	 Val. Loss: 0.071
2024-10-12 21:02 - INFO - 	 ROC-AUC: 0.983
2024-10-12 21:02 - INFO - 	 PR-AUC: 0.849
2024-10-12 21:02 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:02 - INFO - 	 Best Val. Loss: 0.071
2024-10-12 21:02 - INFO - 	 Best ROC-AUC: 0.983
2024-10-12 21:02 - INFO - 	 Best PR-AUC: 0.849
2024-10-12 21:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.839
2024-10-12 21:02 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 21:02 - INFO - ---------------------------------------------
2024-10-12 21:02 - INFO - ---------------------------------------------
2024-10-12 21:02 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:02 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98613
2024-10-12 21:02 - INFO - 	 Train Loss: 0.073
2024-10-12 21:02 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:02 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:02 - INFO - 	 PR-AUC: 0.873
2024-10-12 21:02 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:02 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 21:02 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:02 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 21:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:02 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:02 - INFO - ---------------------------------------------
2024-10-12 21:03 - INFO - ---------------------------------------------
2024-10-12 21:03 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 21:03 - INFO - 	 Train Loss: 0.067
2024-10-12 21:03 - INFO - 	 Val. Loss: 0.066
2024-10-12 21:03 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:03 - INFO - 	 PR-AUC: 0.864
2024-10-12 21:03 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:03 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 21:03 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:03 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 21:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:03 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:03 - INFO - ---------------------------------------------
2024-10-12 21:03 - INFO - ---------------------------------------------
2024-10-12 21:03 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 21:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98633
2024-10-12 21:03 - INFO - 	 Train Loss: 0.064
2024-10-12 21:03 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:03 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:03 - INFO - 	 PR-AUC: 0.872
2024-10-12 21:03 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:03 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 21:03 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:03 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 21:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:03 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:03 - INFO - ---------------------------------------------
2024-10-12 21:04 - INFO - ---------------------------------------------
2024-10-12 21:04 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 21:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9867
2024-10-12 21:04 - INFO - 	 Train Loss: 0.062
2024-10-12 21:04 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:04 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:04 - INFO - 	 PR-AUC: 0.875
2024-10-12 21:04 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:04 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 21:04 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:04 - INFO - 	 Best PR-AUC: 0.875
2024-10-12 21:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.881
2024-10-12 21:04 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:04 - INFO - ---------------------------------------------
2024-10-12 21:04 - INFO - ---------------------------------------------
2024-10-12 21:04 - INFO - Epoch: 07 | Time: 0m 32s
2024-10-12 21:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98715
2024-10-12 21:04 - INFO - 	 Train Loss: 0.059
2024-10-12 21:04 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:04 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:04 - INFO - 	 PR-AUC: 0.880
2024-10-12 21:04 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:04 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 21:04 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:04 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 21:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 21:04 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:04 - INFO - ---------------------------------------------
2024-10-12 21:05 - INFO - ---------------------------------------------
2024-10-12 21:05 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98764
2024-10-12 21:05 - INFO - 	 Train Loss: 0.058
2024-10-12 21:05 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:05 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:05 - INFO - 	 PR-AUC: 0.884
2024-10-12 21:05 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 21:05 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 21:05 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:05 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 21:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 21:05 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:05 - INFO - ---------------------------------------------
2024-10-12 21:05 - INFO - ---------------------------------------------
2024-10-12 21:05 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98819
2024-10-12 21:05 - INFO - 	 Train Loss: 0.057
2024-10-12 21:05 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:05 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:05 - INFO - 	 PR-AUC: 0.891
2024-10-12 21:05 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:05 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:05 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:05 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 21:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 21:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.902
2024-10-12 21:05 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:05 - INFO - ---------------------------------------------
2024-10-12 21:06 - INFO - ---------------------------------------------
2024-10-12 21:06 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:06 - INFO - 	 Train Loss: 0.055
2024-10-12 21:06 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:06 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:06 - INFO - 	 PR-AUC: 0.897
2024-10-12 21:06 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:06 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:06 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:06 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 21:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 21:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 21:06 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:06 - INFO - ---------------------------------------------
2024-10-12 21:07 - INFO - Fit the preprocessing pipeline
2024-10-12 21:07 - INFO - Training using device: cuda
2024-10-12 21:07 - INFO - Creating generators
2024-10-12 21:07 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:07 - INFO - * Model:
2024-10-12 21:07 - INFO - * -----------
2024-10-12 21:07 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:07 - INFO - * -----------
2024-10-12 21:07 - INFO - Evaluating model based on: rocauc
2024-10-12 21:07 - INFO - Training..

2024-10-12 21:08 - INFO - ---------------------------------------------
2024-10-12 21:08 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97967
2024-10-12 21:08 - INFO - 	 Train Loss: 0.147
2024-10-12 21:08 - INFO - 	 Val. Loss: 0.091
2024-10-12 21:08 - INFO - 	 ROC-AUC: 0.980
2024-10-12 21:08 - INFO - 	 PR-AUC: 0.816
2024-10-12 21:08 - INFO - 	 Recall for 0.4 precision: 0.967
2024-10-12 21:08 - INFO - 	 Best Val. Loss: 0.091
2024-10-12 21:08 - INFO - 	 Best ROC-AUC: 0.980
2024-10-12 21:08 - INFO - 	 Best PR-AUC: 0.816
2024-10-12 21:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.980
2024-10-12 21:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.795
2024-10-12 21:08 - INFO - 	 Best Recall for 0.4 precision: 0.967
2024-10-12 21:08 - INFO - ---------------------------------------------
2024-10-12 21:08 - INFO - ---------------------------------------------
2024-10-12 21:08 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98539
2024-10-12 21:08 - INFO - 	 Train Loss: 0.081
2024-10-12 21:08 - INFO - 	 Val. Loss: 0.070
2024-10-12 21:08 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:08 - INFO - 	 PR-AUC: 0.871
2024-10-12 21:08 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:08 - INFO - 	 Best Val. Loss: 0.070
2024-10-12 21:08 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:08 - INFO - 	 Best PR-AUC: 0.871
2024-10-12 21:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.853
2024-10-12 21:08 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 21:08 - INFO - ---------------------------------------------
2024-10-12 21:09 - INFO - ---------------------------------------------
2024-10-12 21:09 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:09 - INFO - 	 Train Loss: 0.072
2024-10-12 21:09 - INFO - 	 Val. Loss: 0.069
2024-10-12 21:09 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:09 - INFO - 	 PR-AUC: 0.866
2024-10-12 21:09 - INFO - 	 Recall for 0.4 precision: 0.972
2024-10-12 21:09 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 21:09 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:09 - INFO - 	 Best PR-AUC: 0.871
2024-10-12 21:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.853
2024-10-12 21:09 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 21:09 - INFO - ---------------------------------------------
2024-10-12 21:09 - INFO - ---------------------------------------------
2024-10-12 21:09 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 21:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98688
2024-10-12 21:09 - INFO - 	 Train Loss: 0.066
2024-10-12 21:09 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:09 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:09 - INFO - 	 PR-AUC: 0.880
2024-10-12 21:09 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:09 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:09 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:09 - INFO - 	 Best PR-AUC: 0.880
2024-10-12 21:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 21:09 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:09 - INFO - ---------------------------------------------
2024-10-12 21:10 - INFO - ---------------------------------------------
2024-10-12 21:10 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 21:10 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98718
2024-10-12 21:10 - INFO - 	 Train Loss: 0.064
2024-10-12 21:10 - INFO - 	 Val. Loss: 0.065
2024-10-12 21:10 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:10 - INFO - 	 PR-AUC: 0.886
2024-10-12 21:10 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:10 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:10 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:10 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 21:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.881
2024-10-12 21:10 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:10 - INFO - ---------------------------------------------
2024-10-12 21:11 - INFO - ---------------------------------------------
2024-10-12 21:11 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98733
2024-10-12 21:11 - INFO - 	 Train Loss: 0.061
2024-10-12 21:11 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:11 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:11 - INFO - 	 PR-AUC: 0.885
2024-10-12 21:11 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:11 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:11 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:11 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 21:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 21:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.881
2024-10-12 21:11 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:11 - INFO - ---------------------------------------------
2024-10-12 21:11 - INFO - ---------------------------------------------
2024-10-12 21:11 - INFO - Epoch: 07 | Time: 0m 32s
2024-10-12 21:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9877
2024-10-12 21:11 - INFO - 	 Train Loss: 0.059
2024-10-12 21:11 - INFO - 	 Val. Loss: 0.069
2024-10-12 21:11 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:11 - INFO - 	 PR-AUC: 0.888
2024-10-12 21:11 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:11 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:11 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:11 - INFO - 	 Best PR-AUC: 0.888
2024-10-12 21:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 21:11 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:11 - INFO - ---------------------------------------------
2024-10-12 21:12 - INFO - ---------------------------------------------
2024-10-12 21:12 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98844
2024-10-12 21:12 - INFO - 	 Train Loss: 0.059
2024-10-12 21:12 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:12 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:12 - INFO - 	 PR-AUC: 0.897
2024-10-12 21:12 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:12 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 21:12 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:12 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 21:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.896
2024-10-12 21:12 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:12 - INFO - ---------------------------------------------
2024-10-12 21:12 - INFO - ---------------------------------------------
2024-10-12 21:12 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:12 - INFO - 	 Train Loss: 0.057
2024-10-12 21:12 - INFO - 	 Val. Loss: 0.057
2024-10-12 21:12 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:12 - INFO - 	 PR-AUC: 0.901
2024-10-12 21:12 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:12 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 21:12 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:12 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 21:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 21:12 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:12 - INFO - ---------------------------------------------
2024-10-12 21:13 - INFO - ---------------------------------------------
2024-10-12 21:13 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:13 - INFO - 	 Train Loss: 0.055
2024-10-12 21:13 - INFO - 	 Val. Loss: 0.056
2024-10-12 21:13 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:13 - INFO - 	 PR-AUC: 0.903
2024-10-12 21:13 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:13 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 21:13 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:13 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 21:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 21:13 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:13 - INFO - ---------------------------------------------
2024-10-12 21:14 - INFO - Fit the preprocessing pipeline
2024-10-12 21:14 - INFO - Training using device: cuda
2024-10-12 21:14 - INFO - Creating generators
2024-10-12 21:14 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:14 - INFO - * Model:
2024-10-12 21:14 - INFO - * -----------
2024-10-12 21:14 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:14 - INFO - * -----------
2024-10-12 21:14 - INFO - Evaluating model based on: rocauc
2024-10-12 21:14 - INFO - Training..

2024-10-12 21:15 - INFO - ---------------------------------------------
2024-10-12 21:15 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97749
2024-10-12 21:15 - INFO - 	 Train Loss: 0.153
2024-10-12 21:15 - INFO - 	 Val. Loss: 0.082
2024-10-12 21:15 - INFO - 	 ROC-AUC: 0.977
2024-10-12 21:15 - INFO - 	 PR-AUC: 0.815
2024-10-12 21:15 - INFO - 	 Recall for 0.4 precision: 0.958
2024-10-12 21:15 - INFO - 	 Best Val. Loss: 0.082
2024-10-12 21:15 - INFO - 	 Best ROC-AUC: 0.977
2024-10-12 21:15 - INFO - 	 Best PR-AUC: 0.815
2024-10-12 21:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.976
2024-10-12 21:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.782
2024-10-12 21:15 - INFO - 	 Best Recall for 0.4 precision: 0.958
2024-10-12 21:15 - INFO - ---------------------------------------------
2024-10-12 21:15 - INFO - ---------------------------------------------
2024-10-12 21:15 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 21:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98488
2024-10-12 21:15 - INFO - 	 Train Loss: 0.082
2024-10-12 21:15 - INFO - 	 Val. Loss: 0.069
2024-10-12 21:15 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:15 - INFO - 	 PR-AUC: 0.852
2024-10-12 21:15 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:15 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 21:15 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:15 - INFO - 	 Best PR-AUC: 0.852
2024-10-12 21:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.823
2024-10-12 21:15 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:15 - INFO - ---------------------------------------------
2024-10-12 21:16 - INFO - ---------------------------------------------
2024-10-12 21:16 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:16 - INFO - 	 Train Loss: 0.073
2024-10-12 21:16 - INFO - 	 Val. Loss: 0.074
2024-10-12 21:16 - INFO - 	 ROC-AUC: 0.983
2024-10-12 21:16 - INFO - 	 PR-AUC: 0.853
2024-10-12 21:16 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 21:16 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 21:16 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:16 - INFO - 	 Best PR-AUC: 0.853
2024-10-12 21:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.835
2024-10-12 21:16 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:16 - INFO - ---------------------------------------------
2024-10-12 21:16 - INFO - ---------------------------------------------
2024-10-12 21:16 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 21:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9858
2024-10-12 21:16 - INFO - 	 Train Loss: 0.068
2024-10-12 21:16 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:16 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:16 - INFO - 	 PR-AUC: 0.881
2024-10-12 21:16 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 21:16 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 21:16 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:16 - INFO - 	 Best PR-AUC: 0.881
2024-10-12 21:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.857
2024-10-12 21:16 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:16 - INFO - ---------------------------------------------
2024-10-12 21:17 - INFO - ---------------------------------------------
2024-10-12 21:17 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 21:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98649
2024-10-12 21:17 - INFO - 	 Train Loss: 0.064
2024-10-12 21:17 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:17 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:17 - INFO - 	 PR-AUC: 0.874
2024-10-12 21:17 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:17 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 21:17 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:17 - INFO - 	 Best PR-AUC: 0.881
2024-10-12 21:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.857
2024-10-12 21:17 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:17 - INFO - ---------------------------------------------
2024-10-12 21:17 - INFO - ---------------------------------------------
2024-10-12 21:17 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98716
2024-10-12 21:17 - INFO - 	 Train Loss: 0.062
2024-10-12 21:17 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:17 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:17 - INFO - 	 PR-AUC: 0.873
2024-10-12 21:17 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:17 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 21:17 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:17 - INFO - 	 Best PR-AUC: 0.881
2024-10-12 21:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.857
2024-10-12 21:17 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:17 - INFO - ---------------------------------------------
2024-10-12 21:18 - INFO - ---------------------------------------------
2024-10-12 21:18 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98742
2024-10-12 21:18 - INFO - 	 Train Loss: 0.060
2024-10-12 21:18 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:18 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:18 - INFO - 	 PR-AUC: 0.893
2024-10-12 21:18 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:18 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:18 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:18 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 21:18 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:18 - INFO - ---------------------------------------------
2024-10-12 21:18 - INFO - ---------------------------------------------
2024-10-12 21:18 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:18 - INFO - 	 Train Loss: 0.057
2024-10-12 21:18 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:18 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:18 - INFO - 	 PR-AUC: 0.878
2024-10-12 21:18 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:18 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:18 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:18 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 21:18 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:18 - INFO - ---------------------------------------------
2024-10-12 21:19 - INFO - ---------------------------------------------
2024-10-12 21:19 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:19 - INFO - 	 Train Loss: 0.056
2024-10-12 21:19 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:19 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:19 - INFO - 	 PR-AUC: 0.884
2024-10-12 21:19 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:19 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:19 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:19 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 21:19 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:19 - INFO - ---------------------------------------------
2024-10-12 21:19 - INFO - ---------------------------------------------
2024-10-12 21:19 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98869
2024-10-12 21:19 - INFO - 	 Train Loss: 0.055
2024-10-12 21:19 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:19 - INFO - 	 ROC-AUC: 0.989
2024-10-12 21:19 - INFO - 	 PR-AUC: 0.894
2024-10-12 21:19 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:19 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:19 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:19 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.898
2024-10-12 21:19 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:19 - INFO - ---------------------------------------------
2024-10-12 21:21 - INFO - Fit the preprocessing pipeline
2024-10-12 21:21 - INFO - Training using device: cuda
2024-10-12 21:21 - INFO - Creating generators
2024-10-12 21:21 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:21 - INFO - * Model:
2024-10-12 21:21 - INFO - * -----------
2024-10-12 21:21 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:21 - INFO - * -----------
2024-10-12 21:21 - INFO - Evaluating model based on: rocauc
2024-10-12 21:21 - INFO - Training..

2024-10-12 21:22 - INFO - ---------------------------------------------
2024-10-12 21:22 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97777
2024-10-12 21:22 - INFO - 	 Train Loss: 0.153
2024-10-12 21:22 - INFO - 	 Val. Loss: 0.088
2024-10-12 21:22 - INFO - 	 ROC-AUC: 0.978
2024-10-12 21:22 - INFO - 	 PR-AUC: 0.800
2024-10-12 21:22 - INFO - 	 Recall for 0.4 precision: 0.963
2024-10-12 21:22 - INFO - 	 Best Val. Loss: 0.088
2024-10-12 21:22 - INFO - 	 Best ROC-AUC: 0.978
2024-10-12 21:22 - INFO - 	 Best PR-AUC: 0.800
2024-10-12 21:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.973
2024-10-12 21:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.773
2024-10-12 21:22 - INFO - 	 Best Recall for 0.4 precision: 0.963
2024-10-12 21:22 - INFO - ---------------------------------------------
2024-10-12 21:22 - INFO - ---------------------------------------------
2024-10-12 21:22 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98534
2024-10-12 21:22 - INFO - 	 Train Loss: 0.081
2024-10-12 21:22 - INFO - 	 Val. Loss: 0.067
2024-10-12 21:22 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:22 - INFO - 	 PR-AUC: 0.871
2024-10-12 21:22 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:22 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:22 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:22 - INFO - 	 Best PR-AUC: 0.871
2024-10-12 21:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.979
2024-10-12 21:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.820
2024-10-12 21:22 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 21:22 - INFO - ---------------------------------------------
2024-10-12 21:23 - INFO - ---------------------------------------------
2024-10-12 21:23 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:23 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98692
2024-10-12 21:23 - INFO - 	 Train Loss: 0.071
2024-10-12 21:23 - INFO - 	 Val. Loss: 0.070
2024-10-12 21:23 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:23 - INFO - 	 PR-AUC: 0.876
2024-10-12 21:23 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:23 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:23 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:23 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 21:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.840
2024-10-12 21:23 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 21:23 - INFO - ---------------------------------------------
2024-10-12 21:23 - INFO - ---------------------------------------------
2024-10-12 21:23 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 21:23 - INFO - 	 Train Loss: 0.068
2024-10-12 21:23 - INFO - 	 Val. Loss: 0.076
2024-10-12 21:23 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:23 - INFO - 	 PR-AUC: 0.855
2024-10-12 21:23 - INFO - 	 Recall for 0.4 precision: 0.969
2024-10-12 21:23 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:23 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:23 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 21:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.840
2024-10-12 21:23 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 21:23 - INFO - ---------------------------------------------
2024-10-12 21:24 - INFO - ---------------------------------------------
2024-10-12 21:24 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 21:24 - INFO - 	 Train Loss: 0.064
2024-10-12 21:24 - INFO - 	 Val. Loss: 0.068
2024-10-12 21:24 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:24 - INFO - 	 PR-AUC: 0.866
2024-10-12 21:24 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:24 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:24 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:24 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 21:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.840
2024-10-12 21:24 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 21:24 - INFO - ---------------------------------------------
2024-10-12 21:24 - INFO - ---------------------------------------------
2024-10-12 21:24 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 21:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98764
2024-10-12 21:24 - INFO - 	 Train Loss: 0.063
2024-10-12 21:24 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:24 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:24 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:24 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:24 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:24 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:24 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:24 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:24 - INFO - ---------------------------------------------
2024-10-12 21:25 - INFO - ---------------------------------------------
2024-10-12 21:25 - INFO - Epoch: 07 | Time: 0m 32s
2024-10-12 21:25 - INFO - 	 Train Loss: 0.060
2024-10-12 21:25 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:25 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:25 - INFO - 	 PR-AUC: 0.882
2024-10-12 21:25 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:25 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:25 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:25 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:25 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:25 - INFO - ---------------------------------------------
2024-10-12 21:25 - INFO - ---------------------------------------------
2024-10-12 21:25 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:25 - INFO - 	 Train Loss: 0.059
2024-10-12 21:25 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:25 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:25 - INFO - 	 PR-AUC: 0.879
2024-10-12 21:25 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:25 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:25 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:25 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:25 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:25 - INFO - ---------------------------------------------
2024-10-12 21:26 - INFO - ---------------------------------------------
2024-10-12 21:26 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98818
2024-10-12 21:26 - INFO - 	 Train Loss: 0.057
2024-10-12 21:26 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:26 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:26 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:26 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 21:26 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:26 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:26 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:26 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:26 - INFO - ---------------------------------------------
2024-10-12 21:26 - INFO - ---------------------------------------------
2024-10-12 21:26 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:26 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98891
2024-10-12 21:26 - INFO - 	 Train Loss: 0.056
2024-10-12 21:26 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:26 - INFO - 	 ROC-AUC: 0.989
2024-10-12 21:26 - INFO - 	 PR-AUC: 0.887
2024-10-12 21:26 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:26 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:26 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:26 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:26 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:26 - INFO - ---------------------------------------------
2024-10-12 21:28 - INFO - Fit the preprocessing pipeline
2024-10-12 21:28 - INFO - Training using device: cuda
2024-10-12 21:28 - INFO - Creating generators
2024-10-12 21:28 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:28 - INFO - * Model:
2024-10-12 21:28 - INFO - * -----------
2024-10-12 21:28 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:28 - INFO - * -----------
2024-10-12 21:28 - INFO - Evaluating model based on: rocauc
2024-10-12 21:28 - INFO - Training..

2024-10-12 21:28 - INFO - ---------------------------------------------
2024-10-12 21:28 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 21:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98166
2024-10-12 21:28 - INFO - 	 Train Loss: 0.155
2024-10-12 21:28 - INFO - 	 Val. Loss: 0.075
2024-10-12 21:28 - INFO - 	 ROC-AUC: 0.982
2024-10-12 21:28 - INFO - 	 PR-AUC: 0.842
2024-10-12 21:28 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 21:28 - INFO - 	 Best Val. Loss: 0.075
2024-10-12 21:28 - INFO - 	 Best ROC-AUC: 0.982
2024-10-12 21:28 - INFO - 	 Best PR-AUC: 0.842
2024-10-12 21:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 21:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.802
2024-10-12 21:28 - INFO - 	 Best Recall for 0.4 precision: 0.970
2024-10-12 21:28 - INFO - ---------------------------------------------
2024-10-12 21:29 - INFO - ---------------------------------------------
2024-10-12 21:29 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 21:29 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9836
2024-10-12 21:29 - INFO - 	 Train Loss: 0.083
2024-10-12 21:29 - INFO - 	 Val. Loss: 0.072
2024-10-12 21:29 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:29 - INFO - 	 PR-AUC: 0.858
2024-10-12 21:29 - INFO - 	 Recall for 0.4 precision: 0.971
2024-10-12 21:29 - INFO - 	 Best Val. Loss: 0.072
2024-10-12 21:29 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 21:29 - INFO - 	 Best PR-AUC: 0.858
2024-10-12 21:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.980
2024-10-12 21:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.824
2024-10-12 21:29 - INFO - 	 Best Recall for 0.4 precision: 0.971
2024-10-12 21:29 - INFO - ---------------------------------------------
2024-10-12 21:29 - INFO - ---------------------------------------------
2024-10-12 21:29 - INFO - Epoch: 03 | Time: 0m 32s
2024-10-12 21:29 - INFO - 	 Train Loss: 0.072
2024-10-12 21:29 - INFO - 	 Val. Loss: 0.069
2024-10-12 21:29 - INFO - 	 ROC-AUC: 0.983
2024-10-12 21:29 - INFO - 	 PR-AUC: 0.863
2024-10-12 21:29 - INFO - 	 Recall for 0.4 precision: 0.972
2024-10-12 21:29 - INFO - 	 Best Val. Loss: 0.069
2024-10-12 21:29 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 21:29 - INFO - 	 Best PR-AUC: 0.863
2024-10-12 21:29 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.980
2024-10-12 21:29 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.845
2024-10-12 21:29 - INFO - 	 Best Recall for 0.4 precision: 0.972
2024-10-12 21:29 - INFO - ---------------------------------------------
2024-10-12 21:30 - INFO - ---------------------------------------------
2024-10-12 21:30 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 21:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98531
2024-10-12 21:30 - INFO - 	 Train Loss: 0.068
2024-10-12 21:30 - INFO - 	 Val. Loss: 0.067
2024-10-12 21:30 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:30 - INFO - 	 PR-AUC: 0.868
2024-10-12 21:30 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:30 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:30 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:30 - INFO - 	 Best PR-AUC: 0.868
2024-10-12 21:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.856
2024-10-12 21:30 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:30 - INFO - ---------------------------------------------
2024-10-12 21:31 - INFO - ---------------------------------------------
2024-10-12 21:31 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 21:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9874
2024-10-12 21:31 - INFO - 	 Train Loss: 0.065
2024-10-12 21:31 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:31 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:31 - INFO - 	 PR-AUC: 0.882
2024-10-12 21:31 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:31 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:31 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:31 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 21:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:31 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:31 - INFO - ---------------------------------------------
2024-10-12 21:31 - INFO - ---------------------------------------------
2024-10-12 21:31 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:31 - INFO - 	 Train Loss: 0.062
2024-10-12 21:31 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:31 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:31 - INFO - 	 PR-AUC: 0.881
2024-10-12 21:31 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:31 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:31 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:31 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 21:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:31 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:31 - INFO - ---------------------------------------------
2024-10-12 21:32 - INFO - ---------------------------------------------
2024-10-12 21:32 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98756
2024-10-12 21:32 - INFO - 	 Train Loss: 0.061
2024-10-12 21:32 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:32 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:32 - INFO - 	 PR-AUC: 0.893
2024-10-12 21:32 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:32 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:32 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:32 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.876
2024-10-12 21:32 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:32 - INFO - ---------------------------------------------
2024-10-12 21:32 - INFO - ---------------------------------------------
2024-10-12 21:32 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98805
2024-10-12 21:32 - INFO - 	 Train Loss: 0.058
2024-10-12 21:32 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:32 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:32 - INFO - 	 PR-AUC: 0.900
2024-10-12 21:32 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:32 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:32 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:32 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 21:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 21:32 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:32 - INFO - ---------------------------------------------
2024-10-12 21:33 - INFO - ---------------------------------------------
2024-10-12 21:33 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98813
2024-10-12 21:33 - INFO - 	 Train Loss: 0.057
2024-10-12 21:33 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:33 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:33 - INFO - 	 PR-AUC: 0.897
2024-10-12 21:33 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:33 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:33 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:33 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 21:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 21:33 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:33 - INFO - ---------------------------------------------
2024-10-12 21:33 - INFO - ---------------------------------------------
2024-10-12 21:33 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:33 - INFO - 	 Train Loss: 0.055
2024-10-12 21:33 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:33 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:33 - INFO - 	 PR-AUC: 0.895
2024-10-12 21:33 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:33 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:33 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:33 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 21:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 21:33 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:33 - INFO - ---------------------------------------------
2024-10-12 21:35 - INFO - Fit the preprocessing pipeline
2024-10-12 21:35 - INFO - Training using device: cuda
2024-10-12 21:35 - INFO - Creating generators
2024-10-12 21:35 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:35 - INFO - * Model:
2024-10-12 21:35 - INFO - * -----------
2024-10-12 21:35 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:35 - INFO - * -----------
2024-10-12 21:35 - INFO - Evaluating model based on: rocauc
2024-10-12 21:35 - INFO - Training..

2024-10-12 21:35 - INFO - ---------------------------------------------
2024-10-12 21:35 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 21:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98121
2024-10-12 21:35 - INFO - 	 Train Loss: 0.154
2024-10-12 21:35 - INFO - 	 Val. Loss: 0.075
2024-10-12 21:35 - INFO - 	 ROC-AUC: 0.981
2024-10-12 21:35 - INFO - 	 PR-AUC: 0.837
2024-10-12 21:35 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 21:35 - INFO - 	 Best Val. Loss: 0.075
2024-10-12 21:35 - INFO - 	 Best ROC-AUC: 0.981
2024-10-12 21:35 - INFO - 	 Best PR-AUC: 0.837
2024-10-12 21:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 21:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.803
2024-10-12 21:35 - INFO - 	 Best Recall for 0.4 precision: 0.968
2024-10-12 21:35 - INFO - ---------------------------------------------
2024-10-12 21:36 - INFO - ---------------------------------------------
2024-10-12 21:36 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:36 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98522
2024-10-12 21:36 - INFO - 	 Train Loss: 0.082
2024-10-12 21:36 - INFO - 	 Val. Loss: 0.068
2024-10-12 21:36 - INFO - 	 ROC-AUC: 0.985
2024-10-12 21:36 - INFO - 	 PR-AUC: 0.865
2024-10-12 21:36 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:36 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 21:36 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:36 - INFO - 	 Best PR-AUC: 0.865
2024-10-12 21:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.833
2024-10-12 21:36 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 21:36 - INFO - ---------------------------------------------
2024-10-12 21:36 - INFO - ---------------------------------------------
2024-10-12 21:36 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:36 - INFO - 	 Train Loss: 0.072
2024-10-12 21:36 - INFO - 	 Val. Loss: 0.072
2024-10-12 21:36 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:36 - INFO - 	 PR-AUC: 0.860
2024-10-12 21:36 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 21:36 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 21:36 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 21:36 - INFO - 	 Best PR-AUC: 0.865
2024-10-12 21:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.833
2024-10-12 21:36 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 21:36 - INFO - ---------------------------------------------
2024-10-12 21:37 - INFO - ---------------------------------------------
2024-10-12 21:37 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 21:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9864
2024-10-12 21:37 - INFO - 	 Train Loss: 0.068
2024-10-12 21:37 - INFO - 	 Val. Loss: 0.065
2024-10-12 21:37 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:37 - INFO - 	 PR-AUC: 0.874
2024-10-12 21:37 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:37 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 21:37 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:37 - INFO - 	 Best PR-AUC: 0.874
2024-10-12 21:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 21:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 21:37 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:37 - INFO - ---------------------------------------------
2024-10-12 21:37 - INFO - ---------------------------------------------
2024-10-12 21:37 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 21:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98751
2024-10-12 21:37 - INFO - 	 Train Loss: 0.065
2024-10-12 21:37 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:37 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:37 - INFO - 	 PR-AUC: 0.885
2024-10-12 21:37 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:37 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:37 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:37 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 21:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.856
2024-10-12 21:37 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:37 - INFO - ---------------------------------------------
2024-10-12 21:38 - INFO - ---------------------------------------------
2024-10-12 21:38 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 21:38 - INFO - 	 Train Loss: 0.061
2024-10-12 21:38 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:38 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:38 - INFO - 	 PR-AUC: 0.886
2024-10-12 21:38 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:38 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:38 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:38 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 21:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.872
2024-10-12 21:38 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:38 - INFO - ---------------------------------------------
2024-10-12 21:38 - INFO - ---------------------------------------------
2024-10-12 21:38 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98815
2024-10-12 21:38 - INFO - 	 Train Loss: 0.059
2024-10-12 21:38 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:38 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:38 - INFO - 	 PR-AUC: 0.895
2024-10-12 21:38 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:38 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 21:38 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:38 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 21:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 21:38 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:38 - INFO - ---------------------------------------------
2024-10-12 21:39 - INFO - ---------------------------------------------
2024-10-12 21:39 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:39 - INFO - 	 Train Loss: 0.058
2024-10-12 21:39 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:39 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:39 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:39 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:39 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 21:39 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:39 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 21:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 21:39 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:39 - INFO - ---------------------------------------------
2024-10-12 21:40 - INFO - ---------------------------------------------
2024-10-12 21:40 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 21:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98865
2024-10-12 21:40 - INFO - 	 Train Loss: 0.055
2024-10-12 21:40 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:40 - INFO - 	 ROC-AUC: 0.989
2024-10-12 21:40 - INFO - 	 PR-AUC: 0.899
2024-10-12 21:40 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:40 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:40 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:40 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 21:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 21:40 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:40 - INFO - ---------------------------------------------
2024-10-12 21:40 - INFO - ---------------------------------------------
2024-10-12 21:40 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:40 - INFO - 	 Train Loss: 0.054
2024-10-12 21:40 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:40 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:40 - INFO - 	 PR-AUC: 0.892
2024-10-12 21:40 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 21:40 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:40 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:40 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 21:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 21:40 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 21:40 - INFO - ---------------------------------------------
2024-10-12 21:42 - INFO - Fit the preprocessing pipeline
2024-10-12 21:42 - INFO - Training using device: cuda
2024-10-12 21:42 - INFO - Creating generators
2024-10-12 21:42 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:42 - INFO - * Model:
2024-10-12 21:42 - INFO - * -----------
2024-10-12 21:42 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:42 - INFO - * -----------
2024-10-12 21:42 - INFO - Evaluating model based on: rocauc
2024-10-12 21:42 - INFO - Training..

2024-10-12 21:42 - INFO - ---------------------------------------------
2024-10-12 21:42 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 21:42 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97588
2024-10-12 21:42 - INFO - 	 Train Loss: 0.156
2024-10-12 21:42 - INFO - 	 Val. Loss: 0.089
2024-10-12 21:42 - INFO - 	 ROC-AUC: 0.976
2024-10-12 21:42 - INFO - 	 PR-AUC: 0.790
2024-10-12 21:42 - INFO - 	 Recall for 0.4 precision: 0.961
2024-10-12 21:42 - INFO - 	 Best Val. Loss: 0.089
2024-10-12 21:42 - INFO - 	 Best ROC-AUC: 0.976
2024-10-12 21:42 - INFO - 	 Best PR-AUC: 0.790
2024-10-12 21:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.973
2024-10-12 21:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.761
2024-10-12 21:42 - INFO - 	 Best Recall for 0.4 precision: 0.961
2024-10-12 21:42 - INFO - ---------------------------------------------
2024-10-12 21:43 - INFO - ---------------------------------------------
2024-10-12 21:43 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 21:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98354
2024-10-12 21:43 - INFO - 	 Train Loss: 0.084
2024-10-12 21:43 - INFO - 	 Val. Loss: 0.074
2024-10-12 21:43 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:43 - INFO - 	 PR-AUC: 0.848
2024-10-12 21:43 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:43 - INFO - 	 Best Val. Loss: 0.074
2024-10-12 21:43 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 21:43 - INFO - 	 Best PR-AUC: 0.848
2024-10-12 21:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.829
2024-10-12 21:43 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 21:43 - INFO - ---------------------------------------------
2024-10-12 21:43 - INFO - ---------------------------------------------
2024-10-12 21:43 - INFO - Epoch: 03 | Time: 0m 32s
2024-10-12 21:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98709
2024-10-12 21:43 - INFO - 	 Train Loss: 0.073
2024-10-12 21:43 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:43 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:43 - INFO - 	 PR-AUC: 0.877
2024-10-12 21:43 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:43 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:43 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:43 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 21:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.839
2024-10-12 21:43 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:43 - INFO - ---------------------------------------------
2024-10-12 21:44 - INFO - ---------------------------------------------
2024-10-12 21:44 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 21:44 - INFO - 	 Train Loss: 0.068
2024-10-12 21:44 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:44 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:44 - INFO - 	 PR-AUC: 0.869
2024-10-12 21:44 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 21:44 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:44 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:44 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 21:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.839
2024-10-12 21:44 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:44 - INFO - ---------------------------------------------
2024-10-12 21:44 - INFO - ---------------------------------------------
2024-10-12 21:44 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 21:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98733
2024-10-12 21:44 - INFO - 	 Train Loss: 0.064
2024-10-12 21:44 - INFO - 	 Val. Loss: 0.063
2024-10-12 21:44 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:44 - INFO - 	 PR-AUC: 0.879
2024-10-12 21:44 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 21:44 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 21:44 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:44 - INFO - 	 Best PR-AUC: 0.879
2024-10-12 21:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.852
2024-10-12 21:44 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:44 - INFO - ---------------------------------------------
2024-10-12 21:45 - INFO - ---------------------------------------------
2024-10-12 21:45 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9874
2024-10-12 21:45 - INFO - 	 Train Loss: 0.063
2024-10-12 21:45 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:45 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:45 - INFO - 	 PR-AUC: 0.883
2024-10-12 21:45 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:45 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:45 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:45 - INFO - 	 Best PR-AUC: 0.883
2024-10-12 21:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.870
2024-10-12 21:45 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:45 - INFO - ---------------------------------------------
2024-10-12 21:45 - INFO - ---------------------------------------------
2024-10-12 21:45 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98765
2024-10-12 21:45 - INFO - 	 Train Loss: 0.059
2024-10-12 21:45 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:45 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:45 - INFO - 	 PR-AUC: 0.890
2024-10-12 21:45 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:45 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:45 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:45 - INFO - 	 Best PR-AUC: 0.890
2024-10-12 21:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 21:45 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:45 - INFO - ---------------------------------------------
2024-10-12 21:46 - INFO - ---------------------------------------------
2024-10-12 21:46 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98832
2024-10-12 21:46 - INFO - 	 Train Loss: 0.057
2024-10-12 21:46 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:46 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:46 - INFO - 	 PR-AUC: 0.891
2024-10-12 21:46 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:46 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:46 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:46 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 21:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.882
2024-10-12 21:46 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:46 - INFO - ---------------------------------------------
2024-10-12 21:46 - INFO - ---------------------------------------------
2024-10-12 21:46 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 21:46 - INFO - 	 Train Loss: 0.055
2024-10-12 21:46 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:46 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:46 - INFO - 	 PR-AUC: 0.885
2024-10-12 21:46 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:46 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:46 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:46 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 21:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.882
2024-10-12 21:46 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:46 - INFO - ---------------------------------------------
2024-10-12 21:47 - INFO - ---------------------------------------------
2024-10-12 21:47 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 21:47 - INFO - 	 Train Loss: 0.055
2024-10-12 21:47 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:47 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:47 - INFO - 	 PR-AUC: 0.894
2024-10-12 21:47 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:47 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:47 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:47 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.879
2024-10-12 21:47 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 21:47 - INFO - ---------------------------------------------
2024-10-12 21:49 - INFO - Fit the preprocessing pipeline
2024-10-12 21:49 - INFO - Training using device: cuda
2024-10-12 21:49 - INFO - Creating generators
2024-10-12 21:49 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:49 - INFO - * Model:
2024-10-12 21:49 - INFO - * -----------
2024-10-12 21:49 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:49 - INFO - * -----------
2024-10-12 21:49 - INFO - Evaluating model based on: rocauc
2024-10-12 21:49 - INFO - Training..

2024-10-12 21:49 - INFO - ---------------------------------------------
2024-10-12 21:49 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97742
2024-10-12 21:49 - INFO - 	 Train Loss: 0.153
2024-10-12 21:49 - INFO - 	 Val. Loss: 0.085
2024-10-12 21:49 - INFO - 	 ROC-AUC: 0.977
2024-10-12 21:49 - INFO - 	 PR-AUC: 0.805
2024-10-12 21:49 - INFO - 	 Recall for 0.4 precision: 0.963
2024-10-12 21:49 - INFO - 	 Best Val. Loss: 0.085
2024-10-12 21:49 - INFO - 	 Best ROC-AUC: 0.977
2024-10-12 21:49 - INFO - 	 Best PR-AUC: 0.805
2024-10-12 21:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.975
2024-10-12 21:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.763
2024-10-12 21:49 - INFO - 	 Best Recall for 0.4 precision: 0.963
2024-10-12 21:49 - INFO - ---------------------------------------------
2024-10-12 21:50 - INFO - ---------------------------------------------
2024-10-12 21:50 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98363
2024-10-12 21:50 - INFO - 	 Train Loss: 0.083
2024-10-12 21:50 - INFO - 	 Val. Loss: 0.072
2024-10-12 21:50 - INFO - 	 ROC-AUC: 0.984
2024-10-12 21:50 - INFO - 	 PR-AUC: 0.866
2024-10-12 21:50 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:50 - INFO - 	 Best Val. Loss: 0.072
2024-10-12 21:50 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 21:50 - INFO - 	 Best PR-AUC: 0.866
2024-10-12 21:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 21:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.834
2024-10-12 21:50 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:50 - INFO - ---------------------------------------------
2024-10-12 21:50 - INFO - ---------------------------------------------
2024-10-12 21:50 - INFO - Epoch: 03 | Time: 0m 32s
2024-10-12 21:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98654
2024-10-12 21:50 - INFO - 	 Train Loss: 0.074
2024-10-12 21:50 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:50 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:50 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:50 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 21:50 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:50 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:50 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 21:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 21:50 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 21:50 - INFO - ---------------------------------------------
2024-10-12 21:51 - INFO - ---------------------------------------------
2024-10-12 21:51 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 21:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98796
2024-10-12 21:51 - INFO - 	 Train Loss: 0.068
2024-10-12 21:51 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:51 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:51 - INFO - 	 PR-AUC: 0.893
2024-10-12 21:51 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:51 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:51 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:51 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 21:51 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:51 - INFO - ---------------------------------------------
2024-10-12 21:51 - INFO - ---------------------------------------------
2024-10-12 21:51 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 21:51 - INFO - 	 Train Loss: 0.063
2024-10-12 21:51 - INFO - 	 Val. Loss: 0.061
2024-10-12 21:51 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:51 - INFO - 	 PR-AUC: 0.890
2024-10-12 21:51 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:51 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 21:51 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:51 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 21:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 21:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 21:51 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:51 - INFO - ---------------------------------------------
2024-10-12 21:52 - INFO - ---------------------------------------------
2024-10-12 21:52 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98823
2024-10-12 21:52 - INFO - 	 Train Loss: 0.061
2024-10-12 21:52 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:52 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:52 - INFO - 	 PR-AUC: 0.894
2024-10-12 21:52 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:52 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:52 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:52 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 21:52 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:52 - INFO - ---------------------------------------------
2024-10-12 21:52 - INFO - ---------------------------------------------
2024-10-12 21:52 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:52 - INFO - 	 Train Loss: 0.059
2024-10-12 21:52 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:52 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:52 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:52 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:52 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:52 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:52 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 21:52 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:52 - INFO - ---------------------------------------------
2024-10-12 21:53 - INFO - ---------------------------------------------
2024-10-12 21:53 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 21:53 - INFO - 	 Train Loss: 0.057
2024-10-12 21:53 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:53 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:53 - INFO - 	 PR-AUC: 0.883
2024-10-12 21:53 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:53 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:53 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:53 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 21:53 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:53 - INFO - ---------------------------------------------
2024-10-12 21:53 - INFO - ---------------------------------------------
2024-10-12 21:53 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 21:53 - INFO - 	 Train Loss: 0.057
2024-10-12 21:53 - INFO - 	 Val. Loss: 0.058
2024-10-12 21:53 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:53 - INFO - 	 PR-AUC: 0.893
2024-10-12 21:53 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 21:53 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 21:53 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:53 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 21:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 21:53 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:53 - INFO - ---------------------------------------------
2024-10-12 21:54 - INFO - ---------------------------------------------
2024-10-12 21:54 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 21:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98932
2024-10-12 21:54 - INFO - 	 Train Loss: 0.055
2024-10-12 21:54 - INFO - 	 Val. Loss: 0.056
2024-10-12 21:54 - INFO - 	 ROC-AUC: 0.989
2024-10-12 21:54 - INFO - 	 PR-AUC: 0.903
2024-10-12 21:54 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 21:54 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 21:54 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:54 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 21:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.894
2024-10-12 21:54 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 21:54 - INFO - ---------------------------------------------
2024-10-12 21:55 - INFO - Fit the preprocessing pipeline
2024-10-12 21:55 - INFO - Training using device: cuda
2024-10-12 21:55 - INFO - Creating generators
2024-10-12 21:55 - INFO - The model has 651,257 trainable parameters
2024-10-12 21:55 - INFO - * Model:
2024-10-12 21:55 - INFO - * -----------
2024-10-12 21:55 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 21:55 - INFO - * -----------
2024-10-12 21:55 - INFO - Evaluating model based on: rocauc
2024-10-12 21:55 - INFO - Training..

2024-10-12 21:56 - INFO - ---------------------------------------------
2024-10-12 21:56 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 21:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97605
2024-10-12 21:56 - INFO - 	 Train Loss: 0.149
2024-10-12 21:56 - INFO - 	 Val. Loss: 0.093
2024-10-12 21:56 - INFO - 	 ROC-AUC: 0.976
2024-10-12 21:56 - INFO - 	 PR-AUC: 0.810
2024-10-12 21:56 - INFO - 	 Recall for 0.4 precision: 0.944
2024-10-12 21:56 - INFO - 	 Best Val. Loss: 0.093
2024-10-12 21:56 - INFO - 	 Best ROC-AUC: 0.976
2024-10-12 21:56 - INFO - 	 Best PR-AUC: 0.810
2024-10-12 21:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.974
2024-10-12 21:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.773
2024-10-12 21:56 - INFO - 	 Best Recall for 0.4 precision: 0.944
2024-10-12 21:56 - INFO - ---------------------------------------------
2024-10-12 21:56 - INFO - ---------------------------------------------
2024-10-12 21:56 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 21:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98571
2024-10-12 21:56 - INFO - 	 Train Loss: 0.082
2024-10-12 21:56 - INFO - 	 Val. Loss: 0.067
2024-10-12 21:56 - INFO - 	 ROC-AUC: 0.986
2024-10-12 21:56 - INFO - 	 PR-AUC: 0.873
2024-10-12 21:56 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 21:56 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 21:56 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 21:56 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 21:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 21:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.838
2024-10-12 21:56 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 21:56 - INFO - ---------------------------------------------
2024-10-12 21:57 - INFO - ---------------------------------------------
2024-10-12 21:57 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 21:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98656
2024-10-12 21:57 - INFO - 	 Train Loss: 0.074
2024-10-12 21:57 - INFO - 	 Val. Loss: 0.065
2024-10-12 21:57 - INFO - 	 ROC-AUC: 0.987
2024-10-12 21:57 - INFO - 	 PR-AUC: 0.871
2024-10-12 21:57 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:57 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 21:57 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 21:57 - INFO - 	 Best PR-AUC: 0.873
2024-10-12 21:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 21:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.838
2024-10-12 21:57 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:57 - INFO - ---------------------------------------------
2024-10-12 21:58 - INFO - ---------------------------------------------
2024-10-12 21:58 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 21:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98776
2024-10-12 21:58 - INFO - 	 Train Loss: 0.068
2024-10-12 21:58 - INFO - 	 Val. Loss: 0.064
2024-10-12 21:58 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:58 - INFO - 	 PR-AUC: 0.886
2024-10-12 21:58 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:58 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 21:58 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:58 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 21:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 21:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.864
2024-10-12 21:58 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 21:58 - INFO - ---------------------------------------------
2024-10-12 21:58 - INFO - ---------------------------------------------
2024-10-12 21:58 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 21:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98843
2024-10-12 21:58 - INFO - 	 Train Loss: 0.065
2024-10-12 21:58 - INFO - 	 Val. Loss: 0.060
2024-10-12 21:58 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:58 - INFO - 	 PR-AUC: 0.888
2024-10-12 21:58 - INFO - 	 Recall for 0.4 precision: 0.981
2024-10-12 21:58 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 21:58 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 21:58 - INFO - 	 Best PR-AUC: 0.888
2024-10-12 21:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 21:58 - INFO - 	 Best Recall for 0.4 precision: 0.981
2024-10-12 21:58 - INFO - ---------------------------------------------
2024-10-12 21:59 - INFO - ---------------------------------------------
2024-10-12 21:59 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 21:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98889
2024-10-12 21:59 - INFO - 	 Train Loss: 0.062
2024-10-12 21:59 - INFO - 	 Val. Loss: 0.059
2024-10-12 21:59 - INFO - 	 ROC-AUC: 0.989
2024-10-12 21:59 - INFO - 	 PR-AUC: 0.899
2024-10-12 21:59 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 21:59 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:59 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:59 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 21:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.883
2024-10-12 21:59 - INFO - 	 Best Recall for 0.4 precision: 0.981
2024-10-12 21:59 - INFO - ---------------------------------------------
2024-10-12 21:59 - INFO - ---------------------------------------------
2024-10-12 21:59 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 21:59 - INFO - 	 Train Loss: 0.060
2024-10-12 21:59 - INFO - 	 Val. Loss: 0.062
2024-10-12 21:59 - INFO - 	 ROC-AUC: 0.988
2024-10-12 21:59 - INFO - 	 PR-AUC: 0.889
2024-10-12 21:59 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 21:59 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 21:59 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 21:59 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 21:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 21:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.883
2024-10-12 21:59 - INFO - 	 Best Recall for 0.4 precision: 0.981
2024-10-12 21:59 - INFO - ---------------------------------------------
2024-10-12 22:00 - INFO - ---------------------------------------------
2024-10-12 22:00 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98901
2024-10-12 22:00 - INFO - 	 Train Loss: 0.058
2024-10-12 22:00 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:00 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:00 - INFO - 	 PR-AUC: 0.896
2024-10-12 22:00 - INFO - 	 Recall for 0.4 precision: 0.982
2024-10-12 22:00 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:00 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:00 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 22:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.883
2024-10-12 22:00 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 22:00 - INFO - ---------------------------------------------
2024-10-12 22:00 - INFO - ---------------------------------------------
2024-10-12 22:00 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:00 - INFO - 	 Train Loss: 0.057
2024-10-12 22:00 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:00 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:00 - INFO - 	 PR-AUC: 0.900
2024-10-12 22:00 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:00 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:00 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:00 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 22:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 22:00 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 22:00 - INFO - ---------------------------------------------
2024-10-12 22:01 - INFO - ---------------------------------------------
2024-10-12 22:01 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 22:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.99006
2024-10-12 22:01 - INFO - 	 Train Loss: 0.056
2024-10-12 22:01 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:01 - INFO - 	 ROC-AUC: 0.990
2024-10-12 22:01 - INFO - 	 PR-AUC: 0.898
2024-10-12 22:01 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:01 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:01 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 22:01 - INFO - 	 Best PR-AUC: 0.900
2024-10-12 22:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.889
2024-10-12 22:01 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 22:01 - INFO - ---------------------------------------------
2024-10-12 22:02 - INFO - Fit the preprocessing pipeline
2024-10-12 22:02 - INFO - Training using device: cuda
2024-10-12 22:02 - INFO - Creating generators
2024-10-12 22:02 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:02 - INFO - * Model:
2024-10-12 22:02 - INFO - * -----------
2024-10-12 22:02 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:02 - INFO - * -----------
2024-10-12 22:02 - INFO - Evaluating model based on: rocauc
2024-10-12 22:02 - INFO - Training..

2024-10-12 22:03 - INFO - ---------------------------------------------
2024-10-12 22:03 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 22:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97833
2024-10-12 22:03 - INFO - 	 Train Loss: 0.154
2024-10-12 22:03 - INFO - 	 Val. Loss: 0.082
2024-10-12 22:03 - INFO - 	 ROC-AUC: 0.978
2024-10-12 22:03 - INFO - 	 PR-AUC: 0.810
2024-10-12 22:03 - INFO - 	 Recall for 0.4 precision: 0.960
2024-10-12 22:03 - INFO - 	 Best Val. Loss: 0.082
2024-10-12 22:03 - INFO - 	 Best ROC-AUC: 0.978
2024-10-12 22:03 - INFO - 	 Best PR-AUC: 0.810
2024-10-12 22:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.976
2024-10-12 22:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.793
2024-10-12 22:03 - INFO - 	 Best Recall for 0.4 precision: 0.960
2024-10-12 22:03 - INFO - ---------------------------------------------
2024-10-12 22:03 - INFO - ---------------------------------------------
2024-10-12 22:03 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 22:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98359
2024-10-12 22:03 - INFO - 	 Train Loss: 0.083
2024-10-12 22:03 - INFO - 	 Val. Loss: 0.075
2024-10-12 22:03 - INFO - 	 ROC-AUC: 0.984
2024-10-12 22:03 - INFO - 	 PR-AUC: 0.852
2024-10-12 22:03 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:03 - INFO - 	 Best Val. Loss: 0.075
2024-10-12 22:03 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 22:03 - INFO - 	 Best PR-AUC: 0.852
2024-10-12 22:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.821
2024-10-12 22:03 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 22:03 - INFO - ---------------------------------------------
2024-10-12 22:04 - INFO - ---------------------------------------------
2024-10-12 22:04 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98569
2024-10-12 22:04 - INFO - 	 Train Loss: 0.072
2024-10-12 22:04 - INFO - 	 Val. Loss: 0.068
2024-10-12 22:04 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:04 - INFO - 	 PR-AUC: 0.870
2024-10-12 22:04 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:04 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 22:04 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:04 - INFO - 	 Best PR-AUC: 0.870
2024-10-12 22:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.829
2024-10-12 22:04 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:04 - INFO - ---------------------------------------------
2024-10-12 22:04 - INFO - ---------------------------------------------
2024-10-12 22:04 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:04 - INFO - 	 Train Loss: 0.067
2024-10-12 22:04 - INFO - 	 Val. Loss: 0.069
2024-10-12 22:04 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:04 - INFO - 	 PR-AUC: 0.872
2024-10-12 22:04 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:04 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 22:04 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:04 - INFO - 	 Best PR-AUC: 0.872
2024-10-12 22:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.836
2024-10-12 22:04 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:04 - INFO - ---------------------------------------------
2024-10-12 22:05 - INFO - ---------------------------------------------
2024-10-12 22:05 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98584
2024-10-12 22:05 - INFO - 	 Train Loss: 0.064
2024-10-12 22:05 - INFO - 	 Val. Loss: 0.066
2024-10-12 22:05 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:05 - INFO - 	 PR-AUC: 0.868
2024-10-12 22:05 - INFO - 	 Recall for 0.4 precision: 0.971
2024-10-12 22:05 - INFO - 	 Best Val. Loss: 0.066
2024-10-12 22:05 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:05 - INFO - 	 Best PR-AUC: 0.872
2024-10-12 22:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.836
2024-10-12 22:05 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:05 - INFO - ---------------------------------------------
2024-10-12 22:05 - INFO - ---------------------------------------------
2024-10-12 22:05 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98621
2024-10-12 22:05 - INFO - 	 Train Loss: 0.062
2024-10-12 22:05 - INFO - 	 Val. Loss: 0.068
2024-10-12 22:05 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:05 - INFO - 	 PR-AUC: 0.877
2024-10-12 22:05 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:05 - INFO - 	 Best Val. Loss: 0.066
2024-10-12 22:05 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:05 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 22:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 22:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.862
2024-10-12 22:05 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:05 - INFO - ---------------------------------------------
2024-10-12 22:06 - INFO - ---------------------------------------------
2024-10-12 22:06 - INFO - Epoch: 07 | Time: 0m 32s
2024-10-12 22:06 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98732
2024-10-12 22:06 - INFO - 	 Train Loss: 0.060
2024-10-12 22:06 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:06 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:06 - INFO - 	 PR-AUC: 0.885
2024-10-12 22:06 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:06 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:06 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:06 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 22:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.868
2024-10-12 22:06 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:06 - INFO - ---------------------------------------------
2024-10-12 22:07 - INFO - ---------------------------------------------
2024-10-12 22:07 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:07 - INFO - 	 Train Loss: 0.058
2024-10-12 22:07 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:07 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:07 - INFO - 	 PR-AUC: 0.883
2024-10-12 22:07 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:07 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:07 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:07 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 22:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.868
2024-10-12 22:07 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:07 - INFO - ---------------------------------------------
2024-10-12 22:07 - INFO - ---------------------------------------------
2024-10-12 22:07 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:07 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98798
2024-10-12 22:07 - INFO - 	 Train Loss: 0.057
2024-10-12 22:07 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:07 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:07 - INFO - 	 PR-AUC: 0.892
2024-10-12 22:07 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:07 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:07 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:07 - INFO - 	 Best PR-AUC: 0.892
2024-10-12 22:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.899
2024-10-12 22:07 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:07 - INFO - ---------------------------------------------
2024-10-12 22:08 - INFO - ---------------------------------------------
2024-10-12 22:08 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98819
2024-10-12 22:08 - INFO - 	 Train Loss: 0.055
2024-10-12 22:08 - INFO - 	 Val. Loss: 0.058
2024-10-12 22:08 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:08 - INFO - 	 PR-AUC: 0.894
2024-10-12 22:08 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:08 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 22:08 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:08 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 22:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.899
2024-10-12 22:08 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:08 - INFO - ---------------------------------------------
2024-10-12 22:09 - INFO - Fit the preprocessing pipeline
2024-10-12 22:09 - INFO - Training using device: cuda
2024-10-12 22:09 - INFO - Creating generators
2024-10-12 22:09 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:09 - INFO - * Model:
2024-10-12 22:09 - INFO - * -----------
2024-10-12 22:09 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:09 - INFO - * -----------
2024-10-12 22:09 - INFO - Evaluating model based on: rocauc
2024-10-12 22:09 - INFO - Training..

2024-10-12 22:10 - INFO - ---------------------------------------------
2024-10-12 22:10 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 22:10 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98021
2024-10-12 22:10 - INFO - 	 Train Loss: 0.155
2024-10-12 22:10 - INFO - 	 Val. Loss: 0.079
2024-10-12 22:10 - INFO - 	 ROC-AUC: 0.980
2024-10-12 22:10 - INFO - 	 PR-AUC: 0.812
2024-10-12 22:10 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 22:10 - INFO - 	 Best Val. Loss: 0.079
2024-10-12 22:10 - INFO - 	 Best ROC-AUC: 0.980
2024-10-12 22:10 - INFO - 	 Best PR-AUC: 0.812
2024-10-12 22:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.978
2024-10-12 22:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.794
2024-10-12 22:10 - INFO - 	 Best Recall for 0.4 precision: 0.968
2024-10-12 22:10 - INFO - ---------------------------------------------
2024-10-12 22:10 - INFO - ---------------------------------------------
2024-10-12 22:10 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 22:10 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98601
2024-10-12 22:10 - INFO - 	 Train Loss: 0.084
2024-10-12 22:10 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:10 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:10 - INFO - 	 PR-AUC: 0.876
2024-10-12 22:10 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:10 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:10 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:10 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 22:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.842
2024-10-12 22:10 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:10 - INFO - ---------------------------------------------
2024-10-12 22:11 - INFO - ---------------------------------------------
2024-10-12 22:11 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:11 - INFO - 	 Train Loss: 0.074
2024-10-12 22:11 - INFO - 	 Val. Loss: 0.067
2024-10-12 22:11 - INFO - 	 ROC-AUC: 0.985
2024-10-12 22:11 - INFO - 	 PR-AUC: 0.869
2024-10-12 22:11 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:11 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:11 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:11 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 22:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.842
2024-10-12 22:11 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:11 - INFO - ---------------------------------------------
2024-10-12 22:11 - INFO - ---------------------------------------------
2024-10-12 22:11 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98615
2024-10-12 22:11 - INFO - 	 Train Loss: 0.068
2024-10-12 22:11 - INFO - 	 Val. Loss: 0.065
2024-10-12 22:11 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:11 - INFO - 	 PR-AUC: 0.878
2024-10-12 22:11 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:11 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:11 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:11 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 22:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.844
2024-10-12 22:11 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:11 - INFO - ---------------------------------------------
2024-10-12 22:12 - INFO - ---------------------------------------------
2024-10-12 22:12 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98618
2024-10-12 22:12 - INFO - 	 Train Loss: 0.065
2024-10-12 22:12 - INFO - 	 Val. Loss: 0.065
2024-10-12 22:12 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:12 - INFO - 	 PR-AUC: 0.877
2024-10-12 22:12 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:12 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:12 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:12 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 22:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.844
2024-10-12 22:12 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 22:12 - INFO - ---------------------------------------------
2024-10-12 22:12 - INFO - ---------------------------------------------
2024-10-12 22:12 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98699
2024-10-12 22:12 - INFO - 	 Train Loss: 0.062
2024-10-12 22:12 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:12 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:12 - INFO - 	 PR-AUC: 0.881
2024-10-12 22:12 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:12 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:12 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:12 - INFO - 	 Best PR-AUC: 0.881
2024-10-12 22:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.872
2024-10-12 22:12 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 22:12 - INFO - ---------------------------------------------
2024-10-12 22:13 - INFO - ---------------------------------------------
2024-10-12 22:13 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:13 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98823
2024-10-12 22:13 - INFO - 	 Train Loss: 0.060
2024-10-12 22:13 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:13 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:13 - INFO - 	 PR-AUC: 0.895
2024-10-12 22:13 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:13 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:13 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:13 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 22:13 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:13 - INFO - ---------------------------------------------
2024-10-12 22:13 - INFO - ---------------------------------------------
2024-10-12 22:13 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:13 - INFO - 	 Train Loss: 0.058
2024-10-12 22:13 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:13 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:13 - INFO - 	 PR-AUC: 0.886
2024-10-12 22:13 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:13 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:13 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:13 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 22:13 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:13 - INFO - ---------------------------------------------
2024-10-12 22:14 - INFO - ---------------------------------------------
2024-10-12 22:14 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:14 - INFO - 	 Train Loss: 0.057
2024-10-12 22:14 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:14 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:14 - INFO - 	 PR-AUC: 0.888
2024-10-12 22:14 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:14 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:14 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:14 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 22:14 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:14 - INFO - ---------------------------------------------
2024-10-12 22:14 - INFO - ---------------------------------------------
2024-10-12 22:14 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:14 - INFO - 	 Train Loss: 0.055
2024-10-12 22:14 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:14 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:14 - INFO - 	 PR-AUC: 0.888
2024-10-12 22:14 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:14 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:14 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:14 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.887
2024-10-12 22:14 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:14 - INFO - ---------------------------------------------
2024-10-12 22:16 - INFO - Fit the preprocessing pipeline
2024-10-12 22:16 - INFO - Training using device: cuda
2024-10-12 22:16 - INFO - Creating generators
2024-10-12 22:16 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:16 - INFO - * Model:
2024-10-12 22:16 - INFO - * -----------
2024-10-12 22:16 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:16 - INFO - * -----------
2024-10-12 22:16 - INFO - Evaluating model based on: rocauc
2024-10-12 22:16 - INFO - Training..

2024-10-12 22:16 - INFO - ---------------------------------------------
2024-10-12 22:16 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 22:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97965
2024-10-12 22:16 - INFO - 	 Train Loss: 0.161
2024-10-12 22:16 - INFO - 	 Val. Loss: 0.081
2024-10-12 22:16 - INFO - 	 ROC-AUC: 0.980
2024-10-12 22:16 - INFO - 	 PR-AUC: 0.792
2024-10-12 22:16 - INFO - 	 Recall for 0.4 precision: 0.962
2024-10-12 22:16 - INFO - 	 Best Val. Loss: 0.081
2024-10-12 22:16 - INFO - 	 Best ROC-AUC: 0.980
2024-10-12 22:16 - INFO - 	 Best PR-AUC: 0.792
2024-10-12 22:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.975
2024-10-12 22:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.779
2024-10-12 22:16 - INFO - 	 Best Recall for 0.4 precision: 0.962
2024-10-12 22:16 - INFO - ---------------------------------------------
2024-10-12 22:17 - INFO - ---------------------------------------------
2024-10-12 22:17 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 22:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98502
2024-10-12 22:17 - INFO - 	 Train Loss: 0.082
2024-10-12 22:17 - INFO - 	 Val. Loss: 0.067
2024-10-12 22:17 - INFO - 	 ROC-AUC: 0.985
2024-10-12 22:17 - INFO - 	 PR-AUC: 0.866
2024-10-12 22:17 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:17 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 22:17 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 22:17 - INFO - 	 Best PR-AUC: 0.866
2024-10-12 22:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.839
2024-10-12 22:17 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:17 - INFO - ---------------------------------------------
2024-10-12 22:18 - INFO - ---------------------------------------------
2024-10-12 22:18 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98684
2024-10-12 22:18 - INFO - 	 Train Loss: 0.072
2024-10-12 22:18 - INFO - 	 Val. Loss: 0.064
2024-10-12 22:18 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:18 - INFO - 	 PR-AUC: 0.877
2024-10-12 22:18 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:18 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 22:18 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:18 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 22:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.854
2024-10-12 22:18 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:18 - INFO - ---------------------------------------------
2024-10-12 22:18 - INFO - ---------------------------------------------
2024-10-12 22:18 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:18 - INFO - 	 Train Loss: 0.068
2024-10-12 22:18 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:18 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:18 - INFO - 	 PR-AUC: 0.874
2024-10-12 22:18 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 22:18 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:18 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:18 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 22:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.854
2024-10-12 22:18 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:18 - INFO - ---------------------------------------------
2024-10-12 22:19 - INFO - ---------------------------------------------
2024-10-12 22:19 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9871
2024-10-12 22:19 - INFO - 	 Train Loss: 0.063
2024-10-12 22:19 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:19 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:19 - INFO - 	 PR-AUC: 0.885
2024-10-12 22:19 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:19 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:19 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:19 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 22:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:19 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:19 - INFO - ---------------------------------------------
2024-10-12 22:19 - INFO - ---------------------------------------------
2024-10-12 22:19 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:19 - INFO - 	 Train Loss: 0.060
2024-10-12 22:19 - INFO - 	 Val. Loss: 0.062
2024-10-12 22:19 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:19 - INFO - 	 PR-AUC: 0.887
2024-10-12 22:19 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:19 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 22:19 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:19 - INFO - 	 Best PR-AUC: 0.887
2024-10-12 22:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 22:19 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:19 - INFO - ---------------------------------------------
2024-10-12 22:20 - INFO - ---------------------------------------------
2024-10-12 22:20 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:20 - INFO - 	 Train Loss: 0.060
2024-10-12 22:20 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:20 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:20 - INFO - 	 PR-AUC: 0.891
2024-10-12 22:20 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:20 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:20 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:20 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 22:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:20 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:20 - INFO - ---------------------------------------------
2024-10-12 22:20 - INFO - ---------------------------------------------
2024-10-12 22:20 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98743
2024-10-12 22:20 - INFO - 	 Train Loss: 0.057
2024-10-12 22:20 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:20 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:20 - INFO - 	 PR-AUC: 0.886
2024-10-12 22:20 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:20 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:20 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:20 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 22:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:20 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:20 - INFO - ---------------------------------------------
2024-10-12 22:21 - INFO - ---------------------------------------------
2024-10-12 22:21 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:21 - INFO - 	 Train Loss: 0.055
2024-10-12 22:21 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:21 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:21 - INFO - 	 PR-AUC: 0.888
2024-10-12 22:21 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:21 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:21 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:21 - INFO - 	 Best PR-AUC: 0.891
2024-10-12 22:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:21 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:21 - INFO - ---------------------------------------------
2024-10-12 22:21 - INFO - ---------------------------------------------
2024-10-12 22:21 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98805
2024-10-12 22:21 - INFO - 	 Train Loss: 0.055
2024-10-12 22:21 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:21 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:21 - INFO - 	 PR-AUC: 0.896
2024-10-12 22:21 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:21 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:21 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:21 - INFO - 	 Best PR-AUC: 0.896
2024-10-12 22:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.890
2024-10-12 22:21 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:21 - INFO - ---------------------------------------------
2024-10-12 22:23 - INFO - Fit the preprocessing pipeline
2024-10-12 22:23 - INFO - Training using device: cuda
2024-10-12 22:23 - INFO - Creating generators
2024-10-12 22:23 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:23 - INFO - * Model:
2024-10-12 22:23 - INFO - * -----------
2024-10-12 22:23 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:23 - INFO - * -----------
2024-10-12 22:23 - INFO - Evaluating model based on: rocauc
2024-10-12 22:23 - INFO - Training..

2024-10-12 22:23 - INFO - ---------------------------------------------
2024-10-12 22:23 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 22:23 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97086
2024-10-12 22:23 - INFO - 	 Train Loss: 0.164
2024-10-12 22:23 - INFO - 	 Val. Loss: 0.094
2024-10-12 22:23 - INFO - 	 ROC-AUC: 0.971
2024-10-12 22:23 - INFO - 	 PR-AUC: 0.773
2024-10-12 22:23 - INFO - 	 Recall for 0.4 precision: 0.942
2024-10-12 22:23 - INFO - 	 Best Val. Loss: 0.094
2024-10-12 22:23 - INFO - 	 Best ROC-AUC: 0.971
2024-10-12 22:23 - INFO - 	 Best PR-AUC: 0.773
2024-10-12 22:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.968
2024-10-12 22:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.763
2024-10-12 22:23 - INFO - 	 Best Recall for 0.4 precision: 0.942
2024-10-12 22:23 - INFO - ---------------------------------------------
2024-10-12 22:24 - INFO - ---------------------------------------------
2024-10-12 22:24 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 22:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98412
2024-10-12 22:24 - INFO - 	 Train Loss: 0.082
2024-10-12 22:24 - INFO - 	 Val. Loss: 0.072
2024-10-12 22:24 - INFO - 	 ROC-AUC: 0.984
2024-10-12 22:24 - INFO - 	 PR-AUC: 0.852
2024-10-12 22:24 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:24 - INFO - 	 Best Val. Loss: 0.072
2024-10-12 22:24 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 22:24 - INFO - 	 Best PR-AUC: 0.852
2024-10-12 22:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 22:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.834
2024-10-12 22:24 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 22:24 - INFO - ---------------------------------------------
2024-10-12 22:24 - INFO - ---------------------------------------------
2024-10-12 22:24 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98626
2024-10-12 22:24 - INFO - 	 Train Loss: 0.073
2024-10-12 22:24 - INFO - 	 Val. Loss: 0.064
2024-10-12 22:24 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:24 - INFO - 	 PR-AUC: 0.869
2024-10-12 22:24 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:24 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 22:24 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:24 - INFO - 	 Best PR-AUC: 0.869
2024-10-12 22:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.859
2024-10-12 22:24 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:24 - INFO - ---------------------------------------------
2024-10-12 22:25 - INFO - ---------------------------------------------
2024-10-12 22:25 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:25 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98833
2024-10-12 22:25 - INFO - 	 Train Loss: 0.068
2024-10-12 22:25 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:25 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:25 - INFO - 	 PR-AUC: 0.892
2024-10-12 22:25 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:25 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:25 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:25 - INFO - 	 Best PR-AUC: 0.892
2024-10-12 22:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.865
2024-10-12 22:25 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:25 - INFO - ---------------------------------------------
2024-10-12 22:25 - INFO - ---------------------------------------------
2024-10-12 22:25 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:25 - INFO - 	 Train Loss: 0.064
2024-10-12 22:25 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:25 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:25 - INFO - 	 PR-AUC: 0.885
2024-10-12 22:25 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:25 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:25 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:25 - INFO - 	 Best PR-AUC: 0.892
2024-10-12 22:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.865
2024-10-12 22:25 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:25 - INFO - ---------------------------------------------
2024-10-12 22:26 - INFO - ---------------------------------------------
2024-10-12 22:26 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:26 - INFO - 	 Train Loss: 0.063
2024-10-12 22:26 - INFO - 	 Val. Loss: 0.062
2024-10-12 22:26 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:26 - INFO - 	 PR-AUC: 0.888
2024-10-12 22:26 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:26 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:26 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:26 - INFO - 	 Best PR-AUC: 0.892
2024-10-12 22:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.865
2024-10-12 22:26 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:26 - INFO - ---------------------------------------------
2024-10-12 22:27 - INFO - ---------------------------------------------
2024-10-12 22:27 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98905
2024-10-12 22:27 - INFO - 	 Train Loss: 0.061
2024-10-12 22:27 - INFO - 	 Val. Loss: 0.056
2024-10-12 22:27 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:27 - INFO - 	 PR-AUC: 0.901
2024-10-12 22:27 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:27 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 22:27 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:27 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 22:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 22:27 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:27 - INFO - ---------------------------------------------
2024-10-12 22:27 - INFO - ---------------------------------------------
2024-10-12 22:27 - INFO - Epoch: 08 | Time: 0m 32s
2024-10-12 22:27 - INFO - 	 Train Loss: 0.059
2024-10-12 22:27 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:27 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:27 - INFO - 	 PR-AUC: 0.894
2024-10-12 22:27 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:27 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 22:27 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:27 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 22:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 22:27 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:27 - INFO - ---------------------------------------------
2024-10-12 22:28 - INFO - ---------------------------------------------
2024-10-12 22:28 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:28 - INFO - 	 Train Loss: 0.056
2024-10-12 22:28 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:28 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:28 - INFO - 	 PR-AUC: 0.896
2024-10-12 22:28 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:28 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 22:28 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:28 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 22:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 22:28 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:28 - INFO - ---------------------------------------------
2024-10-12 22:28 - INFO - ---------------------------------------------
2024-10-12 22:28 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:28 - INFO - 	 Train Loss: 0.055
2024-10-12 22:28 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:28 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:28 - INFO - 	 PR-AUC: 0.899
2024-10-12 22:28 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:28 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 22:28 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:28 - INFO - 	 Best PR-AUC: 0.901
2024-10-12 22:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.891
2024-10-12 22:28 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:28 - INFO - ---------------------------------------------
2024-10-12 22:30 - INFO - Fit the preprocessing pipeline
2024-10-12 22:30 - INFO - Training using device: cuda
2024-10-12 22:30 - INFO - Creating generators
2024-10-12 22:30 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:30 - INFO - * Model:
2024-10-12 22:30 - INFO - * -----------
2024-10-12 22:30 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:30 - INFO - * -----------
2024-10-12 22:30 - INFO - Evaluating model based on: rocauc
2024-10-12 22:30 - INFO - Training..

2024-10-12 22:30 - INFO - ---------------------------------------------
2024-10-12 22:30 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 22:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97536
2024-10-12 22:30 - INFO - 	 Train Loss: 0.162
2024-10-12 22:30 - INFO - 	 Val. Loss: 0.090
2024-10-12 22:30 - INFO - 	 ROC-AUC: 0.975
2024-10-12 22:30 - INFO - 	 PR-AUC: 0.768
2024-10-12 22:30 - INFO - 	 Recall for 0.4 precision: 0.957
2024-10-12 22:30 - INFO - 	 Best Val. Loss: 0.090
2024-10-12 22:30 - INFO - 	 Best ROC-AUC: 0.975
2024-10-12 22:30 - INFO - 	 Best PR-AUC: 0.768
2024-10-12 22:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.971
2024-10-12 22:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.751
2024-10-12 22:30 - INFO - 	 Best Recall for 0.4 precision: 0.957
2024-10-12 22:30 - INFO - ---------------------------------------------
2024-10-12 22:31 - INFO - ---------------------------------------------
2024-10-12 22:31 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 22:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98407
2024-10-12 22:31 - INFO - 	 Train Loss: 0.084
2024-10-12 22:31 - INFO - 	 Val. Loss: 0.068
2024-10-12 22:31 - INFO - 	 ROC-AUC: 0.984
2024-10-12 22:31 - INFO - 	 PR-AUC: 0.857
2024-10-12 22:31 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:31 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 22:31 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 22:31 - INFO - 	 Best PR-AUC: 0.857
2024-10-12 22:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.836
2024-10-12 22:31 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 22:31 - INFO - ---------------------------------------------
2024-10-12 22:31 - INFO - ---------------------------------------------
2024-10-12 22:31 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:31 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98641
2024-10-12 22:31 - INFO - 	 Train Loss: 0.074
2024-10-12 22:31 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:31 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:31 - INFO - 	 PR-AUC: 0.872
2024-10-12 22:31 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:31 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:31 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:31 - INFO - 	 Best PR-AUC: 0.872
2024-10-12 22:31 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:31 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.847
2024-10-12 22:31 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 22:31 - INFO - ---------------------------------------------
2024-10-12 22:32 - INFO - ---------------------------------------------
2024-10-12 22:32 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98743
2024-10-12 22:32 - INFO - 	 Train Loss: 0.069
2024-10-12 22:32 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:32 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:32 - INFO - 	 PR-AUC: 0.882
2024-10-12 22:32 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:32 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:32 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:32 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 22:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.860
2024-10-12 22:32 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:32 - INFO - ---------------------------------------------
2024-10-12 22:32 - INFO - ---------------------------------------------
2024-10-12 22:32 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:32 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98794
2024-10-12 22:32 - INFO - 	 Train Loss: 0.065
2024-10-12 22:32 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:32 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:32 - INFO - 	 PR-AUC: 0.878
2024-10-12 22:32 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:32 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:32 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:32 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 22:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.860
2024-10-12 22:32 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:32 - INFO - ---------------------------------------------
2024-10-12 22:33 - INFO - ---------------------------------------------
2024-10-12 22:33 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:33 - INFO - 	 Train Loss: 0.062
2024-10-12 22:33 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:33 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:33 - INFO - 	 PR-AUC: 0.883
2024-10-12 22:33 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:33 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:33 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:33 - INFO - 	 Best PR-AUC: 0.883
2024-10-12 22:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.874
2024-10-12 22:33 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:33 - INFO - ---------------------------------------------
2024-10-12 22:33 - INFO - ---------------------------------------------
2024-10-12 22:33 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98863
2024-10-12 22:33 - INFO - 	 Train Loss: 0.061
2024-10-12 22:33 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:33 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:33 - INFO - 	 PR-AUC: 0.895
2024-10-12 22:33 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:33 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:33 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:33 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.873
2024-10-12 22:33 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:33 - INFO - ---------------------------------------------
2024-10-12 22:34 - INFO - ---------------------------------------------
2024-10-12 22:34 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:34 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98982
2024-10-12 22:34 - INFO - 	 Train Loss: 0.059
2024-10-12 22:34 - INFO - 	 Val. Loss: 0.055
2024-10-12 22:34 - INFO - 	 ROC-AUC: 0.990
2024-10-12 22:34 - INFO - 	 PR-AUC: 0.898
2024-10-12 22:34 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:34 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:34 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 22:34 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 22:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:34 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:34 - INFO - ---------------------------------------------
2024-10-12 22:34 - INFO - ---------------------------------------------
2024-10-12 22:34 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:34 - INFO - 	 Train Loss: 0.056
2024-10-12 22:34 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:34 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:34 - INFO - 	 PR-AUC: 0.897
2024-10-12 22:34 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:34 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:34 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 22:34 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 22:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:34 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:34 - INFO - ---------------------------------------------
2024-10-12 22:35 - INFO - ---------------------------------------------
2024-10-12 22:35 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:35 - INFO - 	 Train Loss: 0.055
2024-10-12 22:35 - INFO - 	 Val. Loss: 0.058
2024-10-12 22:35 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:35 - INFO - 	 PR-AUC: 0.895
2024-10-12 22:35 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:35 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:35 - INFO - 	 Best ROC-AUC: 0.990
2024-10-12 22:35 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 22:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 22:35 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:35 - INFO - ---------------------------------------------
2024-10-12 22:36 - INFO - Fit the preprocessing pipeline
2024-10-12 22:36 - INFO - Training using device: cuda
2024-10-12 22:36 - INFO - Creating generators
2024-10-12 22:36 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:36 - INFO - * Model:
2024-10-12 22:36 - INFO - * -----------
2024-10-12 22:36 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:36 - INFO - * -----------
2024-10-12 22:36 - INFO - Evaluating model based on: rocauc
2024-10-12 22:36 - INFO - Training..

2024-10-12 22:37 - INFO - ---------------------------------------------
2024-10-12 22:37 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 22:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97664
2024-10-12 22:37 - INFO - 	 Train Loss: 0.164
2024-10-12 22:37 - INFO - 	 Val. Loss: 0.088
2024-10-12 22:37 - INFO - 	 ROC-AUC: 0.977
2024-10-12 22:37 - INFO - 	 PR-AUC: 0.794
2024-10-12 22:37 - INFO - 	 Recall for 0.4 precision: 0.951
2024-10-12 22:37 - INFO - 	 Best Val. Loss: 0.088
2024-10-12 22:37 - INFO - 	 Best ROC-AUC: 0.977
2024-10-12 22:37 - INFO - 	 Best PR-AUC: 0.794
2024-10-12 22:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.970
2024-10-12 22:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.754
2024-10-12 22:37 - INFO - 	 Best Recall for 0.4 precision: 0.951
2024-10-12 22:37 - INFO - ---------------------------------------------
2024-10-12 22:38 - INFO - ---------------------------------------------
2024-10-12 22:38 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 22:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98393
2024-10-12 22:38 - INFO - 	 Train Loss: 0.085
2024-10-12 22:38 - INFO - 	 Val. Loss: 0.071
2024-10-12 22:38 - INFO - 	 ROC-AUC: 0.984
2024-10-12 22:38 - INFO - 	 PR-AUC: 0.856
2024-10-12 22:38 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:38 - INFO - 	 Best Val. Loss: 0.071
2024-10-12 22:38 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 22:38 - INFO - 	 Best PR-AUC: 0.856
2024-10-12 22:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 22:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.852
2024-10-12 22:38 - INFO - 	 Best Recall for 0.4 precision: 0.974
2024-10-12 22:38 - INFO - ---------------------------------------------
2024-10-12 22:38 - INFO - ---------------------------------------------
2024-10-12 22:38 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98751
2024-10-12 22:38 - INFO - 	 Train Loss: 0.072
2024-10-12 22:38 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:38 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:38 - INFO - 	 PR-AUC: 0.879
2024-10-12 22:38 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:38 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 22:38 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:38 - INFO - 	 Best PR-AUC: 0.879
2024-10-12 22:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.863
2024-10-12 22:38 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:38 - INFO - ---------------------------------------------
2024-10-12 22:39 - INFO - ---------------------------------------------
2024-10-12 22:39 - INFO - Epoch: 04 | Time: 0m 32s
2024-10-12 22:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9877
2024-10-12 22:39 - INFO - 	 Train Loss: 0.068
2024-10-12 22:39 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:39 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:39 - INFO - 	 PR-AUC: 0.889
2024-10-12 22:39 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:39 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:39 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:39 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 22:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.860
2024-10-12 22:39 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:39 - INFO - ---------------------------------------------
2024-10-12 22:39 - INFO - ---------------------------------------------
2024-10-12 22:39 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 22:39 - INFO - 	 Train Loss: 0.064
2024-10-12 22:39 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:39 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:39 - INFO - 	 PR-AUC: 0.890
2024-10-12 22:39 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:39 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 22:39 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:39 - INFO - 	 Best PR-AUC: 0.890
2024-10-12 22:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.882
2024-10-12 22:39 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:39 - INFO - ---------------------------------------------
2024-10-12 22:40 - INFO - ---------------------------------------------
2024-10-12 22:40 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 22:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98887
2024-10-12 22:40 - INFO - 	 Train Loss: 0.062
2024-10-12 22:40 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:40 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:40 - INFO - 	 PR-AUC: 0.894
2024-10-12 22:40 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:40 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:40 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:40 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 22:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.881
2024-10-12 22:40 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:40 - INFO - ---------------------------------------------
2024-10-12 22:40 - INFO - ---------------------------------------------
2024-10-12 22:40 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:40 - INFO - 	 Train Loss: 0.060
2024-10-12 22:40 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:40 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:40 - INFO - 	 PR-AUC: 0.894
2024-10-12 22:40 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 22:40 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:40 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:40 - INFO - 	 Best PR-AUC: 0.894
2024-10-12 22:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.881
2024-10-12 22:40 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:40 - INFO - ---------------------------------------------
2024-10-12 22:41 - INFO - ---------------------------------------------
2024-10-12 22:41 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:41 - INFO - 	 Train Loss: 0.057
2024-10-12 22:41 - INFO - 	 Val. Loss: 0.058
2024-10-12 22:41 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:41 - INFO - 	 PR-AUC: 0.895
2024-10-12 22:41 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:41 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:41 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:41 - INFO - 	 Best PR-AUC: 0.895
2024-10-12 22:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 22:41 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:41 - INFO - ---------------------------------------------
2024-10-12 22:41 - INFO - ---------------------------------------------
2024-10-12 22:41 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:41 - INFO - 	 Train Loss: 0.057
2024-10-12 22:41 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:41 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:41 - INFO - 	 PR-AUC: 0.899
2024-10-12 22:41 - INFO - 	 Recall for 0.4 precision: 0.981
2024-10-12 22:41 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:41 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:41 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 22:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 22:41 - INFO - 	 Best Recall for 0.4 precision: 0.981
2024-10-12 22:41 - INFO - ---------------------------------------------
2024-10-12 22:43 - INFO - Fit the preprocessing pipeline
2024-10-12 22:43 - INFO - Training using device: cuda
2024-10-12 22:43 - INFO - Creating generators
2024-10-12 22:43 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:43 - INFO - * Model:
2024-10-12 22:43 - INFO - * -----------
2024-10-12 22:43 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:43 - INFO - * -----------
2024-10-12 22:43 - INFO - Evaluating model based on: rocauc
2024-10-12 22:43 - INFO - Training..

2024-10-12 22:44 - INFO - ---------------------------------------------
2024-10-12 22:44 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 22:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97904
2024-10-12 22:44 - INFO - 	 Train Loss: 0.155
2024-10-12 22:44 - INFO - 	 Val. Loss: 0.081
2024-10-12 22:44 - INFO - 	 ROC-AUC: 0.979
2024-10-12 22:44 - INFO - 	 PR-AUC: 0.818
2024-10-12 22:44 - INFO - 	 Recall for 0.4 precision: 0.966
2024-10-12 22:44 - INFO - 	 Best Val. Loss: 0.081
2024-10-12 22:44 - INFO - 	 Best ROC-AUC: 0.979
2024-10-12 22:44 - INFO - 	 Best PR-AUC: 0.818
2024-10-12 22:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 22:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.788
2024-10-12 22:44 - INFO - 	 Best Recall for 0.4 precision: 0.966
2024-10-12 22:44 - INFO - ---------------------------------------------
2024-10-12 22:44 - INFO - ---------------------------------------------
2024-10-12 22:44 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 22:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98345
2024-10-12 22:44 - INFO - 	 Train Loss: 0.082
2024-10-12 22:44 - INFO - 	 Val. Loss: 0.079
2024-10-12 22:44 - INFO - 	 ROC-AUC: 0.983
2024-10-12 22:44 - INFO - 	 PR-AUC: 0.865
2024-10-12 22:44 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 22:44 - INFO - 	 Best Val. Loss: 0.079
2024-10-12 22:44 - INFO - 	 Best ROC-AUC: 0.983
2024-10-12 22:44 - INFO - 	 Best PR-AUC: 0.865
2024-10-12 22:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 22:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.810
2024-10-12 22:44 - INFO - 	 Best Recall for 0.4 precision: 0.970
2024-10-12 22:44 - INFO - ---------------------------------------------
2024-10-12 22:45 - INFO - ---------------------------------------------
2024-10-12 22:45 - INFO - Epoch: 03 | Time: 0m 32s
2024-10-12 22:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98658
2024-10-12 22:45 - INFO - 	 Train Loss: 0.073
2024-10-12 22:45 - INFO - 	 Val. Loss: 0.064
2024-10-12 22:45 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:45 - INFO - 	 PR-AUC: 0.885
2024-10-12 22:45 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:45 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 22:45 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:45 - INFO - 	 Best PR-AUC: 0.885
2024-10-12 22:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.854
2024-10-12 22:45 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:45 - INFO - ---------------------------------------------
2024-10-12 22:46 - INFO - ---------------------------------------------
2024-10-12 22:46 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98685
2024-10-12 22:46 - INFO - 	 Train Loss: 0.066
2024-10-12 22:46 - INFO - 	 Val. Loss: 0.065
2024-10-12 22:46 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:46 - INFO - 	 PR-AUC: 0.890
2024-10-12 22:46 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:46 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 22:46 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:46 - INFO - 	 Best PR-AUC: 0.890
2024-10-12 22:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.869
2024-10-12 22:46 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:46 - INFO - ---------------------------------------------
2024-10-12 22:46 - INFO - ---------------------------------------------
2024-10-12 22:46 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 22:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98744
2024-10-12 22:46 - INFO - 	 Train Loss: 0.063
2024-10-12 22:46 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:46 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:46 - INFO - 	 PR-AUC: 0.903
2024-10-12 22:46 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:46 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:46 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:46 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 22:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 22:46 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:46 - INFO - ---------------------------------------------
2024-10-12 22:47 - INFO - ---------------------------------------------
2024-10-12 22:47 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 22:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98843
2024-10-12 22:47 - INFO - 	 Train Loss: 0.061
2024-10-12 22:47 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:47 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:47 - INFO - 	 PR-AUC: 0.899
2024-10-12 22:47 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 22:47 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:47 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:47 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 22:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 22:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 22:47 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:47 - INFO - ---------------------------------------------
2024-10-12 22:47 - INFO - ---------------------------------------------
2024-10-12 22:47 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:47 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98881
2024-10-12 22:47 - INFO - 	 Train Loss: 0.059
2024-10-12 22:47 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:47 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:47 - INFO - 	 PR-AUC: 0.898
2024-10-12 22:47 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:47 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:47 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:47 - INFO - 	 Best PR-AUC: 0.903
2024-10-12 22:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 22:47 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:47 - INFO - ---------------------------------------------
2024-10-12 22:48 - INFO - ---------------------------------------------
2024-10-12 22:48 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:48 - INFO - 	 Train Loss: 0.057
2024-10-12 22:48 - INFO - 	 Val. Loss: 0.055
2024-10-12 22:48 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:48 - INFO - 	 PR-AUC: 0.904
2024-10-12 22:48 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:48 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:48 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:48 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 22:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.895
2024-10-12 22:48 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:48 - INFO - ---------------------------------------------
2024-10-12 22:48 - INFO - ---------------------------------------------
2024-10-12 22:48 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:48 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98912
2024-10-12 22:48 - INFO - 	 Train Loss: 0.056
2024-10-12 22:48 - INFO - 	 Val. Loss: 0.056
2024-10-12 22:48 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:48 - INFO - 	 PR-AUC: 0.904
2024-10-12 22:48 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 22:48 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:48 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:48 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 22:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.906
2024-10-12 22:48 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:48 - INFO - ---------------------------------------------
2024-10-12 22:49 - INFO - ---------------------------------------------
2024-10-12 22:49 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 22:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98918
2024-10-12 22:49 - INFO - 	 Train Loss: 0.055
2024-10-12 22:49 - INFO - 	 Val. Loss: 0.056
2024-10-12 22:49 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:49 - INFO - 	 PR-AUC: 0.900
2024-10-12 22:49 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:49 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 22:49 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:49 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 22:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.906
2024-10-12 22:49 - INFO - 	 Best Recall for 0.4 precision: 0.980
2024-10-12 22:49 - INFO - ---------------------------------------------
2024-10-12 22:50 - INFO - Fit the preprocessing pipeline
2024-10-12 22:50 - INFO - Training using device: cuda
2024-10-12 22:50 - INFO - Creating generators
2024-10-12 22:50 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:50 - INFO - * Model:
2024-10-12 22:50 - INFO - * -----------
2024-10-12 22:50 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:50 - INFO - * -----------
2024-10-12 22:50 - INFO - Evaluating model based on: rocauc
2024-10-12 22:50 - INFO - Training..

2024-10-12 22:51 - INFO - ---------------------------------------------
2024-10-12 22:51 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 22:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98131
2024-10-12 22:51 - INFO - 	 Train Loss: 0.160
2024-10-12 22:51 - INFO - 	 Val. Loss: 0.075
2024-10-12 22:51 - INFO - 	 ROC-AUC: 0.981
2024-10-12 22:51 - INFO - 	 PR-AUC: 0.835
2024-10-12 22:51 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 22:51 - INFO - 	 Best Val. Loss: 0.075
2024-10-12 22:51 - INFO - 	 Best ROC-AUC: 0.981
2024-10-12 22:51 - INFO - 	 Best PR-AUC: 0.835
2024-10-12 22:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 22:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.790
2024-10-12 22:51 - INFO - 	 Best Recall for 0.4 precision: 0.968
2024-10-12 22:51 - INFO - ---------------------------------------------
2024-10-12 22:51 - INFO - ---------------------------------------------
2024-10-12 22:51 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 22:51 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98565
2024-10-12 22:51 - INFO - 	 Train Loss: 0.083
2024-10-12 22:51 - INFO - 	 Val. Loss: 0.066
2024-10-12 22:51 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:51 - INFO - 	 PR-AUC: 0.869
2024-10-12 22:51 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:51 - INFO - 	 Best Val. Loss: 0.066
2024-10-12 22:51 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 22:51 - INFO - 	 Best PR-AUC: 0.869
2024-10-12 22:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 22:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.840
2024-10-12 22:51 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 22:51 - INFO - ---------------------------------------------
2024-10-12 22:52 - INFO - ---------------------------------------------
2024-10-12 22:52 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98651
2024-10-12 22:52 - INFO - 	 Train Loss: 0.072
2024-10-12 22:52 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:52 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:52 - INFO - 	 PR-AUC: 0.876
2024-10-12 22:52 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:52 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:52 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:52 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 22:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.858
2024-10-12 22:52 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 22:52 - INFO - ---------------------------------------------
2024-10-12 22:52 - INFO - ---------------------------------------------
2024-10-12 22:52 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:52 - INFO - 	 Train Loss: 0.068
2024-10-12 22:52 - INFO - 	 Val. Loss: 0.063
2024-10-12 22:52 - INFO - 	 ROC-AUC: 0.986
2024-10-12 22:52 - INFO - 	 PR-AUC: 0.876
2024-10-12 22:52 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:52 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 22:52 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:52 - INFO - 	 Best PR-AUC: 0.876
2024-10-12 22:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.865
2024-10-12 22:52 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 22:52 - INFO - ---------------------------------------------
2024-10-12 22:53 - INFO - ---------------------------------------------
2024-10-12 22:53 - INFO - Epoch: 05 | Time: 0m 32s
2024-10-12 22:53 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98653
2024-10-12 22:53 - INFO - 	 Train Loss: 0.064
2024-10-12 22:53 - INFO - 	 Val. Loss: 0.062
2024-10-12 22:53 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:53 - INFO - 	 PR-AUC: 0.882
2024-10-12 22:53 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 22:53 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 22:53 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:53 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 22:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 22:53 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 22:53 - INFO - ---------------------------------------------
2024-10-12 22:53 - INFO - ---------------------------------------------
2024-10-12 22:53 - INFO - Epoch: 06 | Time: 0m 32s
2024-10-12 22:53 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98833
2024-10-12 22:53 - INFO - 	 Train Loss: 0.061
2024-10-12 22:53 - INFO - 	 Val. Loss: 0.059
2024-10-12 22:53 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:53 - INFO - 	 PR-AUC: 0.897
2024-10-12 22:53 - INFO - 	 Recall for 0.4 precision: 0.976
2024-10-12 22:53 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:53 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 22:53 - INFO - 	 Best PR-AUC: 0.897
2024-10-12 22:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.888
2024-10-12 22:53 - INFO - 	 Best Recall for 0.4 precision: 0.976
2024-10-12 22:53 - INFO - ---------------------------------------------
2024-10-12 22:54 - INFO - ---------------------------------------------
2024-10-12 22:54 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 22:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98875
2024-10-12 22:54 - INFO - 	 Train Loss: 0.059
2024-10-12 22:54 - INFO - 	 Val. Loss: 0.060
2024-10-12 22:54 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:54 - INFO - 	 PR-AUC: 0.899
2024-10-12 22:54 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:54 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:54 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:54 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 22:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.898
2024-10-12 22:54 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:54 - INFO - ---------------------------------------------
2024-10-12 22:55 - INFO - ---------------------------------------------
2024-10-12 22:55 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 22:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98878
2024-10-12 22:55 - INFO - 	 Train Loss: 0.058
2024-10-12 22:55 - INFO - 	 Val. Loss: 0.061
2024-10-12 22:55 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:55 - INFO - 	 PR-AUC: 0.895
2024-10-12 22:55 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 22:55 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:55 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:55 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 22:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.898
2024-10-12 22:55 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:55 - INFO - ---------------------------------------------
2024-10-12 22:55 - INFO - ---------------------------------------------
2024-10-12 22:55 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 22:55 - INFO - 	 Train Loss: 0.056
2024-10-12 22:55 - INFO - 	 Val. Loss: 0.062
2024-10-12 22:55 - INFO - 	 ROC-AUC: 0.988
2024-10-12 22:55 - INFO - 	 PR-AUC: 0.888
2024-10-12 22:55 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:55 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 22:55 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:55 - INFO - 	 Best PR-AUC: 0.899
2024-10-12 22:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 22:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.898
2024-10-12 22:55 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:55 - INFO - ---------------------------------------------
2024-10-12 22:56 - INFO - ---------------------------------------------
2024-10-12 22:56 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 22:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98889
2024-10-12 22:56 - INFO - 	 Train Loss: 0.055
2024-10-12 22:56 - INFO - 	 Val. Loss: 0.057
2024-10-12 22:56 - INFO - 	 ROC-AUC: 0.989
2024-10-12 22:56 - INFO - 	 PR-AUC: 0.904
2024-10-12 22:56 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:56 - INFO - 	 Best Val. Loss: 0.057
2024-10-12 22:56 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 22:56 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 22:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 22:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.901
2024-10-12 22:56 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 22:56 - INFO - ---------------------------------------------
2024-10-12 22:57 - INFO - Fit the preprocessing pipeline
2024-10-12 22:57 - INFO - Training using device: cuda
2024-10-12 22:57 - INFO - Creating generators
2024-10-12 22:57 - INFO - The model has 651,257 trainable parameters
2024-10-12 22:57 - INFO - * Model:
2024-10-12 22:57 - INFO - * -----------
2024-10-12 22:57 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 22:57 - INFO - * -----------
2024-10-12 22:57 - INFO - Evaluating model based on: rocauc
2024-10-12 22:57 - INFO - Training..

2024-10-12 22:58 - INFO - ---------------------------------------------
2024-10-12 22:58 - INFO - Epoch: 01 | Time: 0m 32s
2024-10-12 22:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98114
2024-10-12 22:58 - INFO - 	 Train Loss: 0.168
2024-10-12 22:58 - INFO - 	 Val. Loss: 0.077
2024-10-12 22:58 - INFO - 	 ROC-AUC: 0.981
2024-10-12 22:58 - INFO - 	 PR-AUC: 0.823
2024-10-12 22:58 - INFO - 	 Recall for 0.4 precision: 0.969
2024-10-12 22:58 - INFO - 	 Best Val. Loss: 0.077
2024-10-12 22:58 - INFO - 	 Best ROC-AUC: 0.981
2024-10-12 22:58 - INFO - 	 Best PR-AUC: 0.823
2024-10-12 22:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.977
2024-10-12 22:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.791
2024-10-12 22:58 - INFO - 	 Best Recall for 0.4 precision: 0.969
2024-10-12 22:58 - INFO - ---------------------------------------------
2024-10-12 22:58 - INFO - ---------------------------------------------
2024-10-12 22:58 - INFO - Epoch: 02 | Time: 0m 32s
2024-10-12 22:58 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98443
2024-10-12 22:58 - INFO - 	 Train Loss: 0.086
2024-10-12 22:58 - INFO - 	 Val. Loss: 0.080
2024-10-12 22:58 - INFO - 	 ROC-AUC: 0.984
2024-10-12 22:58 - INFO - 	 PR-AUC: 0.852
2024-10-12 22:58 - INFO - 	 Recall for 0.4 precision: 0.970
2024-10-12 22:58 - INFO - 	 Best Val. Loss: 0.077
2024-10-12 22:58 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 22:58 - INFO - 	 Best PR-AUC: 0.852
2024-10-12 22:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.841
2024-10-12 22:58 - INFO - 	 Best Recall for 0.4 precision: 0.970
2024-10-12 22:58 - INFO - ---------------------------------------------
2024-10-12 22:59 - INFO - ---------------------------------------------
2024-10-12 22:59 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 22:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98547
2024-10-12 22:59 - INFO - 	 Train Loss: 0.075
2024-10-12 22:59 - INFO - 	 Val. Loss: 0.065
2024-10-12 22:59 - INFO - 	 ROC-AUC: 0.985
2024-10-12 22:59 - INFO - 	 PR-AUC: 0.867
2024-10-12 22:59 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 22:59 - INFO - 	 Best Val. Loss: 0.065
2024-10-12 22:59 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 22:59 - INFO - 	 Best PR-AUC: 0.867
2024-10-12 22:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 22:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.855
2024-10-12 22:59 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 22:59 - INFO - ---------------------------------------------
2024-10-12 22:59 - INFO - ---------------------------------------------
2024-10-12 22:59 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 22:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98698
2024-10-12 22:59 - INFO - 	 Train Loss: 0.069
2024-10-12 22:59 - INFO - 	 Val. Loss: 0.062
2024-10-12 22:59 - INFO - 	 ROC-AUC: 0.987
2024-10-12 22:59 - INFO - 	 PR-AUC: 0.884
2024-10-12 22:59 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 22:59 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 22:59 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 22:59 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 22:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 22:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.867
2024-10-12 22:59 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 22:59 - INFO - ---------------------------------------------
2024-10-12 23:00 - INFO - ---------------------------------------------
2024-10-12 23:00 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 23:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98787
2024-10-12 23:00 - INFO - 	 Train Loss: 0.066
2024-10-12 23:00 - INFO - 	 Val. Loss: 0.062
2024-10-12 23:00 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:00 - INFO - 	 PR-AUC: 0.884
2024-10-12 23:00 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 23:00 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 23:00 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:00 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 23:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.867
2024-10-12 23:00 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 23:00 - INFO - ---------------------------------------------
2024-10-12 23:00 - INFO - ---------------------------------------------
2024-10-12 23:00 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 23:00 - INFO - 	 Train Loss: 0.063
2024-10-12 23:00 - INFO - 	 Val. Loss: 0.059
2024-10-12 23:00 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:00 - INFO - 	 PR-AUC: 0.886
2024-10-12 23:00 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:00 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 23:00 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:00 - INFO - 	 Best PR-AUC: 0.886
2024-10-12 23:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 23:00 - INFO - 	 Best Recall for 0.4 precision: 0.977
2024-10-12 23:00 - INFO - ---------------------------------------------
2024-10-12 23:01 - INFO - ---------------------------------------------
2024-10-12 23:01 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 23:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98873
2024-10-12 23:01 - INFO - 	 Train Loss: 0.061
2024-10-12 23:01 - INFO - 	 Val. Loss: 0.062
2024-10-12 23:01 - INFO - 	 ROC-AUC: 0.989
2024-10-12 23:01 - INFO - 	 PR-AUC: 0.896
2024-10-12 23:01 - INFO - 	 Recall for 0.4 precision: 0.982
2024-10-12 23:01 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 23:01 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 23:01 - INFO - 	 Best PR-AUC: 0.896
2024-10-12 23:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 23:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 23:01 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 23:01 - INFO - ---------------------------------------------
2024-10-12 23:01 - INFO - ---------------------------------------------
2024-10-12 23:01 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 23:01 - INFO - 	 Train Loss: 0.059
2024-10-12 23:01 - INFO - 	 Val. Loss: 0.059
2024-10-12 23:01 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:01 - INFO - 	 PR-AUC: 0.890
2024-10-12 23:01 - INFO - 	 Recall for 0.4 precision: 0.980
2024-10-12 23:01 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 23:01 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 23:01 - INFO - 	 Best PR-AUC: 0.896
2024-10-12 23:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 23:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.878
2024-10-12 23:01 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 23:01 - INFO - ---------------------------------------------
2024-10-12 23:02 - INFO - ---------------------------------------------
2024-10-12 23:02 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 23:02 - INFO - 	 Train Loss: 0.058
2024-10-12 23:02 - INFO - 	 Val. Loss: 0.055
2024-10-12 23:02 - INFO - 	 ROC-AUC: 0.989
2024-10-12 23:02 - INFO - 	 PR-AUC: 0.904
2024-10-12 23:02 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 23:02 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 23:02 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 23:02 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 23:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 23:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 23:02 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 23:02 - INFO - ---------------------------------------------
2024-10-12 23:02 - INFO - ---------------------------------------------
2024-10-12 23:02 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 23:02 - INFO - 	 Train Loss: 0.056
2024-10-12 23:02 - INFO - 	 Val. Loss: 0.059
2024-10-12 23:02 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:02 - INFO - 	 PR-AUC: 0.898
2024-10-12 23:02 - INFO - 	 Recall for 0.4 precision: 0.974
2024-10-12 23:02 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 23:02 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 23:02 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 23:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.985
2024-10-12 23:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 23:02 - INFO - 	 Best Recall for 0.4 precision: 0.982
2024-10-12 23:02 - INFO - ---------------------------------------------
2024-10-12 23:04 - INFO - Fit the preprocessing pipeline
2024-10-12 23:04 - INFO - Training using device: cuda
2024-10-12 23:04 - INFO - Creating generators
2024-10-12 23:04 - INFO - The model has 651,257 trainable parameters
2024-10-12 23:04 - INFO - * Model:
2024-10-12 23:04 - INFO - * -----------
2024-10-12 23:04 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 23:04 - INFO - * -----------
2024-10-12 23:04 - INFO - Evaluating model based on: rocauc
2024-10-12 23:04 - INFO - Training..

2024-10-12 23:04 - INFO - ---------------------------------------------
2024-10-12 23:04 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 23:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.9785
2024-10-12 23:04 - INFO - 	 Train Loss: 0.156
2024-10-12 23:04 - INFO - 	 Val. Loss: 0.085
2024-10-12 23:04 - INFO - 	 ROC-AUC: 0.978
2024-10-12 23:04 - INFO - 	 PR-AUC: 0.818
2024-10-12 23:04 - INFO - 	 Recall for 0.4 precision: 0.959
2024-10-12 23:04 - INFO - 	 Best Val. Loss: 0.085
2024-10-12 23:04 - INFO - 	 Best ROC-AUC: 0.978
2024-10-12 23:04 - INFO - 	 Best PR-AUC: 0.818
2024-10-12 23:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.974
2024-10-12 23:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.790
2024-10-12 23:04 - INFO - 	 Best Recall for 0.4 precision: 0.959
2024-10-12 23:04 - INFO - ---------------------------------------------
2024-10-12 23:05 - INFO - ---------------------------------------------
2024-10-12 23:05 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 23:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98453
2024-10-12 23:05 - INFO - 	 Train Loss: 0.084
2024-10-12 23:05 - INFO - 	 Val. Loss: 0.068
2024-10-12 23:05 - INFO - 	 ROC-AUC: 0.985
2024-10-12 23:05 - INFO - 	 PR-AUC: 0.850
2024-10-12 23:05 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:05 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 23:05 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 23:05 - INFO - 	 Best PR-AUC: 0.850
2024-10-12 23:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 23:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.843
2024-10-12 23:05 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 23:05 - INFO - ---------------------------------------------
2024-10-12 23:06 - INFO - ---------------------------------------------
2024-10-12 23:06 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 23:06 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98466
2024-10-12 23:06 - INFO - 	 Train Loss: 0.073
2024-10-12 23:06 - INFO - 	 Val. Loss: 0.071
2024-10-12 23:06 - INFO - 	 ROC-AUC: 0.985
2024-10-12 23:06 - INFO - 	 PR-AUC: 0.862
2024-10-12 23:06 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:06 - INFO - 	 Best Val. Loss: 0.068
2024-10-12 23:06 - INFO - 	 Best ROC-AUC: 0.985
2024-10-12 23:06 - INFO - 	 Best PR-AUC: 0.862
2024-10-12 23:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.982
2024-10-12 23:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.842
2024-10-12 23:06 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 23:06 - INFO - ---------------------------------------------
2024-10-12 23:06 - INFO - ---------------------------------------------
2024-10-12 23:06 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 23:06 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98728
2024-10-12 23:06 - INFO - 	 Train Loss: 0.070
2024-10-12 23:06 - INFO - 	 Val. Loss: 0.063
2024-10-12 23:06 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:06 - INFO - 	 PR-AUC: 0.875
2024-10-12 23:06 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:06 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 23:06 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:06 - INFO - 	 Best PR-AUC: 0.875
2024-10-12 23:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.856
2024-10-12 23:06 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 23:06 - INFO - ---------------------------------------------
2024-10-12 23:07 - INFO - ---------------------------------------------
2024-10-12 23:07 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 23:07 - INFO - 	 Train Loss: 0.065
2024-10-12 23:07 - INFO - 	 Val. Loss: 0.065
2024-10-12 23:07 - INFO - 	 ROC-AUC: 0.986
2024-10-12 23:07 - INFO - 	 PR-AUC: 0.870
2024-10-12 23:07 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 23:07 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 23:07 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:07 - INFO - 	 Best PR-AUC: 0.875
2024-10-12 23:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.856
2024-10-12 23:07 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 23:07 - INFO - ---------------------------------------------
2024-10-12 23:07 - INFO - ---------------------------------------------
2024-10-12 23:07 - INFO - Epoch: 06 | Time: 0m 33s
2024-10-12 23:07 - INFO - 	 Train Loss: 0.063
2024-10-12 23:07 - INFO - 	 Val. Loss: 0.063
2024-10-12 23:07 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:07 - INFO - 	 PR-AUC: 0.877
2024-10-12 23:07 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 23:07 - INFO - 	 Best Val. Loss: 0.063
2024-10-12 23:07 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:07 - INFO - 	 Best PR-AUC: 0.877
2024-10-12 23:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.885
2024-10-12 23:07 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:07 - INFO - ---------------------------------------------
2024-10-12 23:08 - INFO - ---------------------------------------------
2024-10-12 23:08 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 23:08 - INFO - 	 Train Loss: 0.061
2024-10-12 23:08 - INFO - 	 Val. Loss: 0.062
2024-10-12 23:08 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:08 - INFO - 	 PR-AUC: 0.878
2024-10-12 23:08 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 23:08 - INFO - 	 Best Val. Loss: 0.062
2024-10-12 23:08 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:08 - INFO - 	 Best PR-AUC: 0.878
2024-10-12 23:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.886
2024-10-12 23:08 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:08 - INFO - ---------------------------------------------
2024-10-12 23:08 - INFO - ---------------------------------------------
2024-10-12 23:08 - INFO - Epoch: 08 | Time: 0m 32s
2024-10-12 23:08 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98752
2024-10-12 23:08 - INFO - 	 Train Loss: 0.059
2024-10-12 23:08 - INFO - 	 Val. Loss: 0.061
2024-10-12 23:08 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:08 - INFO - 	 PR-AUC: 0.884
2024-10-12 23:08 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:08 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 23:08 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:08 - INFO - 	 Best PR-AUC: 0.884
2024-10-12 23:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.877
2024-10-12 23:08 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:08 - INFO - ---------------------------------------------
2024-10-12 23:09 - INFO - ---------------------------------------------
2024-10-12 23:09 - INFO - Epoch: 09 | Time: 0m 32s
2024-10-12 23:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98781
2024-10-12 23:09 - INFO - 	 Train Loss: 0.057
2024-10-12 23:09 - INFO - 	 Val. Loss: 0.062
2024-10-12 23:09 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:09 - INFO - 	 PR-AUC: 0.889
2024-10-12 23:09 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:09 - INFO - 	 Best Val. Loss: 0.061
2024-10-12 23:09 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:09 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 23:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 23:09 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:09 - INFO - ---------------------------------------------
2024-10-12 23:09 - INFO - ---------------------------------------------
2024-10-12 23:09 - INFO - Epoch: 10 | Time: 0m 32s
2024-10-12 23:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98792
2024-10-12 23:09 - INFO - 	 Train Loss: 0.057
2024-10-12 23:09 - INFO - 	 Val. Loss: 0.058
2024-10-12 23:09 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:09 - INFO - 	 PR-AUC: 0.893
2024-10-12 23:09 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 23:09 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 23:09 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:09 - INFO - 	 Best PR-AUC: 0.893
2024-10-12 23:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.987
2024-10-12 23:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.888
2024-10-12 23:09 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:09 - INFO - ---------------------------------------------
2024-10-12 23:11 - INFO - Fit the preprocessing pipeline
2024-10-12 23:11 - INFO - Training using device: cuda
2024-10-12 23:11 - INFO - Creating generators
2024-10-12 23:11 - INFO - The model has 651,257 trainable parameters
2024-10-12 23:11 - INFO - * Model:
2024-10-12 23:11 - INFO - * -----------
2024-10-12 23:11 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-10-12 23:11 - INFO - * -----------
2024-10-12 23:11 - INFO - Evaluating model based on: rocauc
2024-10-12 23:11 - INFO - Training..

2024-10-12 23:11 - INFO - ---------------------------------------------
2024-10-12 23:11 - INFO - Epoch: 01 | Time: 0m 31s
2024-10-12 23:11 - INFO - 	 New best val_rocauc loss was found, current best value is 0.97992
2024-10-12 23:11 - INFO - 	 Train Loss: 0.157
2024-10-12 23:11 - INFO - 	 Val. Loss: 0.079
2024-10-12 23:11 - INFO - 	 ROC-AUC: 0.980
2024-10-12 23:11 - INFO - 	 PR-AUC: 0.835
2024-10-12 23:11 - INFO - 	 Recall for 0.4 precision: 0.968
2024-10-12 23:11 - INFO - 	 Best Val. Loss: 0.079
2024-10-12 23:11 - INFO - 	 Best ROC-AUC: 0.980
2024-10-12 23:11 - INFO - 	 Best PR-AUC: 0.835
2024-10-12 23:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.979
2024-10-12 23:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.811
2024-10-12 23:11 - INFO - 	 Best Recall for 0.4 precision: 0.968
2024-10-12 23:11 - INFO - ---------------------------------------------
2024-10-12 23:12 - INFO - ---------------------------------------------
2024-10-12 23:12 - INFO - Epoch: 02 | Time: 0m 31s
2024-10-12 23:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98428
2024-10-12 23:12 - INFO - 	 Train Loss: 0.082
2024-10-12 23:12 - INFO - 	 Val. Loss: 0.071
2024-10-12 23:12 - INFO - 	 ROC-AUC: 0.984
2024-10-12 23:12 - INFO - 	 PR-AUC: 0.864
2024-10-12 23:12 - INFO - 	 Recall for 0.4 precision: 0.973
2024-10-12 23:12 - INFO - 	 Best Val. Loss: 0.071
2024-10-12 23:12 - INFO - 	 Best ROC-AUC: 0.984
2024-10-12 23:12 - INFO - 	 Best PR-AUC: 0.864
2024-10-12 23:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.981
2024-10-12 23:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.820
2024-10-12 23:12 - INFO - 	 Best Recall for 0.4 precision: 0.973
2024-10-12 23:12 - INFO - ---------------------------------------------
2024-10-12 23:12 - INFO - ---------------------------------------------
2024-10-12 23:12 - INFO - Epoch: 03 | Time: 0m 31s
2024-10-12 23:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98599
2024-10-12 23:12 - INFO - 	 Train Loss: 0.071
2024-10-12 23:12 - INFO - 	 Val. Loss: 0.067
2024-10-12 23:12 - INFO - 	 ROC-AUC: 0.986
2024-10-12 23:12 - INFO - 	 PR-AUC: 0.874
2024-10-12 23:12 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:12 - INFO - 	 Best Val. Loss: 0.067
2024-10-12 23:12 - INFO - 	 Best ROC-AUC: 0.986
2024-10-12 23:12 - INFO - 	 Best PR-AUC: 0.874
2024-10-12 23:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.983
2024-10-12 23:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.838
2024-10-12 23:12 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 23:12 - INFO - ---------------------------------------------
2024-10-12 23:13 - INFO - ---------------------------------------------
2024-10-12 23:13 - INFO - Epoch: 04 | Time: 0m 31s
2024-10-12 23:13 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98652
2024-10-12 23:13 - INFO - 	 Train Loss: 0.067
2024-10-12 23:13 - INFO - 	 Val. Loss: 0.064
2024-10-12 23:13 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:13 - INFO - 	 PR-AUC: 0.882
2024-10-12 23:13 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:13 - INFO - 	 Best Val. Loss: 0.064
2024-10-12 23:13 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:13 - INFO - 	 Best PR-AUC: 0.882
2024-10-12 23:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.984
2024-10-12 23:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.863
2024-10-12 23:13 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 23:13 - INFO - ---------------------------------------------
2024-10-12 23:14 - INFO - ---------------------------------------------
2024-10-12 23:14 - INFO - Epoch: 05 | Time: 0m 31s
2024-10-12 23:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98748
2024-10-12 23:14 - INFO - 	 Train Loss: 0.064
2024-10-12 23:14 - INFO - 	 Val. Loss: 0.060
2024-10-12 23:14 - INFO - 	 ROC-AUC: 0.987
2024-10-12 23:14 - INFO - 	 PR-AUC: 0.889
2024-10-12 23:14 - INFO - 	 Recall for 0.4 precision: 0.975
2024-10-12 23:14 - INFO - 	 Best Val. Loss: 0.060
2024-10-12 23:14 - INFO - 	 Best ROC-AUC: 0.987
2024-10-12 23:14 - INFO - 	 Best PR-AUC: 0.889
2024-10-12 23:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.871
2024-10-12 23:14 - INFO - 	 Best Recall for 0.4 precision: 0.975
2024-10-12 23:14 - INFO - ---------------------------------------------
2024-10-12 23:14 - INFO - ---------------------------------------------
2024-10-12 23:14 - INFO - Epoch: 06 | Time: 0m 31s
2024-10-12 23:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98839
2024-10-12 23:14 - INFO - 	 Train Loss: 0.062
2024-10-12 23:14 - INFO - 	 Val. Loss: 0.059
2024-10-12 23:14 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:14 - INFO - 	 PR-AUC: 0.896
2024-10-12 23:14 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:14 - INFO - 	 Best Val. Loss: 0.059
2024-10-12 23:14 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:14 - INFO - 	 Best PR-AUC: 0.896
2024-10-12 23:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.879
2024-10-12 23:14 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 23:14 - INFO - ---------------------------------------------
2024-10-12 23:15 - INFO - ---------------------------------------------
2024-10-12 23:15 - INFO - Epoch: 07 | Time: 0m 31s
2024-10-12 23:15 - INFO - 	 Train Loss: 0.059
2024-10-12 23:15 - INFO - 	 Val. Loss: 0.058
2024-10-12 23:15 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:15 - INFO - 	 PR-AUC: 0.898
2024-10-12 23:15 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:15 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 23:15 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:15 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 23:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.890
2024-10-12 23:15 - INFO - 	 Best Recall for 0.4 precision: 0.978
2024-10-12 23:15 - INFO - ---------------------------------------------
2024-10-12 23:15 - INFO - ---------------------------------------------
2024-10-12 23:15 - INFO - Epoch: 08 | Time: 0m 31s
2024-10-12 23:15 - INFO - 	 Train Loss: 0.058
2024-10-12 23:15 - INFO - 	 Val. Loss: 0.059
2024-10-12 23:15 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:15 - INFO - 	 PR-AUC: 0.894
2024-10-12 23:15 - INFO - 	 Recall for 0.4 precision: 0.979
2024-10-12 23:15 - INFO - 	 Best Val. Loss: 0.058
2024-10-12 23:15 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:15 - INFO - 	 Best PR-AUC: 0.898
2024-10-12 23:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.890
2024-10-12 23:15 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:15 - INFO - ---------------------------------------------
2024-10-12 23:16 - INFO - ---------------------------------------------
2024-10-12 23:16 - INFO - Epoch: 09 | Time: 0m 31s
2024-10-12 23:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98848
2024-10-12 23:16 - INFO - 	 Train Loss: 0.059
2024-10-12 23:16 - INFO - 	 Val. Loss: 0.056
2024-10-12 23:16 - INFO - 	 ROC-AUC: 0.988
2024-10-12 23:16 - INFO - 	 PR-AUC: 0.904
2024-10-12 23:16 - INFO - 	 Recall for 0.4 precision: 0.977
2024-10-12 23:16 - INFO - 	 Best Val. Loss: 0.056
2024-10-12 23:16 - INFO - 	 Best ROC-AUC: 0.988
2024-10-12 23:16 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 23:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.893
2024-10-12 23:16 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:16 - INFO - ---------------------------------------------
2024-10-12 23:16 - INFO - ---------------------------------------------
2024-10-12 23:16 - INFO - Epoch: 10 | Time: 0m 31s
2024-10-12 23:16 - INFO - 	 New best val_rocauc loss was found, current best value is 0.98864
2024-10-12 23:16 - INFO - 	 Train Loss: 0.056
2024-10-12 23:16 - INFO - 	 Val. Loss: 0.055
2024-10-12 23:16 - INFO - 	 ROC-AUC: 0.989
2024-10-12 23:16 - INFO - 	 PR-AUC: 0.904
2024-10-12 23:16 - INFO - 	 Recall for 0.4 precision: 0.978
2024-10-12 23:16 - INFO - 	 Best Val. Loss: 0.055
2024-10-12 23:16 - INFO - 	 Best ROC-AUC: 0.989
2024-10-12 23:16 - INFO - 	 Best PR-AUC: 0.904
2024-10-12 23:16 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.986
2024-10-12 23:16 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.892
2024-10-12 23:16 - INFO - 	 Best Recall for 0.4 precision: 0.979
2024-10-12 23:16 - INFO - ---------------------------------------------
