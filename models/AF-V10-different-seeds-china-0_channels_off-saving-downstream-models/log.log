2024-11-02 21:53 - INFO - Fit the preprocessing pipeline
2024-11-02 21:53 - INFO - Training using device: mps
2024-11-02 21:53 - INFO - Creating generators
2024-11-02 21:53 - INFO - The model has 651,257 trainable parameters
2024-11-02 21:53 - INFO - * Model:
2024-11-02 21:53 - INFO - * -----------
2024-11-02 21:53 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 21:53 - INFO - * -----------
2024-11-02 21:53 - INFO - Evaluating model based on: aucpr
2024-11-02 21:53 - INFO - Training..

2024-11-02 21:55 - INFO - ---------------------------------------------
2024-11-02 21:55 - INFO - Epoch: 01 | Time: 1m 57s
2024-11-02 21:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.11647
2024-11-02 21:55 - INFO - 	 Train Loss: 0.260
2024-11-02 21:55 - INFO - 	 Val. Loss: 0.311
2024-11-02 21:55 - INFO - 	 ROC-AUC: 0.728
2024-11-02 21:55 - INFO - 	 PR-AUC: 0.116
2024-11-02 21:55 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-02 21:55 - INFO - 	 Best Val. Loss: 0.311
2024-11-02 21:55 - INFO - 	 Best ROC-AUC: 0.728
2024-11-02 21:55 - INFO - 	 Best PR-AUC: 0.116
2024-11-02 21:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.783
2024-11-02 21:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.151
2024-11-02 21:55 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-02 21:55 - INFO - ---------------------------------------------
2024-11-02 21:57 - INFO - ---------------------------------------------
2024-11-02 21:57 - INFO - Epoch: 02 | Time: 1m 53s
2024-11-02 21:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.15702
2024-11-02 21:57 - INFO - 	 Train Loss: 0.222
2024-11-02 21:57 - INFO - 	 Val. Loss: 0.287
2024-11-02 21:57 - INFO - 	 ROC-AUC: 0.744
2024-11-02 21:57 - INFO - 	 PR-AUC: 0.157
2024-11-02 21:57 - INFO - 	 Recall for 0.4 precision: 0.198
2024-11-02 21:57 - INFO - 	 Best Val. Loss: 0.287
2024-11-02 21:57 - INFO - 	 Best ROC-AUC: 0.744
2024-11-02 21:57 - INFO - 	 Best PR-AUC: 0.157
2024-11-02 21:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.772
2024-11-02 21:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.158
2024-11-02 21:57 - INFO - 	 Best Recall for 0.4 precision: 0.198
2024-11-02 21:57 - INFO - ---------------------------------------------
2024-11-02 21:59 - INFO - ---------------------------------------------
2024-11-02 21:59 - INFO - Epoch: 03 | Time: 1m 53s
2024-11-02 21:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.20998
2024-11-02 21:59 - INFO - 	 Train Loss: 0.195
2024-11-02 21:59 - INFO - 	 Val. Loss: 0.249
2024-11-02 21:59 - INFO - 	 ROC-AUC: 0.785
2024-11-02 21:59 - INFO - 	 PR-AUC: 0.210
2024-11-02 21:59 - INFO - 	 Recall for 0.4 precision: 0.023
2024-11-02 21:59 - INFO - 	 Best Val. Loss: 0.249
2024-11-02 21:59 - INFO - 	 Best ROC-AUC: 0.785
2024-11-02 21:59 - INFO - 	 Best PR-AUC: 0.210
2024-11-02 21:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.788
2024-11-02 21:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-02 21:59 - INFO - 	 Best Recall for 0.4 precision: 0.198
2024-11-02 21:59 - INFO - ---------------------------------------------
2024-11-02 22:01 - INFO - ---------------------------------------------
2024-11-02 22:01 - INFO - Epoch: 04 | Time: 1m 53s
2024-11-02 22:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.26084
2024-11-02 22:01 - INFO - 	 Train Loss: 0.178
2024-11-02 22:01 - INFO - 	 Val. Loss: 0.193
2024-11-02 22:01 - INFO - 	 ROC-AUC: 0.804
2024-11-02 22:01 - INFO - 	 PR-AUC: 0.261
2024-11-02 22:01 - INFO - 	 Recall for 0.4 precision: 0.332
2024-11-02 22:01 - INFO - 	 Best Val. Loss: 0.193
2024-11-02 22:01 - INFO - 	 Best ROC-AUC: 0.804
2024-11-02 22:01 - INFO - 	 Best PR-AUC: 0.261
2024-11-02 22:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.786
2024-11-02 22:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-02 22:01 - INFO - 	 Best Recall for 0.4 precision: 0.332
2024-11-02 22:01 - INFO - ---------------------------------------------
2024-11-02 22:03 - INFO - ---------------------------------------------
2024-11-02 22:03 - INFO - Epoch: 05 | Time: 1m 54s
2024-11-02 22:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.32057
2024-11-02 22:03 - INFO - 	 Train Loss: 0.168
2024-11-02 22:03 - INFO - 	 Val. Loss: 0.181
2024-11-02 22:03 - INFO - 	 ROC-AUC: 0.815
2024-11-02 22:03 - INFO - 	 PR-AUC: 0.321
2024-11-02 22:03 - INFO - 	 Recall for 0.4 precision: 0.403
2024-11-02 22:03 - INFO - 	 Best Val. Loss: 0.181
2024-11-02 22:03 - INFO - 	 Best ROC-AUC: 0.815
2024-11-02 22:03 - INFO - 	 Best PR-AUC: 0.321
2024-11-02 22:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.809
2024-11-02 22:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.193
2024-11-02 22:03 - INFO - 	 Best Recall for 0.4 precision: 0.403
2024-11-02 22:03 - INFO - ---------------------------------------------
2024-11-02 22:05 - INFO - ---------------------------------------------
2024-11-02 22:05 - INFO - Epoch: 06 | Time: 1m 56s
2024-11-02 22:05 - INFO - 	 Train Loss: 0.160
2024-11-02 22:05 - INFO - 	 Val. Loss: 0.176
2024-11-02 22:05 - INFO - 	 ROC-AUC: 0.827
2024-11-02 22:05 - INFO - 	 PR-AUC: 0.303
2024-11-02 22:05 - INFO - 	 Recall for 0.4 precision: 0.298
2024-11-02 22:05 - INFO - 	 Best Val. Loss: 0.176
2024-11-02 22:05 - INFO - 	 Best ROC-AUC: 0.827
2024-11-02 22:05 - INFO - 	 Best PR-AUC: 0.321
2024-11-02 22:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.809
2024-11-02 22:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.193
2024-11-02 22:05 - INFO - 	 Best Recall for 0.4 precision: 0.403
2024-11-02 22:05 - INFO - ---------------------------------------------
2024-11-02 22:07 - INFO - ---------------------------------------------
2024-11-02 22:07 - INFO - Epoch: 07 | Time: 1m 55s
2024-11-02 22:07 - INFO - 	 New best val_rocauc loss was found, current best value is 0.32903
2024-11-02 22:07 - INFO - 	 Train Loss: 0.156
2024-11-02 22:07 - INFO - 	 Val. Loss: 0.163
2024-11-02 22:07 - INFO - 	 ROC-AUC: 0.838
2024-11-02 22:07 - INFO - 	 PR-AUC: 0.329
2024-11-02 22:07 - INFO - 	 Recall for 0.4 precision: 0.377
2024-11-02 22:07 - INFO - 	 Best Val. Loss: 0.163
2024-11-02 22:07 - INFO - 	 Best ROC-AUC: 0.838
2024-11-02 22:07 - INFO - 	 Best PR-AUC: 0.329
2024-11-02 22:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.814
2024-11-02 22:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.163
2024-11-02 22:07 - INFO - 	 Best Recall for 0.4 precision: 0.403
2024-11-02 22:07 - INFO - ---------------------------------------------
2024-11-02 22:09 - INFO - ---------------------------------------------
2024-11-02 22:09 - INFO - Epoch: 08 | Time: 1m 56s
2024-11-02 22:09 - INFO - 	 New best val_rocauc loss was found, current best value is 0.33644
2024-11-02 22:09 - INFO - 	 Train Loss: 0.152
2024-11-02 22:09 - INFO - 	 Val. Loss: 0.168
2024-11-02 22:09 - INFO - 	 ROC-AUC: 0.834
2024-11-02 22:09 - INFO - 	 PR-AUC: 0.336
2024-11-02 22:09 - INFO - 	 Recall for 0.4 precision: 0.436
2024-11-02 22:09 - INFO - 	 Best Val. Loss: 0.163
2024-11-02 22:09 - INFO - 	 Best ROC-AUC: 0.838
2024-11-02 22:09 - INFO - 	 Best PR-AUC: 0.336
2024-11-02 22:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.814
2024-11-02 22:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.156
2024-11-02 22:09 - INFO - 	 Best Recall for 0.4 precision: 0.436
2024-11-02 22:09 - INFO - ---------------------------------------------
2024-11-02 22:11 - INFO - ---------------------------------------------
2024-11-02 22:11 - INFO - Epoch: 09 | Time: 1m 57s
2024-11-02 22:11 - INFO - 	 Train Loss: 0.149
2024-11-02 22:11 - INFO - 	 Val. Loss: 0.164
2024-11-02 22:11 - INFO - 	 ROC-AUC: 0.829
2024-11-02 22:11 - INFO - 	 PR-AUC: 0.293
2024-11-02 22:11 - INFO - 	 Recall for 0.4 precision: 0.228
2024-11-02 22:11 - INFO - 	 Best Val. Loss: 0.163
2024-11-02 22:11 - INFO - 	 Best ROC-AUC: 0.838
2024-11-02 22:11 - INFO - 	 Best PR-AUC: 0.336
2024-11-02 22:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.814
2024-11-02 22:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.156
2024-11-02 22:11 - INFO - 	 Best Recall for 0.4 precision: 0.436
2024-11-02 22:11 - INFO - ---------------------------------------------
2024-11-02 22:13 - INFO - ---------------------------------------------
2024-11-02 22:13 - INFO - Epoch: 10 | Time: 1m 59s
2024-11-02 22:13 - INFO - 	 Train Loss: 0.148
2024-11-02 22:13 - INFO - 	 Val. Loss: 0.160
2024-11-02 22:13 - INFO - 	 ROC-AUC: 0.843
2024-11-02 22:13 - INFO - 	 PR-AUC: 0.307
2024-11-02 22:13 - INFO - 	 Recall for 0.4 precision: 0.286
2024-11-02 22:13 - INFO - 	 Best Val. Loss: 0.160
2024-11-02 22:13 - INFO - 	 Best ROC-AUC: 0.843
2024-11-02 22:13 - INFO - 	 Best PR-AUC: 0.336
2024-11-02 22:13 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.805
2024-11-02 22:13 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.156
2024-11-02 22:13 - INFO - 	 Best Recall for 0.4 precision: 0.436
2024-11-02 22:13 - INFO - ---------------------------------------------
2024-11-02 22:16 - INFO - Fit the preprocessing pipeline
2024-11-02 22:16 - INFO - Training using device: mps
2024-11-02 22:16 - INFO - Creating generators
2024-11-02 22:16 - INFO - The model has 651,257 trainable parameters
2024-11-02 22:16 - INFO - * Model:
2024-11-02 22:16 - INFO - * -----------
2024-11-02 22:16 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 22:16 - INFO - * -----------
2024-11-02 22:16 - INFO - Evaluating model based on: aucpr
2024-11-02 22:16 - INFO - Training..

2024-11-02 22:18 - INFO - ---------------------------------------------
2024-11-02 22:18 - INFO - Epoch: 01 | Time: 1m 58s
2024-11-02 22:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.18423
2024-11-02 22:18 - INFO - 	 Train Loss: 0.260
2024-11-02 22:18 - INFO - 	 Val. Loss: 0.299
2024-11-02 22:18 - INFO - 	 ROC-AUC: 0.752
2024-11-02 22:18 - INFO - 	 PR-AUC: 0.184
2024-11-02 22:18 - INFO - 	 Recall for 0.4 precision: 0.146
2024-11-02 22:18 - INFO - 	 Best Val. Loss: 0.299
2024-11-02 22:18 - INFO - 	 Best ROC-AUC: 0.752
2024-11-02 22:18 - INFO - 	 Best PR-AUC: 0.184
2024-11-02 22:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.731
2024-11-02 22:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.121
2024-11-02 22:18 - INFO - 	 Best Recall for 0.4 precision: 0.146
2024-11-02 22:18 - INFO - ---------------------------------------------
2024-11-02 22:20 - INFO - ---------------------------------------------
2024-11-02 22:20 - INFO - Epoch: 02 | Time: 2m 14s
2024-11-02 22:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.23334
2024-11-02 22:20 - INFO - 	 Train Loss: 0.214
2024-11-02 22:20 - INFO - 	 Val. Loss: 0.246
2024-11-02 22:20 - INFO - 	 ROC-AUC: 0.774
2024-11-02 22:20 - INFO - 	 PR-AUC: 0.233
2024-11-02 22:20 - INFO - 	 Recall for 0.4 precision: 0.085
2024-11-02 22:20 - INFO - 	 Best Val. Loss: 0.246
2024-11-02 22:20 - INFO - 	 Best ROC-AUC: 0.774
2024-11-02 22:20 - INFO - 	 Best PR-AUC: 0.233
2024-11-02 22:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.769
2024-11-02 22:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-02 22:20 - INFO - 	 Best Recall for 0.4 precision: 0.146
2024-11-02 22:20 - INFO - ---------------------------------------------
2024-11-02 22:22 - INFO - ---------------------------------------------
2024-11-02 22:22 - INFO - Epoch: 03 | Time: 2m 16s
2024-11-02 22:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.27503
2024-11-02 22:22 - INFO - 	 Train Loss: 0.191
2024-11-02 22:22 - INFO - 	 Val. Loss: 0.212
2024-11-02 22:22 - INFO - 	 ROC-AUC: 0.823
2024-11-02 22:22 - INFO - 	 PR-AUC: 0.275
2024-11-02 22:22 - INFO - 	 Recall for 0.4 precision: 0.211
2024-11-02 22:22 - INFO - 	 Best Val. Loss: 0.212
2024-11-02 22:22 - INFO - 	 Best ROC-AUC: 0.823
2024-11-02 22:22 - INFO - 	 Best PR-AUC: 0.275
2024-11-02 22:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.807
2024-11-02 22:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.138
2024-11-02 22:22 - INFO - 	 Best Recall for 0.4 precision: 0.211
2024-11-02 22:22 - INFO - ---------------------------------------------
2024-11-02 22:25 - INFO - ---------------------------------------------
2024-11-02 22:25 - INFO - Epoch: 04 | Time: 2m 23s
2024-11-02 22:25 - INFO - 	 Train Loss: 0.175
2024-11-02 22:25 - INFO - 	 Val. Loss: 0.210
2024-11-02 22:25 - INFO - 	 ROC-AUC: 0.799
2024-11-02 22:25 - INFO - 	 PR-AUC: 0.249
2024-11-02 22:25 - INFO - 	 Recall for 0.4 precision: 0.374
2024-11-02 22:25 - INFO - 	 Best Val. Loss: 0.210
2024-11-02 22:25 - INFO - 	 Best ROC-AUC: 0.823
2024-11-02 22:25 - INFO - 	 Best PR-AUC: 0.275
2024-11-02 22:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.807
2024-11-02 22:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.138
2024-11-02 22:25 - INFO - 	 Best Recall for 0.4 precision: 0.374
2024-11-02 22:25 - INFO - ---------------------------------------------
2024-11-02 22:28 - INFO - ---------------------------------------------
2024-11-02 22:28 - INFO - Epoch: 05 | Time: 3m 42s
2024-11-02 22:28 - INFO - 	 Train Loss: 0.167
2024-11-02 22:28 - INFO - 	 Val. Loss: 0.186
2024-11-02 22:28 - INFO - 	 ROC-AUC: 0.824
2024-11-02 22:28 - INFO - 	 PR-AUC: 0.208
2024-11-02 22:28 - INFO - 	 Recall for 0.4 precision: 0.039
2024-11-02 22:28 - INFO - 	 Best Val. Loss: 0.186
2024-11-02 22:28 - INFO - 	 Best ROC-AUC: 0.824
2024-11-02 22:28 - INFO - 	 Best PR-AUC: 0.275
2024-11-02 22:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.786
2024-11-02 22:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.138
2024-11-02 22:28 - INFO - 	 Best Recall for 0.4 precision: 0.374
2024-11-02 22:28 - INFO - ---------------------------------------------
2024-11-02 22:48 - INFO - ---------------------------------------------
2024-11-02 22:48 - INFO - Epoch: 06 | Time: 19m 21s
2024-11-02 22:48 - INFO - 	 Train Loss: 0.156
2024-11-02 22:48 - INFO - 	 Val. Loss: 0.174
2024-11-02 22:48 - INFO - 	 ROC-AUC: 0.858
2024-11-02 22:48 - INFO - 	 PR-AUC: 0.236
2024-11-02 22:48 - INFO - 	 Recall for 0.4 precision: 0.023
2024-11-02 22:48 - INFO - 	 Best Val. Loss: 0.174
2024-11-02 22:48 - INFO - 	 Best ROC-AUC: 0.858
2024-11-02 22:48 - INFO - 	 Best PR-AUC: 0.275
2024-11-02 22:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.766
2024-11-02 22:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.138
2024-11-02 22:48 - INFO - 	 Best Recall for 0.4 precision: 0.374
2024-11-02 22:48 - INFO - ---------------------------------------------
2024-11-02 22:54 - INFO - Fit the preprocessing pipeline
2024-11-02 22:54 - INFO - Training using device: mps
2024-11-02 22:54 - INFO - Creating generators
2024-11-02 22:54 - INFO - The model has 651,257 trainable parameters
2024-11-02 22:54 - INFO - * Model:
2024-11-02 22:54 - INFO - * -----------
2024-11-02 22:54 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 22:54 - INFO - * -----------
2024-11-02 22:54 - INFO - Evaluating model based on: aucpr
2024-11-02 22:54 - INFO - Training..

2024-11-02 22:56 - INFO - ---------------------------------------------
2024-11-02 22:56 - INFO - Epoch: 01 | Time: 1m 44s
2024-11-02 22:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.14417
2024-11-02 22:56 - INFO - 	 Train Loss: 0.259
2024-11-02 22:56 - INFO - 	 Val. Loss: 0.305
2024-11-02 22:56 - INFO - 	 ROC-AUC: 0.744
2024-11-02 22:56 - INFO - 	 PR-AUC: 0.144
2024-11-02 22:56 - INFO - 	 Recall for 0.4 precision: 0.091
2024-11-02 22:56 - INFO - 	 Best Val. Loss: 0.305
2024-11-02 22:56 - INFO - 	 Best ROC-AUC: 0.744
2024-11-02 22:56 - INFO - 	 Best PR-AUC: 0.144
2024-11-02 22:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.667
2024-11-02 22:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.074
2024-11-02 22:56 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-02 22:56 - INFO - ---------------------------------------------
2024-11-02 22:58 - INFO - ---------------------------------------------
2024-11-02 22:58 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-02 22:58 - INFO - 	 Train Loss: 0.214
2024-11-02 22:58 - INFO - 	 Val. Loss: 0.319
2024-11-02 22:58 - INFO - 	 ROC-AUC: 0.736
2024-11-02 22:58 - INFO - 	 PR-AUC: 0.123
2024-11-02 22:58 - INFO - 	 Recall for 0.4 precision: 0.026
2024-11-02 22:58 - INFO - 	 Best Val. Loss: 0.305
2024-11-02 22:58 - INFO - 	 Best ROC-AUC: 0.744
2024-11-02 22:58 - INFO - 	 Best PR-AUC: 0.144
2024-11-02 22:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.667
2024-11-02 22:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.074
2024-11-02 22:58 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-02 22:58 - INFO - ---------------------------------------------
2024-11-02 22:59 - INFO - ---------------------------------------------
2024-11-02 22:59 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-02 22:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.17498
2024-11-02 22:59 - INFO - 	 Train Loss: 0.198
2024-11-02 22:59 - INFO - 	 Val. Loss: 0.262
2024-11-02 22:59 - INFO - 	 ROC-AUC: 0.769
2024-11-02 22:59 - INFO - 	 PR-AUC: 0.175
2024-11-02 22:59 - INFO - 	 Recall for 0.4 precision: 0.068
2024-11-02 22:59 - INFO - 	 Best Val. Loss: 0.262
2024-11-02 22:59 - INFO - 	 Best ROC-AUC: 0.769
2024-11-02 22:59 - INFO - 	 Best PR-AUC: 0.175
2024-11-02 22:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.808
2024-11-02 22:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.211
2024-11-02 22:59 - INFO - 	 Best Recall for 0.4 precision: 0.091
2024-11-02 22:59 - INFO - ---------------------------------------------
2024-11-02 23:01 - INFO - ---------------------------------------------
2024-11-02 23:01 - INFO - Epoch: 04 | Time: 1m 43s
2024-11-02 23:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31391
2024-11-02 23:01 - INFO - 	 Train Loss: 0.180
2024-11-02 23:01 - INFO - 	 Val. Loss: 0.206
2024-11-02 23:01 - INFO - 	 ROC-AUC: 0.803
2024-11-02 23:01 - INFO - 	 PR-AUC: 0.314
2024-11-02 23:01 - INFO - 	 Recall for 0.4 precision: 0.351
2024-11-02 23:01 - INFO - 	 Best Val. Loss: 0.206
2024-11-02 23:01 - INFO - 	 Best ROC-AUC: 0.803
2024-11-02 23:01 - INFO - 	 Best PR-AUC: 0.314
2024-11-02 23:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.790
2024-11-02 23:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.183
2024-11-02 23:01 - INFO - 	 Best Recall for 0.4 precision: 0.351
2024-11-02 23:01 - INFO - ---------------------------------------------
2024-11-02 23:03 - INFO - ---------------------------------------------
2024-11-02 23:03 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-02 23:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31992
2024-11-02 23:03 - INFO - 	 Train Loss: 0.169
2024-11-02 23:03 - INFO - 	 Val. Loss: 0.185
2024-11-02 23:03 - INFO - 	 ROC-AUC: 0.808
2024-11-02 23:03 - INFO - 	 PR-AUC: 0.320
2024-11-02 23:03 - INFO - 	 Recall for 0.4 precision: 0.472
2024-11-02 23:03 - INFO - 	 Best Val. Loss: 0.185
2024-11-02 23:03 - INFO - 	 Best ROC-AUC: 0.808
2024-11-02 23:03 - INFO - 	 Best PR-AUC: 0.320
2024-11-02 23:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.799
2024-11-02 23:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-02 23:03 - INFO - 	 Best Recall for 0.4 precision: 0.472
2024-11-02 23:03 - INFO - ---------------------------------------------
2024-11-02 23:05 - INFO - ---------------------------------------------
2024-11-02 23:05 - INFO - Epoch: 06 | Time: 1m 43s
2024-11-02 23:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.34161
2024-11-02 23:05 - INFO - 	 Train Loss: 0.162
2024-11-02 23:05 - INFO - 	 Val. Loss: 0.185
2024-11-02 23:05 - INFO - 	 ROC-AUC: 0.813
2024-11-02 23:05 - INFO - 	 PR-AUC: 0.342
2024-11-02 23:05 - INFO - 	 Recall for 0.4 precision: 0.429
2024-11-02 23:05 - INFO - 	 Best Val. Loss: 0.185
2024-11-02 23:05 - INFO - 	 Best ROC-AUC: 0.813
2024-11-02 23:05 - INFO - 	 Best PR-AUC: 0.342
2024-11-02 23:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.790
2024-11-02 23:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.164
2024-11-02 23:05 - INFO - 	 Best Recall for 0.4 precision: 0.472
2024-11-02 23:05 - INFO - ---------------------------------------------
2024-11-02 23:06 - INFO - ---------------------------------------------
2024-11-02 23:06 - INFO - Epoch: 07 | Time: 1m 44s
2024-11-02 23:06 - INFO - 	 Train Loss: 0.156
2024-11-02 23:06 - INFO - 	 Val. Loss: 0.168
2024-11-02 23:06 - INFO - 	 ROC-AUC: 0.821
2024-11-02 23:06 - INFO - 	 PR-AUC: 0.337
2024-11-02 23:06 - INFO - 	 Recall for 0.4 precision: 0.390
2024-11-02 23:06 - INFO - 	 Best Val. Loss: 0.168
2024-11-02 23:06 - INFO - 	 Best ROC-AUC: 0.821
2024-11-02 23:06 - INFO - 	 Best PR-AUC: 0.342
2024-11-02 23:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.775
2024-11-02 23:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.164
2024-11-02 23:06 - INFO - 	 Best Recall for 0.4 precision: 0.472
2024-11-02 23:06 - INFO - ---------------------------------------------
2024-11-02 23:08 - INFO - ---------------------------------------------
2024-11-02 23:08 - INFO - Epoch: 08 | Time: 1m 43s
2024-11-02 23:08 - INFO - 	 Train Loss: 0.151
2024-11-02 23:08 - INFO - 	 Val. Loss: 0.172
2024-11-02 23:08 - INFO - 	 ROC-AUC: 0.821
2024-11-02 23:08 - INFO - 	 PR-AUC: 0.325
2024-11-02 23:08 - INFO - 	 Recall for 0.4 precision: 0.016
2024-11-02 23:08 - INFO - 	 Best Val. Loss: 0.168
2024-11-02 23:08 - INFO - 	 Best ROC-AUC: 0.821
2024-11-02 23:08 - INFO - 	 Best PR-AUC: 0.342
2024-11-02 23:08 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.766
2024-11-02 23:08 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.164
2024-11-02 23:08 - INFO - 	 Best Recall for 0.4 precision: 0.472
2024-11-02 23:08 - INFO - ---------------------------------------------
2024-11-02 23:10 - INFO - ---------------------------------------------
2024-11-02 23:10 - INFO - Epoch: 09 | Time: 2m 27s
2024-11-02 23:10 - INFO - 	 Train Loss: 0.147
2024-11-02 23:10 - INFO - 	 Val. Loss: 0.174
2024-11-02 23:10 - INFO - 	 ROC-AUC: 0.833
2024-11-02 23:10 - INFO - 	 PR-AUC: 0.328
2024-11-02 23:10 - INFO - 	 Recall for 0.4 precision: 0.299
2024-11-02 23:10 - INFO - 	 Best Val. Loss: 0.168
2024-11-02 23:10 - INFO - 	 Best ROC-AUC: 0.833
2024-11-02 23:10 - INFO - 	 Best PR-AUC: 0.342
2024-11-02 23:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.766
2024-11-02 23:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.164
2024-11-02 23:10 - INFO - 	 Best Recall for 0.4 precision: 0.472
2024-11-02 23:10 - INFO - ---------------------------------------------
2024-11-02 23:15 - INFO - Fit the preprocessing pipeline
2024-11-02 23:15 - INFO - Training using device: mps
2024-11-02 23:15 - INFO - Creating generators
2024-11-02 23:15 - INFO - The model has 651,257 trainable parameters
2024-11-02 23:15 - INFO - * Model:
2024-11-02 23:15 - INFO - * -----------
2024-11-02 23:15 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 23:15 - INFO - * -----------
2024-11-02 23:15 - INFO - Evaluating model based on: aucpr
2024-11-02 23:15 - INFO - Training..

2024-11-02 23:17 - INFO - ---------------------------------------------
2024-11-02 23:17 - INFO - Epoch: 01 | Time: 1m 42s
2024-11-02 23:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.15532
2024-11-02 23:17 - INFO - 	 Train Loss: 0.258
2024-11-02 23:17 - INFO - 	 Val. Loss: 0.306
2024-11-02 23:17 - INFO - 	 ROC-AUC: 0.750
2024-11-02 23:17 - INFO - 	 PR-AUC: 0.155
2024-11-02 23:17 - INFO - 	 Recall for 0.4 precision: 0.182
2024-11-02 23:17 - INFO - 	 Best Val. Loss: 0.306
2024-11-02 23:17 - INFO - 	 Best ROC-AUC: 0.750
2024-11-02 23:17 - INFO - 	 Best PR-AUC: 0.155
2024-11-02 23:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.679
2024-11-02 23:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.137
2024-11-02 23:17 - INFO - 	 Best Recall for 0.4 precision: 0.182
2024-11-02 23:17 - INFO - ---------------------------------------------
2024-11-02 23:19 - INFO - ---------------------------------------------
2024-11-02 23:19 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-02 23:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.25363
2024-11-02 23:19 - INFO - 	 Train Loss: 0.214
2024-11-02 23:19 - INFO - 	 Val. Loss: 0.223
2024-11-02 23:19 - INFO - 	 ROC-AUC: 0.788
2024-11-02 23:19 - INFO - 	 PR-AUC: 0.254
2024-11-02 23:19 - INFO - 	 Recall for 0.4 precision: 0.244
2024-11-02 23:19 - INFO - 	 Best Val. Loss: 0.223
2024-11-02 23:19 - INFO - 	 Best ROC-AUC: 0.788
2024-11-02 23:19 - INFO - 	 Best PR-AUC: 0.254
2024-11-02 23:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.750
2024-11-02 23:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.153
2024-11-02 23:19 - INFO - 	 Best Recall for 0.4 precision: 0.244
2024-11-02 23:19 - INFO - ---------------------------------------------
2024-11-02 23:20 - INFO - ---------------------------------------------
2024-11-02 23:20 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-02 23:20 - INFO - 	 Train Loss: 0.189
2024-11-02 23:20 - INFO - 	 Val. Loss: 0.213
2024-11-02 23:20 - INFO - 	 ROC-AUC: 0.785
2024-11-02 23:20 - INFO - 	 PR-AUC: 0.205
2024-11-02 23:20 - INFO - 	 Recall for 0.4 precision: 0.127
2024-11-02 23:20 - INFO - 	 Best Val. Loss: 0.213
2024-11-02 23:20 - INFO - 	 Best ROC-AUC: 0.788
2024-11-02 23:20 - INFO - 	 Best PR-AUC: 0.254
2024-11-02 23:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.750
2024-11-02 23:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.153
2024-11-02 23:20 - INFO - 	 Best Recall for 0.4 precision: 0.244
2024-11-02 23:20 - INFO - ---------------------------------------------
2024-11-02 23:22 - INFO - ---------------------------------------------
2024-11-02 23:22 - INFO - Epoch: 04 | Time: 1m 46s
2024-11-02 23:22 - INFO - 	 Train Loss: 0.174
2024-11-02 23:22 - INFO - 	 Val. Loss: 0.202
2024-11-02 23:22 - INFO - 	 ROC-AUC: 0.804
2024-11-02 23:22 - INFO - 	 PR-AUC: 0.254
2024-11-02 23:22 - INFO - 	 Recall for 0.4 precision: 0.211
2024-11-02 23:22 - INFO - 	 Best Val. Loss: 0.202
2024-11-02 23:22 - INFO - 	 Best ROC-AUC: 0.804
2024-11-02 23:22 - INFO - 	 Best PR-AUC: 0.254
2024-11-02 23:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-02 23:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.153
2024-11-02 23:22 - INFO - 	 Best Recall for 0.4 precision: 0.244
2024-11-02 23:22 - INFO - ---------------------------------------------
2024-11-02 23:24 - INFO - ---------------------------------------------
2024-11-02 23:24 - INFO - Epoch: 05 | Time: 1m 52s
2024-11-02 23:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.28001
2024-11-02 23:24 - INFO - 	 Train Loss: 0.164
2024-11-02 23:24 - INFO - 	 Val. Loss: 0.186
2024-11-02 23:24 - INFO - 	 ROC-AUC: 0.800
2024-11-02 23:24 - INFO - 	 PR-AUC: 0.280
2024-11-02 23:24 - INFO - 	 Recall for 0.4 precision: 0.193
2024-11-02 23:24 - INFO - 	 Best Val. Loss: 0.186
2024-11-02 23:24 - INFO - 	 Best ROC-AUC: 0.804
2024-11-02 23:24 - INFO - 	 Best PR-AUC: 0.280
2024-11-02 23:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-02 23:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.171
2024-11-02 23:24 - INFO - 	 Best Recall for 0.4 precision: 0.244
2024-11-02 23:24 - INFO - ---------------------------------------------
2024-11-02 23:26 - INFO - ---------------------------------------------
2024-11-02 23:26 - INFO - Epoch: 06 | Time: 1m 57s
2024-11-02 23:26 - INFO - 	 Train Loss: 0.156
2024-11-02 23:26 - INFO - 	 Val. Loss: 0.187
2024-11-02 23:26 - INFO - 	 ROC-AUC: 0.799
2024-11-02 23:26 - INFO - 	 PR-AUC: 0.258
2024-11-02 23:26 - INFO - 	 Recall for 0.4 precision: 0.176
2024-11-02 23:26 - INFO - 	 Best Val. Loss: 0.186
2024-11-02 23:26 - INFO - 	 Best ROC-AUC: 0.804
2024-11-02 23:26 - INFO - 	 Best PR-AUC: 0.280
2024-11-02 23:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-02 23:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.171
2024-11-02 23:26 - INFO - 	 Best Recall for 0.4 precision: 0.244
2024-11-02 23:26 - INFO - ---------------------------------------------
2024-11-02 23:28 - INFO - ---------------------------------------------
2024-11-02 23:28 - INFO - Epoch: 07 | Time: 1m 59s
2024-11-02 23:28 - INFO - 	 New best val_rocauc loss was found, current best value is 0.33004
2024-11-02 23:28 - INFO - 	 Train Loss: 0.151
2024-11-02 23:28 - INFO - 	 Val. Loss: 0.183
2024-11-02 23:28 - INFO - 	 ROC-AUC: 0.831
2024-11-02 23:28 - INFO - 	 PR-AUC: 0.330
2024-11-02 23:28 - INFO - 	 Recall for 0.4 precision: 0.301
2024-11-02 23:28 - INFO - 	 Best Val. Loss: 0.183
2024-11-02 23:28 - INFO - 	 Best ROC-AUC: 0.831
2024-11-02 23:28 - INFO - 	 Best PR-AUC: 0.330
2024-11-02 23:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.798
2024-11-02 23:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-02 23:28 - INFO - 	 Best Recall for 0.4 precision: 0.301
2024-11-02 23:28 - INFO - ---------------------------------------------
2024-11-02 23:30 - INFO - ---------------------------------------------
2024-11-02 23:30 - INFO - Epoch: 08 | Time: 1m 57s
2024-11-02 23:30 - INFO - 	 Train Loss: 0.149
2024-11-02 23:30 - INFO - 	 Val. Loss: 0.182
2024-11-02 23:30 - INFO - 	 ROC-AUC: 0.841
2024-11-02 23:30 - INFO - 	 PR-AUC: 0.303
2024-11-02 23:30 - INFO - 	 Recall for 0.4 precision: 0.302
2024-11-02 23:30 - INFO - 	 Best Val. Loss: 0.182
2024-11-02 23:30 - INFO - 	 Best ROC-AUC: 0.841
2024-11-02 23:30 - INFO - 	 Best PR-AUC: 0.330
2024-11-02 23:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.803
2024-11-02 23:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-02 23:30 - INFO - 	 Best Recall for 0.4 precision: 0.302
2024-11-02 23:30 - INFO - ---------------------------------------------
2024-11-02 23:32 - INFO - ---------------------------------------------
2024-11-02 23:32 - INFO - Epoch: 09 | Time: 1m 55s
2024-11-02 23:32 - INFO - 	 Train Loss: 0.147
2024-11-02 23:32 - INFO - 	 Val. Loss: 0.181
2024-11-02 23:32 - INFO - 	 ROC-AUC: 0.848
2024-11-02 23:32 - INFO - 	 PR-AUC: 0.272
2024-11-02 23:32 - INFO - 	 Recall for 0.4 precision: 0.190
2024-11-02 23:32 - INFO - 	 Best Val. Loss: 0.181
2024-11-02 23:32 - INFO - 	 Best ROC-AUC: 0.848
2024-11-02 23:32 - INFO - 	 Best PR-AUC: 0.330
2024-11-02 23:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.786
2024-11-02 23:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-02 23:32 - INFO - 	 Best Recall for 0.4 precision: 0.302
2024-11-02 23:32 - INFO - ---------------------------------------------
2024-11-02 23:34 - INFO - ---------------------------------------------
2024-11-02 23:34 - INFO - Epoch: 10 | Time: 1m 54s
2024-11-02 23:34 - INFO - 	 Train Loss: 0.146
2024-11-02 23:34 - INFO - 	 Val. Loss: 0.179
2024-11-02 23:34 - INFO - 	 ROC-AUC: 0.857
2024-11-02 23:34 - INFO - 	 PR-AUC: 0.246
2024-11-02 23:34 - INFO - 	 Recall for 0.4 precision: 0.117
2024-11-02 23:34 - INFO - 	 Best Val. Loss: 0.179
2024-11-02 23:34 - INFO - 	 Best ROC-AUC: 0.857
2024-11-02 23:34 - INFO - 	 Best PR-AUC: 0.330
2024-11-02 23:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.787
2024-11-02 23:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.161
2024-11-02 23:34 - INFO - 	 Best Recall for 0.4 precision: 0.302
2024-11-02 23:34 - INFO - ---------------------------------------------
2024-11-02 23:36 - INFO - Fit the preprocessing pipeline
2024-11-02 23:36 - INFO - Training using device: mps
2024-11-02 23:36 - INFO - Creating generators
2024-11-02 23:36 - INFO - The model has 651,257 trainable parameters
2024-11-02 23:36 - INFO - * Model:
2024-11-02 23:36 - INFO - * -----------
2024-11-02 23:36 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 23:36 - INFO - * -----------
2024-11-02 23:36 - INFO - Evaluating model based on: aucpr
2024-11-02 23:36 - INFO - Training..

2024-11-02 23:38 - INFO - ---------------------------------------------
2024-11-02 23:38 - INFO - Epoch: 01 | Time: 1m 44s
2024-11-02 23:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.1428
2024-11-02 23:38 - INFO - 	 Train Loss: 0.261
2024-11-02 23:38 - INFO - 	 Val. Loss: 0.301
2024-11-02 23:38 - INFO - 	 ROC-AUC: 0.713
2024-11-02 23:38 - INFO - 	 PR-AUC: 0.143
2024-11-02 23:38 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-02 23:38 - INFO - 	 Best Val. Loss: 0.301
2024-11-02 23:38 - INFO - 	 Best ROC-AUC: 0.713
2024-11-02 23:38 - INFO - 	 Best PR-AUC: 0.143
2024-11-02 23:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.719
2024-11-02 23:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.120
2024-11-02 23:38 - INFO - 	 Best Recall for 0.4 precision: 0.010
2024-11-02 23:38 - INFO - ---------------------------------------------
2024-11-02 23:40 - INFO - ---------------------------------------------
2024-11-02 23:40 - INFO - Epoch: 02 | Time: 2m 0s
2024-11-02 23:40 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30051
2024-11-02 23:40 - INFO - 	 Train Loss: 0.214
2024-11-02 23:40 - INFO - 	 Val. Loss: 0.222
2024-11-02 23:40 - INFO - 	 ROC-AUC: 0.813
2024-11-02 23:40 - INFO - 	 PR-AUC: 0.301
2024-11-02 23:40 - INFO - 	 Recall for 0.4 precision: 0.309
2024-11-02 23:40 - INFO - 	 Best Val. Loss: 0.222
2024-11-02 23:40 - INFO - 	 Best ROC-AUC: 0.813
2024-11-02 23:40 - INFO - 	 Best PR-AUC: 0.301
2024-11-02 23:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.810
2024-11-02 23:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.144
2024-11-02 23:40 - INFO - 	 Best Recall for 0.4 precision: 0.309
2024-11-02 23:40 - INFO - ---------------------------------------------
2024-11-02 23:42 - INFO - ---------------------------------------------
2024-11-02 23:42 - INFO - Epoch: 03 | Time: 1m 51s
2024-11-02 23:42 - INFO - 	 Train Loss: 0.198
2024-11-02 23:42 - INFO - 	 Val. Loss: 0.238
2024-11-02 23:42 - INFO - 	 ROC-AUC: 0.805
2024-11-02 23:42 - INFO - 	 PR-AUC: 0.278
2024-11-02 23:42 - INFO - 	 Recall for 0.4 precision: 0.416
2024-11-02 23:42 - INFO - 	 Best Val. Loss: 0.222
2024-11-02 23:42 - INFO - 	 Best ROC-AUC: 0.813
2024-11-02 23:42 - INFO - 	 Best PR-AUC: 0.301
2024-11-02 23:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.810
2024-11-02 23:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.144
2024-11-02 23:42 - INFO - 	 Best Recall for 0.4 precision: 0.416
2024-11-02 23:42 - INFO - ---------------------------------------------
2024-11-02 23:44 - INFO - ---------------------------------------------
2024-11-02 23:44 - INFO - Epoch: 04 | Time: 1m 50s
2024-11-02 23:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.33662
2024-11-02 23:44 - INFO - 	 Train Loss: 0.174
2024-11-02 23:44 - INFO - 	 Val. Loss: 0.201
2024-11-02 23:44 - INFO - 	 ROC-AUC: 0.818
2024-11-02 23:44 - INFO - 	 PR-AUC: 0.337
2024-11-02 23:44 - INFO - 	 Recall for 0.4 precision: 0.470
2024-11-02 23:44 - INFO - 	 Best Val. Loss: 0.201
2024-11-02 23:44 - INFO - 	 Best ROC-AUC: 0.818
2024-11-02 23:44 - INFO - 	 Best PR-AUC: 0.337
2024-11-02 23:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.797
2024-11-02 23:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.171
2024-11-02 23:44 - INFO - 	 Best Recall for 0.4 precision: 0.470
2024-11-02 23:44 - INFO - ---------------------------------------------
2024-11-02 23:46 - INFO - ---------------------------------------------
2024-11-02 23:46 - INFO - Epoch: 05 | Time: 1m 50s
2024-11-02 23:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.40646
2024-11-02 23:46 - INFO - 	 Train Loss: 0.165
2024-11-02 23:46 - INFO - 	 Val. Loss: 0.178
2024-11-02 23:46 - INFO - 	 ROC-AUC: 0.842
2024-11-02 23:46 - INFO - 	 PR-AUC: 0.406
2024-11-02 23:46 - INFO - 	 Recall for 0.4 precision: 0.522
2024-11-02 23:46 - INFO - 	 Best Val. Loss: 0.178
2024-11-02 23:46 - INFO - 	 Best ROC-AUC: 0.842
2024-11-02 23:46 - INFO - 	 Best PR-AUC: 0.406
2024-11-02 23:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.811
2024-11-02 23:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.196
2024-11-02 23:46 - INFO - 	 Best Recall for 0.4 precision: 0.522
2024-11-02 23:46 - INFO - ---------------------------------------------
2024-11-02 23:48 - INFO - ---------------------------------------------
2024-11-02 23:48 - INFO - Epoch: 06 | Time: 1m 51s
2024-11-02 23:48 - INFO - 	 Train Loss: 0.159
2024-11-02 23:48 - INFO - 	 Val. Loss: 0.172
2024-11-02 23:48 - INFO - 	 ROC-AUC: 0.838
2024-11-02 23:48 - INFO - 	 PR-AUC: 0.403
2024-11-02 23:48 - INFO - 	 Recall for 0.4 precision: 0.556
2024-11-02 23:48 - INFO - 	 Best Val. Loss: 0.172
2024-11-02 23:48 - INFO - 	 Best ROC-AUC: 0.842
2024-11-02 23:48 - INFO - 	 Best PR-AUC: 0.406
2024-11-02 23:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.811
2024-11-02 23:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.196
2024-11-02 23:48 - INFO - 	 Best Recall for 0.4 precision: 0.556
2024-11-02 23:48 - INFO - ---------------------------------------------
2024-11-02 23:49 - INFO - ---------------------------------------------
2024-11-02 23:49 - INFO - Epoch: 07 | Time: 1m 52s
2024-11-02 23:49 - INFO - 	 New best val_rocauc loss was found, current best value is 0.41652
2024-11-02 23:49 - INFO - 	 Train Loss: 0.154
2024-11-02 23:49 - INFO - 	 Val. Loss: 0.156
2024-11-02 23:49 - INFO - 	 ROC-AUC: 0.858
2024-11-02 23:49 - INFO - 	 PR-AUC: 0.417
2024-11-02 23:49 - INFO - 	 Recall for 0.4 precision: 0.579
2024-11-02 23:49 - INFO - 	 Best Val. Loss: 0.156
2024-11-02 23:49 - INFO - 	 Best ROC-AUC: 0.858
2024-11-02 23:49 - INFO - 	 Best PR-AUC: 0.417
2024-11-02 23:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.810
2024-11-02 23:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.194
2024-11-02 23:49 - INFO - 	 Best Recall for 0.4 precision: 0.579
2024-11-02 23:49 - INFO - ---------------------------------------------
2024-11-02 23:51 - INFO - ---------------------------------------------
2024-11-02 23:51 - INFO - Epoch: 08 | Time: 1m 52s
2024-11-02 23:51 - INFO - 	 Train Loss: 0.151
2024-11-02 23:51 - INFO - 	 Val. Loss: 0.157
2024-11-02 23:51 - INFO - 	 ROC-AUC: 0.858
2024-11-02 23:51 - INFO - 	 PR-AUC: 0.411
2024-11-02 23:51 - INFO - 	 Recall for 0.4 precision: 0.572
2024-11-02 23:51 - INFO - 	 Best Val. Loss: 0.156
2024-11-02 23:51 - INFO - 	 Best ROC-AUC: 0.858
2024-11-02 23:51 - INFO - 	 Best PR-AUC: 0.417
2024-11-02 23:51 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.809
2024-11-02 23:51 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.194
2024-11-02 23:51 - INFO - 	 Best Recall for 0.4 precision: 0.579
2024-11-02 23:51 - INFO - ---------------------------------------------
2024-11-02 23:53 - INFO - ---------------------------------------------
2024-11-02 23:53 - INFO - Epoch: 09 | Time: 1m 51s
2024-11-02 23:53 - INFO - 	 Train Loss: 0.150
2024-11-02 23:53 - INFO - 	 Val. Loss: 0.154
2024-11-02 23:53 - INFO - 	 ROC-AUC: 0.862
2024-11-02 23:53 - INFO - 	 PR-AUC: 0.362
2024-11-02 23:53 - INFO - 	 Recall for 0.4 precision: 0.016
2024-11-02 23:53 - INFO - 	 Best Val. Loss: 0.154
2024-11-02 23:53 - INFO - 	 Best ROC-AUC: 0.862
2024-11-02 23:53 - INFO - 	 Best PR-AUC: 0.417
2024-11-02 23:53 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.794
2024-11-02 23:53 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.194
2024-11-02 23:53 - INFO - 	 Best Recall for 0.4 precision: 0.579
2024-11-02 23:53 - INFO - ---------------------------------------------
2024-11-02 23:55 - INFO - ---------------------------------------------
2024-11-02 23:55 - INFO - Epoch: 10 | Time: 1m 51s
2024-11-02 23:55 - INFO - 	 Train Loss: 0.148
2024-11-02 23:55 - INFO - 	 Val. Loss: 0.173
2024-11-02 23:55 - INFO - 	 ROC-AUC: 0.792
2024-11-02 23:55 - INFO - 	 PR-AUC: 0.283
2024-11-02 23:55 - INFO - 	 Recall for 0.4 precision: 0.273
2024-11-02 23:55 - INFO - 	 Best Val. Loss: 0.154
2024-11-02 23:55 - INFO - 	 Best ROC-AUC: 0.862
2024-11-02 23:55 - INFO - 	 Best PR-AUC: 0.417
2024-11-02 23:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.794
2024-11-02 23:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.194
2024-11-02 23:55 - INFO - 	 Best Recall for 0.4 precision: 0.579
2024-11-02 23:55 - INFO - ---------------------------------------------
2024-11-02 23:58 - INFO - Fit the preprocessing pipeline
2024-11-02 23:58 - INFO - Training using device: mps
2024-11-02 23:58 - INFO - Creating generators
2024-11-02 23:58 - INFO - The model has 651,257 trainable parameters
2024-11-02 23:58 - INFO - * Model:
2024-11-02 23:58 - INFO - * -----------
2024-11-02 23:58 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-02 23:58 - INFO - * -----------
2024-11-02 23:58 - INFO - Evaluating model based on: aucpr
2024-11-02 23:58 - INFO - Training..

2024-11-02 23:59 - INFO - ---------------------------------------------
2024-11-02 23:59 - INFO - Epoch: 01 | Time: 1m 42s
2024-11-02 23:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.32585
2024-11-02 23:59 - INFO - 	 Train Loss: 0.263
2024-11-02 23:59 - INFO - 	 Val. Loss: 0.268
2024-11-02 23:59 - INFO - 	 ROC-AUC: 0.778
2024-11-02 23:59 - INFO - 	 PR-AUC: 0.326
2024-11-02 23:59 - INFO - 	 Recall for 0.4 precision: 0.371
2024-11-02 23:59 - INFO - 	 Best Val. Loss: 0.268
2024-11-02 23:59 - INFO - 	 Best ROC-AUC: 0.778
2024-11-02 23:59 - INFO - 	 Best PR-AUC: 0.326
2024-11-02 23:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.761
2024-11-02 23:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-02 23:59 - INFO - 	 Best Recall for 0.4 precision: 0.371
2024-11-02 23:59 - INFO - ---------------------------------------------
2024-11-03 00:01 - INFO - ---------------------------------------------
2024-11-03 00:01 - INFO - Epoch: 02 | Time: 1m 50s
2024-11-03 00:01 - INFO - 	 Train Loss: 0.208
2024-11-03 00:01 - INFO - 	 Val. Loss: 0.222
2024-11-03 00:01 - INFO - 	 ROC-AUC: 0.792
2024-11-03 00:01 - INFO - 	 PR-AUC: 0.298
2024-11-03 00:01 - INFO - 	 Recall for 0.4 precision: 0.423
2024-11-03 00:01 - INFO - 	 Best Val. Loss: 0.222
2024-11-03 00:01 - INFO - 	 Best ROC-AUC: 0.792
2024-11-03 00:01 - INFO - 	 Best PR-AUC: 0.326
2024-11-03 00:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.775
2024-11-03 00:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-03 00:01 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:01 - INFO - ---------------------------------------------
2024-11-03 00:03 - INFO - ---------------------------------------------
2024-11-03 00:03 - INFO - Epoch: 03 | Time: 1m 50s
2024-11-03 00:03 - INFO - 	 Train Loss: 0.186
2024-11-03 00:03 - INFO - 	 Val. Loss: 0.189
2024-11-03 00:03 - INFO - 	 ROC-AUC: 0.802
2024-11-03 00:03 - INFO - 	 PR-AUC: 0.293
2024-11-03 00:03 - INFO - 	 Recall for 0.4 precision: 0.384
2024-11-03 00:03 - INFO - 	 Best Val. Loss: 0.189
2024-11-03 00:03 - INFO - 	 Best ROC-AUC: 0.802
2024-11-03 00:03 - INFO - 	 Best PR-AUC: 0.326
2024-11-03 00:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.754
2024-11-03 00:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-03 00:03 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:03 - INFO - ---------------------------------------------
2024-11-03 00:05 - INFO - ---------------------------------------------
2024-11-03 00:05 - INFO - Epoch: 04 | Time: 1m 51s
2024-11-03 00:05 - INFO - 	 New best val_rocauc loss was found, current best value is 0.36107
2024-11-03 00:05 - INFO - 	 Train Loss: 0.171
2024-11-03 00:05 - INFO - 	 Val. Loss: 0.194
2024-11-03 00:05 - INFO - 	 ROC-AUC: 0.805
2024-11-03 00:05 - INFO - 	 PR-AUC: 0.361
2024-11-03 00:05 - INFO - 	 Recall for 0.4 precision: 0.372
2024-11-03 00:05 - INFO - 	 Best Val. Loss: 0.189
2024-11-03 00:05 - INFO - 	 Best ROC-AUC: 0.805
2024-11-03 00:05 - INFO - 	 Best PR-AUC: 0.361
2024-11-03 00:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.744
2024-11-03 00:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.124
2024-11-03 00:05 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:05 - INFO - ---------------------------------------------
2024-11-03 00:07 - INFO - ---------------------------------------------
2024-11-03 00:07 - INFO - Epoch: 05 | Time: 1m 53s
2024-11-03 00:07 - INFO - 	 Train Loss: 0.161
2024-11-03 00:07 - INFO - 	 Val. Loss: 0.181
2024-11-03 00:07 - INFO - 	 ROC-AUC: 0.817
2024-11-03 00:07 - INFO - 	 PR-AUC: 0.346
2024-11-03 00:07 - INFO - 	 Recall for 0.4 precision: 0.389
2024-11-03 00:07 - INFO - 	 Best Val. Loss: 0.181
2024-11-03 00:07 - INFO - 	 Best ROC-AUC: 0.817
2024-11-03 00:07 - INFO - 	 Best PR-AUC: 0.361
2024-11-03 00:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.766
2024-11-03 00:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.124
2024-11-03 00:07 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:07 - INFO - ---------------------------------------------
2024-11-03 00:09 - INFO - ---------------------------------------------
2024-11-03 00:09 - INFO - Epoch: 06 | Time: 1m 53s
2024-11-03 00:09 - INFO - 	 Train Loss: 0.153
2024-11-03 00:09 - INFO - 	 Val. Loss: 0.156
2024-11-03 00:09 - INFO - 	 ROC-AUC: 0.853
2024-11-03 00:09 - INFO - 	 PR-AUC: 0.318
2024-11-03 00:09 - INFO - 	 Recall for 0.4 precision: 0.340
2024-11-03 00:09 - INFO - 	 Best Val. Loss: 0.156
2024-11-03 00:09 - INFO - 	 Best ROC-AUC: 0.853
2024-11-03 00:09 - INFO - 	 Best PR-AUC: 0.361
2024-11-03 00:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.789
2024-11-03 00:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.124
2024-11-03 00:09 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:09 - INFO - ---------------------------------------------
2024-11-03 00:11 - INFO - ---------------------------------------------
2024-11-03 00:11 - INFO - Epoch: 07 | Time: 1m 54s
2024-11-03 00:11 - INFO - 	 Train Loss: 0.148
2024-11-03 00:11 - INFO - 	 Val. Loss: 0.147
2024-11-03 00:11 - INFO - 	 ROC-AUC: 0.871
2024-11-03 00:11 - INFO - 	 PR-AUC: 0.286
2024-11-03 00:11 - INFO - 	 Recall for 0.4 precision: 0.221
2024-11-03 00:11 - INFO - 	 Best Val. Loss: 0.147
2024-11-03 00:11 - INFO - 	 Best ROC-AUC: 0.871
2024-11-03 00:11 - INFO - 	 Best PR-AUC: 0.361
2024-11-03 00:11 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.790
2024-11-03 00:11 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.124
2024-11-03 00:11 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 00:11 - INFO - ---------------------------------------------
2024-11-03 00:15 - INFO - Fit the preprocessing pipeline
2024-11-03 00:15 - INFO - Training using device: mps
2024-11-03 00:15 - INFO - Creating generators
2024-11-03 00:15 - INFO - The model has 651,257 trainable parameters
2024-11-03 00:15 - INFO - * Model:
2024-11-03 00:15 - INFO - * -----------
2024-11-03 00:15 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 00:15 - INFO - * -----------
2024-11-03 00:15 - INFO - Evaluating model based on: aucpr
2024-11-03 00:15 - INFO - Training..

2024-11-03 00:17 - INFO - ---------------------------------------------
2024-11-03 00:17 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-03 00:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.15825
2024-11-03 00:17 - INFO - 	 Train Loss: 0.265
2024-11-03 00:17 - INFO - 	 Val. Loss: 0.303
2024-11-03 00:17 - INFO - 	 ROC-AUC: 0.732
2024-11-03 00:17 - INFO - 	 PR-AUC: 0.158
2024-11-03 00:17 - INFO - 	 Recall for 0.4 precision: 0.055
2024-11-03 00:17 - INFO - 	 Best Val. Loss: 0.303
2024-11-03 00:17 - INFO - 	 Best ROC-AUC: 0.732
2024-11-03 00:17 - INFO - 	 Best PR-AUC: 0.158
2024-11-03 00:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.637
2024-11-03 00:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.101
2024-11-03 00:17 - INFO - 	 Best Recall for 0.4 precision: 0.055
2024-11-03 00:17 - INFO - ---------------------------------------------
2024-11-03 00:19 - INFO - ---------------------------------------------
2024-11-03 00:19 - INFO - Epoch: 02 | Time: 1m 43s
2024-11-03 00:19 - INFO - 	 Train Loss: 0.212
2024-11-03 00:19 - INFO - 	 Val. Loss: 0.248
2024-11-03 00:19 - INFO - 	 ROC-AUC: 0.783
2024-11-03 00:19 - INFO - 	 PR-AUC: 0.143
2024-11-03 00:19 - INFO - 	 Recall for 0.4 precision: 0.005
2024-11-03 00:19 - INFO - 	 Best Val. Loss: 0.248
2024-11-03 00:19 - INFO - 	 Best ROC-AUC: 0.783
2024-11-03 00:19 - INFO - 	 Best PR-AUC: 0.158
2024-11-03 00:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.778
2024-11-03 00:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.101
2024-11-03 00:19 - INFO - 	 Best Recall for 0.4 precision: 0.055
2024-11-03 00:19 - INFO - ---------------------------------------------
2024-11-03 00:20 - INFO - ---------------------------------------------
2024-11-03 00:20 - INFO - Epoch: 03 | Time: 1m 48s
2024-11-03 00:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30228
2024-11-03 00:20 - INFO - 	 Train Loss: 0.193
2024-11-03 00:20 - INFO - 	 Val. Loss: 0.225
2024-11-03 00:20 - INFO - 	 ROC-AUC: 0.795
2024-11-03 00:20 - INFO - 	 PR-AUC: 0.302
2024-11-03 00:20 - INFO - 	 Recall for 0.4 precision: 0.293
2024-11-03 00:20 - INFO - 	 Best Val. Loss: 0.225
2024-11-03 00:20 - INFO - 	 Best ROC-AUC: 0.795
2024-11-03 00:20 - INFO - 	 Best PR-AUC: 0.302
2024-11-03 00:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.732
2024-11-03 00:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.140
2024-11-03 00:20 - INFO - 	 Best Recall for 0.4 precision: 0.293
2024-11-03 00:20 - INFO - ---------------------------------------------
2024-11-03 00:22 - INFO - ---------------------------------------------
2024-11-03 00:22 - INFO - Epoch: 04 | Time: 1m 47s
2024-11-03 00:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30324
2024-11-03 00:22 - INFO - 	 Train Loss: 0.175
2024-11-03 00:22 - INFO - 	 Val. Loss: 0.199
2024-11-03 00:22 - INFO - 	 ROC-AUC: 0.800
2024-11-03 00:22 - INFO - 	 PR-AUC: 0.303
2024-11-03 00:22 - INFO - 	 Recall for 0.4 precision: 0.377
2024-11-03 00:22 - INFO - 	 Best Val. Loss: 0.199
2024-11-03 00:22 - INFO - 	 Best ROC-AUC: 0.800
2024-11-03 00:22 - INFO - 	 Best PR-AUC: 0.303
2024-11-03 00:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.781
2024-11-03 00:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 00:22 - INFO - 	 Best Recall for 0.4 precision: 0.377
2024-11-03 00:22 - INFO - ---------------------------------------------
2024-11-03 00:24 - INFO - ---------------------------------------------
2024-11-03 00:24 - INFO - Epoch: 05 | Time: 1m 48s
2024-11-03 00:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.35761
2024-11-03 00:24 - INFO - 	 Train Loss: 0.165
2024-11-03 00:24 - INFO - 	 Val. Loss: 0.185
2024-11-03 00:24 - INFO - 	 ROC-AUC: 0.824
2024-11-03 00:24 - INFO - 	 PR-AUC: 0.358
2024-11-03 00:24 - INFO - 	 Recall for 0.4 precision: 0.462
2024-11-03 00:24 - INFO - 	 Best Val. Loss: 0.185
2024-11-03 00:24 - INFO - 	 Best ROC-AUC: 0.824
2024-11-03 00:24 - INFO - 	 Best PR-AUC: 0.358
2024-11-03 00:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.793
2024-11-03 00:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 00:24 - INFO - 	 Best Recall for 0.4 precision: 0.462
2024-11-03 00:24 - INFO - ---------------------------------------------
2024-11-03 00:26 - INFO - ---------------------------------------------
2024-11-03 00:26 - INFO - Epoch: 06 | Time: 1m 48s
2024-11-03 00:26 - INFO - 	 Train Loss: 0.158
2024-11-03 00:26 - INFO - 	 Val. Loss: 0.175
2024-11-03 00:26 - INFO - 	 ROC-AUC: 0.843
2024-11-03 00:26 - INFO - 	 PR-AUC: 0.347
2024-11-03 00:26 - INFO - 	 Recall for 0.4 precision: 0.444
2024-11-03 00:26 - INFO - 	 Best Val. Loss: 0.175
2024-11-03 00:26 - INFO - 	 Best ROC-AUC: 0.843
2024-11-03 00:26 - INFO - 	 Best PR-AUC: 0.358
2024-11-03 00:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.778
2024-11-03 00:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 00:26 - INFO - 	 Best Recall for 0.4 precision: 0.462
2024-11-03 00:26 - INFO - ---------------------------------------------
2024-11-03 00:28 - INFO - ---------------------------------------------
2024-11-03 00:28 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-03 00:28 - INFO - 	 Train Loss: 0.152
2024-11-03 00:28 - INFO - 	 Val. Loss: 0.161
2024-11-03 00:28 - INFO - 	 ROC-AUC: 0.842
2024-11-03 00:28 - INFO - 	 PR-AUC: 0.322
2024-11-03 00:28 - INFO - 	 Recall for 0.4 precision: 0.283
2024-11-03 00:28 - INFO - 	 Best Val. Loss: 0.161
2024-11-03 00:28 - INFO - 	 Best ROC-AUC: 0.843
2024-11-03 00:28 - INFO - 	 Best PR-AUC: 0.358
2024-11-03 00:28 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.778
2024-11-03 00:28 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 00:28 - INFO - 	 Best Recall for 0.4 precision: 0.462
2024-11-03 00:28 - INFO - ---------------------------------------------
2024-11-03 00:30 - INFO - ---------------------------------------------
2024-11-03 00:30 - INFO - Epoch: 08 | Time: 1m 49s
2024-11-03 00:30 - INFO - 	 Train Loss: 0.149
2024-11-03 00:30 - INFO - 	 Val. Loss: 0.165
2024-11-03 00:30 - INFO - 	 ROC-AUC: 0.846
2024-11-03 00:30 - INFO - 	 PR-AUC: 0.294
2024-11-03 00:30 - INFO - 	 Recall for 0.4 precision: 0.182
2024-11-03 00:30 - INFO - 	 Best Val. Loss: 0.161
2024-11-03 00:30 - INFO - 	 Best ROC-AUC: 0.846
2024-11-03 00:30 - INFO - 	 Best PR-AUC: 0.358
2024-11-03 00:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.788
2024-11-03 00:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 00:30 - INFO - 	 Best Recall for 0.4 precision: 0.462
2024-11-03 00:30 - INFO - ---------------------------------------------
2024-11-03 00:34 - INFO - Fit the preprocessing pipeline
2024-11-03 00:34 - INFO - Training using device: mps
2024-11-03 00:34 - INFO - Creating generators
2024-11-03 00:34 - INFO - The model has 651,257 trainable parameters
2024-11-03 00:34 - INFO - * Model:
2024-11-03 00:34 - INFO - * -----------
2024-11-03 00:34 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 00:34 - INFO - * -----------
2024-11-03 00:34 - INFO - Evaluating model based on: aucpr
2024-11-03 00:34 - INFO - Training..

2024-11-03 00:36 - INFO - ---------------------------------------------
2024-11-03 00:36 - INFO - Epoch: 01 | Time: 1m 41s
2024-11-03 00:36 - INFO - 	 New best val_rocauc loss was found, current best value is 0.20232
2024-11-03 00:36 - INFO - 	 Train Loss: 0.263
2024-11-03 00:36 - INFO - 	 Val. Loss: 0.291
2024-11-03 00:36 - INFO - 	 ROC-AUC: 0.755
2024-11-03 00:36 - INFO - 	 PR-AUC: 0.202
2024-11-03 00:36 - INFO - 	 Recall for 0.4 precision: 0.115
2024-11-03 00:36 - INFO - 	 Best Val. Loss: 0.291
2024-11-03 00:36 - INFO - 	 Best ROC-AUC: 0.755
2024-11-03 00:36 - INFO - 	 Best PR-AUC: 0.202
2024-11-03 00:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.747
2024-11-03 00:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.108
2024-11-03 00:36 - INFO - 	 Best Recall for 0.4 precision: 0.115
2024-11-03 00:36 - INFO - ---------------------------------------------
2024-11-03 00:37 - INFO - ---------------------------------------------
2024-11-03 00:37 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 00:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.21771
2024-11-03 00:37 - INFO - 	 Train Loss: 0.215
2024-11-03 00:37 - INFO - 	 Val. Loss: 0.274
2024-11-03 00:37 - INFO - 	 ROC-AUC: 0.740
2024-11-03 00:37 - INFO - 	 PR-AUC: 0.218
2024-11-03 00:37 - INFO - 	 Recall for 0.4 precision: 0.039
2024-11-03 00:37 - INFO - 	 Best Val. Loss: 0.274
2024-11-03 00:37 - INFO - 	 Best ROC-AUC: 0.755
2024-11-03 00:37 - INFO - 	 Best PR-AUC: 0.218
2024-11-03 00:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.747
2024-11-03 00:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.157
2024-11-03 00:37 - INFO - 	 Best Recall for 0.4 precision: 0.115
2024-11-03 00:37 - INFO - ---------------------------------------------
2024-11-03 00:39 - INFO - ---------------------------------------------
2024-11-03 00:39 - INFO - Epoch: 03 | Time: 1m 45s
2024-11-03 00:39 - INFO - 	 Train Loss: 0.188
2024-11-03 00:39 - INFO - 	 Val. Loss: 0.249
2024-11-03 00:39 - INFO - 	 ROC-AUC: 0.757
2024-11-03 00:39 - INFO - 	 PR-AUC: 0.184
2024-11-03 00:39 - INFO - 	 Recall for 0.4 precision: 0.101
2024-11-03 00:39 - INFO - 	 Best Val. Loss: 0.249
2024-11-03 00:39 - INFO - 	 Best ROC-AUC: 0.757
2024-11-03 00:39 - INFO - 	 Best PR-AUC: 0.218
2024-11-03 00:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.801
2024-11-03 00:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.157
2024-11-03 00:39 - INFO - 	 Best Recall for 0.4 precision: 0.115
2024-11-03 00:39 - INFO - ---------------------------------------------
2024-11-03 00:41 - INFO - ---------------------------------------------
2024-11-03 00:41 - INFO - Epoch: 04 | Time: 1m 47s
2024-11-03 00:41 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30145
2024-11-03 00:41 - INFO - 	 Train Loss: 0.174
2024-11-03 00:41 - INFO - 	 Val. Loss: 0.218
2024-11-03 00:41 - INFO - 	 ROC-AUC: 0.784
2024-11-03 00:41 - INFO - 	 PR-AUC: 0.301
2024-11-03 00:41 - INFO - 	 Recall for 0.4 precision: 0.299
2024-11-03 00:41 - INFO - 	 Best Val. Loss: 0.218
2024-11-03 00:41 - INFO - 	 Best ROC-AUC: 0.784
2024-11-03 00:41 - INFO - 	 Best PR-AUC: 0.301
2024-11-03 00:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.769
2024-11-03 00:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.166
2024-11-03 00:41 - INFO - 	 Best Recall for 0.4 precision: 0.299
2024-11-03 00:41 - INFO - ---------------------------------------------
2024-11-03 00:43 - INFO - ---------------------------------------------
2024-11-03 00:43 - INFO - Epoch: 05 | Time: 1m 47s
2024-11-03 00:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.3158
2024-11-03 00:43 - INFO - 	 Train Loss: 0.164
2024-11-03 00:43 - INFO - 	 Val. Loss: 0.188
2024-11-03 00:43 - INFO - 	 ROC-AUC: 0.798
2024-11-03 00:43 - INFO - 	 PR-AUC: 0.316
2024-11-03 00:43 - INFO - 	 Recall for 0.4 precision: 0.387
2024-11-03 00:43 - INFO - 	 Best Val. Loss: 0.188
2024-11-03 00:43 - INFO - 	 Best ROC-AUC: 0.798
2024-11-03 00:43 - INFO - 	 Best PR-AUC: 0.316
2024-11-03 00:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.760
2024-11-03 00:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.148
2024-11-03 00:43 - INFO - 	 Best Recall for 0.4 precision: 0.387
2024-11-03 00:43 - INFO - ---------------------------------------------
2024-11-03 00:45 - INFO - ---------------------------------------------
2024-11-03 00:45 - INFO - Epoch: 06 | Time: 1m 48s
2024-11-03 00:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.38839
2024-11-03 00:45 - INFO - 	 Train Loss: 0.157
2024-11-03 00:45 - INFO - 	 Val. Loss: 0.168
2024-11-03 00:45 - INFO - 	 ROC-AUC: 0.815
2024-11-03 00:45 - INFO - 	 PR-AUC: 0.388
2024-11-03 00:45 - INFO - 	 Recall for 0.4 precision: 0.328
2024-11-03 00:45 - INFO - 	 Best Val. Loss: 0.168
2024-11-03 00:45 - INFO - 	 Best ROC-AUC: 0.815
2024-11-03 00:45 - INFO - 	 Best PR-AUC: 0.388
2024-11-03 00:45 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.761
2024-11-03 00:45 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.132
2024-11-03 00:45 - INFO - 	 Best Recall for 0.4 precision: 0.387
2024-11-03 00:45 - INFO - ---------------------------------------------
2024-11-03 00:46 - INFO - ---------------------------------------------
2024-11-03 00:46 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-03 00:46 - INFO - 	 Train Loss: 0.152
2024-11-03 00:46 - INFO - 	 Val. Loss: 0.149
2024-11-03 00:46 - INFO - 	 ROC-AUC: 0.863
2024-11-03 00:46 - INFO - 	 PR-AUC: 0.379
2024-11-03 00:46 - INFO - 	 Recall for 0.4 precision: 0.449
2024-11-03 00:46 - INFO - 	 Best Val. Loss: 0.149
2024-11-03 00:46 - INFO - 	 Best ROC-AUC: 0.863
2024-11-03 00:46 - INFO - 	 Best PR-AUC: 0.388
2024-11-03 00:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.802
2024-11-03 00:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.132
2024-11-03 00:46 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 00:46 - INFO - ---------------------------------------------
2024-11-03 00:48 - INFO - ---------------------------------------------
2024-11-03 00:48 - INFO - Epoch: 08 | Time: 1m 49s
2024-11-03 00:48 - INFO - 	 Train Loss: 0.143
2024-11-03 00:48 - INFO - 	 Val. Loss: 0.146
2024-11-03 00:48 - INFO - 	 ROC-AUC: 0.836
2024-11-03 00:48 - INFO - 	 PR-AUC: 0.354
2024-11-03 00:48 - INFO - 	 Recall for 0.4 precision: 0.296
2024-11-03 00:48 - INFO - 	 Best Val. Loss: 0.146
2024-11-03 00:48 - INFO - 	 Best ROC-AUC: 0.863
2024-11-03 00:48 - INFO - 	 Best PR-AUC: 0.388
2024-11-03 00:48 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.802
2024-11-03 00:48 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.132
2024-11-03 00:48 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 00:48 - INFO - ---------------------------------------------
2024-11-03 00:50 - INFO - ---------------------------------------------
2024-11-03 00:50 - INFO - Epoch: 09 | Time: 1m 49s
2024-11-03 00:50 - INFO - 	 Train Loss: 0.138
2024-11-03 00:50 - INFO - 	 Val. Loss: 0.152
2024-11-03 00:50 - INFO - 	 ROC-AUC: 0.847
2024-11-03 00:50 - INFO - 	 PR-AUC: 0.285
2024-11-03 00:50 - INFO - 	 Recall for 0.4 precision: 0.218
2024-11-03 00:50 - INFO - 	 Best Val. Loss: 0.146
2024-11-03 00:50 - INFO - 	 Best ROC-AUC: 0.863
2024-11-03 00:50 - INFO - 	 Best PR-AUC: 0.388
2024-11-03 00:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.802
2024-11-03 00:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.132
2024-11-03 00:50 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 00:50 - INFO - ---------------------------------------------
2024-11-03 00:52 - INFO - ---------------------------------------------
2024-11-03 00:52 - INFO - Epoch: 10 | Time: 1m 49s
2024-11-03 00:52 - INFO - 	 New best val_rocauc loss was found, current best value is 0.38944
2024-11-03 00:52 - INFO - 	 Train Loss: 0.123
2024-11-03 00:52 - INFO - 	 Val. Loss: 0.142
2024-11-03 00:52 - INFO - 	 ROC-AUC: 0.916
2024-11-03 00:52 - INFO - 	 PR-AUC: 0.389
2024-11-03 00:52 - INFO - 	 Recall for 0.4 precision: 0.514
2024-11-03 00:52 - INFO - 	 Best Val. Loss: 0.142
2024-11-03 00:52 - INFO - 	 Best ROC-AUC: 0.916
2024-11-03 00:52 - INFO - 	 Best PR-AUC: 0.389
2024-11-03 00:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.915
2024-11-03 00:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.305
2024-11-03 00:52 - INFO - 	 Best Recall for 0.4 precision: 0.514
2024-11-03 00:52 - INFO - ---------------------------------------------
2024-11-03 00:54 - INFO - Fit the preprocessing pipeline
2024-11-03 00:54 - INFO - Training using device: mps
2024-11-03 00:54 - INFO - Creating generators
2024-11-03 00:54 - INFO - The model has 651,257 trainable parameters
2024-11-03 00:54 - INFO - * Model:
2024-11-03 00:54 - INFO - * -----------
2024-11-03 00:54 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 00:54 - INFO - * -----------
2024-11-03 00:54 - INFO - Evaluating model based on: aucpr
2024-11-03 00:54 - INFO - Training..

2024-11-03 00:56 - INFO - ---------------------------------------------
2024-11-03 00:56 - INFO - Epoch: 01 | Time: 1m 41s
2024-11-03 00:56 - INFO - 	 New best val_rocauc loss was found, current best value is 0.17303
2024-11-03 00:56 - INFO - 	 Train Loss: 0.267
2024-11-03 00:56 - INFO - 	 Val. Loss: 0.297
2024-11-03 00:56 - INFO - 	 ROC-AUC: 0.704
2024-11-03 00:56 - INFO - 	 PR-AUC: 0.173
2024-11-03 00:56 - INFO - 	 Recall for 0.4 precision: 0.075
2024-11-03 00:56 - INFO - 	 Best Val. Loss: 0.297
2024-11-03 00:56 - INFO - 	 Best ROC-AUC: 0.704
2024-11-03 00:56 - INFO - 	 Best PR-AUC: 0.173
2024-11-03 00:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.750
2024-11-03 00:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.114
2024-11-03 00:56 - INFO - 	 Best Recall for 0.4 precision: 0.075
2024-11-03 00:56 - INFO - ---------------------------------------------
2024-11-03 00:58 - INFO - ---------------------------------------------
2024-11-03 00:58 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 00:58 - INFO - 	 Train Loss: 0.240
2024-11-03 00:58 - INFO - 	 Val. Loss: 0.325
2024-11-03 00:58 - INFO - 	 ROC-AUC: 0.562
2024-11-03 00:58 - INFO - 	 PR-AUC: 0.081
2024-11-03 00:58 - INFO - 	 Recall for 0.4 precision: 0.002
2024-11-03 00:58 - INFO - 	 Best Val. Loss: 0.297
2024-11-03 00:58 - INFO - 	 Best ROC-AUC: 0.704
2024-11-03 00:58 - INFO - 	 Best PR-AUC: 0.173
2024-11-03 00:58 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.750
2024-11-03 00:58 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.114
2024-11-03 00:58 - INFO - 	 Best Recall for 0.4 precision: 0.075
2024-11-03 00:58 - INFO - ---------------------------------------------
2024-11-03 01:00 - INFO - ---------------------------------------------
2024-11-03 01:00 - INFO - Epoch: 03 | Time: 1m 43s
2024-11-03 01:00 - INFO - 	 New best val_rocauc loss was found, current best value is 0.21321
2024-11-03 01:00 - INFO - 	 Train Loss: 0.206
2024-11-03 01:00 - INFO - 	 Val. Loss: 0.221
2024-11-03 01:00 - INFO - 	 ROC-AUC: 0.817
2024-11-03 01:00 - INFO - 	 PR-AUC: 0.213
2024-11-03 01:00 - INFO - 	 Recall for 0.4 precision: 0.024
2024-11-03 01:00 - INFO - 	 Best Val. Loss: 0.221
2024-11-03 01:00 - INFO - 	 Best ROC-AUC: 0.817
2024-11-03 01:00 - INFO - 	 Best PR-AUC: 0.213
2024-11-03 01:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.822
2024-11-03 01:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.164
2024-11-03 01:00 - INFO - 	 Best Recall for 0.4 precision: 0.075
2024-11-03 01:00 - INFO - ---------------------------------------------
2024-11-03 01:01 - INFO - ---------------------------------------------
2024-11-03 01:01 - INFO - Epoch: 04 | Time: 1m 45s
2024-11-03 01:01 - INFO - 	 New best val_rocauc loss was found, current best value is 0.28377
2024-11-03 01:01 - INFO - 	 Train Loss: 0.184
2024-11-03 01:01 - INFO - 	 Val. Loss: 0.196
2024-11-03 01:01 - INFO - 	 ROC-AUC: 0.839
2024-11-03 01:01 - INFO - 	 PR-AUC: 0.284
2024-11-03 01:01 - INFO - 	 Recall for 0.4 precision: 0.322
2024-11-03 01:01 - INFO - 	 Best Val. Loss: 0.196
2024-11-03 01:01 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:01 - INFO - 	 Best PR-AUC: 0.284
2024-11-03 01:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.181
2024-11-03 01:01 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:01 - INFO - ---------------------------------------------
2024-11-03 01:03 - INFO - ---------------------------------------------
2024-11-03 01:03 - INFO - Epoch: 05 | Time: 1m 47s
2024-11-03 01:03 - INFO - 	 Train Loss: 0.176
2024-11-03 01:03 - INFO - 	 Val. Loss: 0.197
2024-11-03 01:03 - INFO - 	 ROC-AUC: 0.748
2024-11-03 01:03 - INFO - 	 PR-AUC: 0.225
2024-11-03 01:03 - INFO - 	 Recall for 0.4 precision: 0.174
2024-11-03 01:03 - INFO - 	 Best Val. Loss: 0.196
2024-11-03 01:03 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:03 - INFO - 	 Best PR-AUC: 0.284
2024-11-03 01:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.181
2024-11-03 01:03 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:03 - INFO - ---------------------------------------------
2024-11-03 01:05 - INFO - ---------------------------------------------
2024-11-03 01:05 - INFO - Epoch: 06 | Time: 1m 48s
2024-11-03 01:05 - INFO - 	 Train Loss: 0.175
2024-11-03 01:05 - INFO - 	 Val. Loss: 0.185
2024-11-03 01:05 - INFO - 	 ROC-AUC: 0.798
2024-11-03 01:05 - INFO - 	 PR-AUC: 0.256
2024-11-03 01:05 - INFO - 	 Recall for 0.4 precision: 0.260
2024-11-03 01:05 - INFO - 	 Best Val. Loss: 0.185
2024-11-03 01:05 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:05 - INFO - 	 Best PR-AUC: 0.284
2024-11-03 01:05 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:05 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.181
2024-11-03 01:05 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:05 - INFO - ---------------------------------------------
2024-11-03 01:07 - INFO - ---------------------------------------------
2024-11-03 01:07 - INFO - Epoch: 07 | Time: 1m 49s
2024-11-03 01:07 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31634
2024-11-03 01:07 - INFO - 	 Train Loss: 0.161
2024-11-03 01:07 - INFO - 	 Val. Loss: 0.183
2024-11-03 01:07 - INFO - 	 ROC-AUC: 0.819
2024-11-03 01:07 - INFO - 	 PR-AUC: 0.316
2024-11-03 01:07 - INFO - 	 Recall for 0.4 precision: 0.260
2024-11-03 01:07 - INFO - 	 Best Val. Loss: 0.183
2024-11-03 01:07 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:07 - INFO - 	 Best PR-AUC: 0.316
2024-11-03 01:07 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:07 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:07 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:07 - INFO - ---------------------------------------------
2024-11-03 01:09 - INFO - ---------------------------------------------
2024-11-03 01:09 - INFO - Epoch: 08 | Time: 1m 49s
2024-11-03 01:09 - INFO - 	 Train Loss: 0.153
2024-11-03 01:09 - INFO - 	 Val. Loss: 0.181
2024-11-03 01:09 - INFO - 	 ROC-AUC: 0.816
2024-11-03 01:09 - INFO - 	 PR-AUC: 0.241
2024-11-03 01:09 - INFO - 	 Recall for 0.4 precision: 0.198
2024-11-03 01:09 - INFO - 	 Best Val. Loss: 0.181
2024-11-03 01:09 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:09 - INFO - 	 Best PR-AUC: 0.316
2024-11-03 01:09 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:09 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:09 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:09 - INFO - ---------------------------------------------
2024-11-03 01:10 - INFO - ---------------------------------------------
2024-11-03 01:10 - INFO - Epoch: 09 | Time: 1m 49s
2024-11-03 01:10 - INFO - 	 Train Loss: 0.149
2024-11-03 01:10 - INFO - 	 Val. Loss: 0.200
2024-11-03 01:10 - INFO - 	 ROC-AUC: 0.803
2024-11-03 01:10 - INFO - 	 PR-AUC: 0.250
2024-11-03 01:10 - INFO - 	 Recall for 0.4 precision: 0.197
2024-11-03 01:10 - INFO - 	 Best Val. Loss: 0.181
2024-11-03 01:10 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:10 - INFO - 	 Best PR-AUC: 0.316
2024-11-03 01:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:10 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:10 - INFO - ---------------------------------------------
2024-11-03 01:12 - INFO - ---------------------------------------------
2024-11-03 01:12 - INFO - Epoch: 10 | Time: 1m 49s
2024-11-03 01:12 - INFO - 	 Train Loss: 0.146
2024-11-03 01:12 - INFO - 	 Val. Loss: 0.204
2024-11-03 01:12 - INFO - 	 ROC-AUC: 0.811
2024-11-03 01:12 - INFO - 	 PR-AUC: 0.241
2024-11-03 01:12 - INFO - 	 Recall for 0.4 precision: 0.150
2024-11-03 01:12 - INFO - 	 Best Val. Loss: 0.181
2024-11-03 01:12 - INFO - 	 Best ROC-AUC: 0.839
2024-11-03 01:12 - INFO - 	 Best PR-AUC: 0.316
2024-11-03 01:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.831
2024-11-03 01:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:12 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:12 - INFO - ---------------------------------------------
2024-11-03 01:15 - INFO - Fit the preprocessing pipeline
2024-11-03 01:15 - INFO - Training using device: mps
2024-11-03 01:15 - INFO - Creating generators
2024-11-03 01:15 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:15 - INFO - * Model:
2024-11-03 01:15 - INFO - * -----------
2024-11-03 01:15 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:15 - INFO - * -----------
2024-11-03 01:15 - INFO - Evaluating model based on: aucpr
2024-11-03 01:15 - INFO - Training..

2024-11-03 01:17 - INFO - ---------------------------------------------
2024-11-03 01:17 - INFO - Epoch: 01 | Time: 1m 42s
2024-11-03 01:17 - INFO - 	 New best val_rocauc loss was found, current best value is 0.15976
2024-11-03 01:17 - INFO - 	 Train Loss: 0.257
2024-11-03 01:17 - INFO - 	 Val. Loss: 0.290
2024-11-03 01:17 - INFO - 	 ROC-AUC: 0.754
2024-11-03 01:17 - INFO - 	 PR-AUC: 0.160
2024-11-03 01:17 - INFO - 	 Recall for 0.4 precision: 0.033
2024-11-03 01:17 - INFO - 	 Best Val. Loss: 0.290
2024-11-03 01:17 - INFO - 	 Best ROC-AUC: 0.754
2024-11-03 01:17 - INFO - 	 Best PR-AUC: 0.160
2024-11-03 01:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.771
2024-11-03 01:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.191
2024-11-03 01:17 - INFO - 	 Best Recall for 0.4 precision: 0.033
2024-11-03 01:17 - INFO - ---------------------------------------------
2024-11-03 01:18 - INFO - ---------------------------------------------
2024-11-03 01:18 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:18 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22752
2024-11-03 01:18 - INFO - 	 Train Loss: 0.216
2024-11-03 01:18 - INFO - 	 Val. Loss: 0.232
2024-11-03 01:18 - INFO - 	 ROC-AUC: 0.803
2024-11-03 01:18 - INFO - 	 PR-AUC: 0.228
2024-11-03 01:18 - INFO - 	 Recall for 0.4 precision: 0.198
2024-11-03 01:18 - INFO - 	 Best Val. Loss: 0.232
2024-11-03 01:18 - INFO - 	 Best ROC-AUC: 0.803
2024-11-03 01:18 - INFO - 	 Best PR-AUC: 0.228
2024-11-03 01:18 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.787
2024-11-03 01:18 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.176
2024-11-03 01:18 - INFO - 	 Best Recall for 0.4 precision: 0.198
2024-11-03 01:18 - INFO - ---------------------------------------------
2024-11-03 01:20 - INFO - ---------------------------------------------
2024-11-03 01:20 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-03 01:20 - INFO - 	 New best val_rocauc loss was found, current best value is 0.25051
2024-11-03 01:20 - INFO - 	 Train Loss: 0.190
2024-11-03 01:20 - INFO - 	 Val. Loss: 0.210
2024-11-03 01:20 - INFO - 	 ROC-AUC: 0.813
2024-11-03 01:20 - INFO - 	 PR-AUC: 0.251
2024-11-03 01:20 - INFO - 	 Recall for 0.4 precision: 0.202
2024-11-03 01:20 - INFO - 	 Best Val. Loss: 0.210
2024-11-03 01:20 - INFO - 	 Best ROC-AUC: 0.813
2024-11-03 01:20 - INFO - 	 Best PR-AUC: 0.251
2024-11-03 01:20 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.756
2024-11-03 01:20 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.143
2024-11-03 01:20 - INFO - 	 Best Recall for 0.4 precision: 0.202
2024-11-03 01:20 - INFO - ---------------------------------------------
2024-11-03 01:22 - INFO - ---------------------------------------------
2024-11-03 01:22 - INFO - Epoch: 04 | Time: 1m 43s
2024-11-03 01:22 - INFO - 	 New best val_rocauc loss was found, current best value is 0.29333
2024-11-03 01:22 - INFO - 	 Train Loss: 0.175
2024-11-03 01:22 - INFO - 	 Val. Loss: 0.202
2024-11-03 01:22 - INFO - 	 ROC-AUC: 0.840
2024-11-03 01:22 - INFO - 	 PR-AUC: 0.293
2024-11-03 01:22 - INFO - 	 Recall for 0.4 precision: 0.273
2024-11-03 01:22 - INFO - 	 Best Val. Loss: 0.202
2024-11-03 01:22 - INFO - 	 Best ROC-AUC: 0.840
2024-11-03 01:22 - INFO - 	 Best PR-AUC: 0.293
2024-11-03 01:22 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.793
2024-11-03 01:22 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.187
2024-11-03 01:22 - INFO - 	 Best Recall for 0.4 precision: 0.273
2024-11-03 01:22 - INFO - ---------------------------------------------
2024-11-03 01:24 - INFO - ---------------------------------------------
2024-11-03 01:24 - INFO - Epoch: 05 | Time: 1m 45s
2024-11-03 01:24 - INFO - 	 Train Loss: 0.166
2024-11-03 01:24 - INFO - 	 Val. Loss: 0.186
2024-11-03 01:24 - INFO - 	 ROC-AUC: 0.832
2024-11-03 01:24 - INFO - 	 PR-AUC: 0.282
2024-11-03 01:24 - INFO - 	 Recall for 0.4 precision: 0.172
2024-11-03 01:24 - INFO - 	 Best Val. Loss: 0.186
2024-11-03 01:24 - INFO - 	 Best ROC-AUC: 0.840
2024-11-03 01:24 - INFO - 	 Best PR-AUC: 0.293
2024-11-03 01:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.793
2024-11-03 01:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.187
2024-11-03 01:24 - INFO - 	 Best Recall for 0.4 precision: 0.273
2024-11-03 01:24 - INFO - ---------------------------------------------
2024-11-03 01:25 - INFO - ---------------------------------------------
2024-11-03 01:25 - INFO - Epoch: 06 | Time: 1m 46s
2024-11-03 01:25 - INFO - 	 Train Loss: 0.158
2024-11-03 01:25 - INFO - 	 Val. Loss: 0.174
2024-11-03 01:25 - INFO - 	 ROC-AUC: 0.840
2024-11-03 01:25 - INFO - 	 PR-AUC: 0.258
2024-11-03 01:25 - INFO - 	 Recall for 0.4 precision: 0.267
2024-11-03 01:25 - INFO - 	 Best Val. Loss: 0.174
2024-11-03 01:25 - INFO - 	 Best ROC-AUC: 0.840
2024-11-03 01:25 - INFO - 	 Best PR-AUC: 0.293
2024-11-03 01:25 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.792
2024-11-03 01:25 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.187
2024-11-03 01:25 - INFO - 	 Best Recall for 0.4 precision: 0.273
2024-11-03 01:25 - INFO - ---------------------------------------------
2024-11-03 01:27 - INFO - ---------------------------------------------
2024-11-03 01:27 - INFO - Epoch: 07 | Time: 1m 48s
2024-11-03 01:27 - INFO - 	 Train Loss: 0.153
2024-11-03 01:27 - INFO - 	 Val. Loss: 0.177
2024-11-03 01:27 - INFO - 	 ROC-AUC: 0.832
2024-11-03 01:27 - INFO - 	 PR-AUC: 0.266
2024-11-03 01:27 - INFO - 	 Recall for 0.4 precision: 0.278
2024-11-03 01:27 - INFO - 	 Best Val. Loss: 0.174
2024-11-03 01:27 - INFO - 	 Best ROC-AUC: 0.840
2024-11-03 01:27 - INFO - 	 Best PR-AUC: 0.293
2024-11-03 01:27 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.792
2024-11-03 01:27 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.187
2024-11-03 01:27 - INFO - 	 Best Recall for 0.4 precision: 0.278
2024-11-03 01:27 - INFO - ---------------------------------------------
2024-11-03 01:32 - INFO - Fit the preprocessing pipeline
2024-11-03 01:32 - INFO - Training using device: mps
2024-11-03 01:32 - INFO - Creating generators
2024-11-03 01:32 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:32 - INFO - * Model:
2024-11-03 01:32 - INFO - * -----------
2024-11-03 01:32 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:32 - INFO - * -----------
2024-11-03 01:32 - INFO - Evaluating model based on: aucpr
2024-11-03 01:32 - INFO - Training..

2024-11-03 01:33 - INFO - ---------------------------------------------
2024-11-03 01:33 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-03 01:33 - INFO - 	 New best val_rocauc loss was found, current best value is 0.02782
2024-11-03 01:33 - INFO - 	 Train Loss: 0.257
2024-11-03 01:33 - INFO - 	 Val. Loss: 0.472
2024-11-03 01:33 - INFO - 	 ROC-AUC: 0.254
2024-11-03 01:33 - INFO - 	 PR-AUC: 0.028
2024-11-03 01:33 - INFO - 	 Recall for 0.4 precision: 1.000
2024-11-03 01:33 - INFO - 	 Best Val. Loss: 0.472
2024-11-03 01:33 - INFO - 	 Best ROC-AUC: 0.254
2024-11-03 01:33 - INFO - 	 Best PR-AUC: 0.028
2024-11-03 01:33 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.355
2024-11-03 01:33 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.035
2024-11-03 01:33 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:33 - INFO - ---------------------------------------------
2024-11-03 01:35 - INFO - ---------------------------------------------
2024-11-03 01:35 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:35 - INFO - 	 New best val_rocauc loss was found, current best value is 0.21818
2024-11-03 01:35 - INFO - 	 Train Loss: 0.211
2024-11-03 01:35 - INFO - 	 Val. Loss: 0.256
2024-11-03 01:35 - INFO - 	 ROC-AUC: 0.767
2024-11-03 01:35 - INFO - 	 PR-AUC: 0.218
2024-11-03 01:35 - INFO - 	 Recall for 0.4 precision: 0.150
2024-11-03 01:35 - INFO - 	 Best Val. Loss: 0.256
2024-11-03 01:35 - INFO - 	 Best ROC-AUC: 0.767
2024-11-03 01:35 - INFO - 	 Best PR-AUC: 0.218
2024-11-03 01:35 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-03 01:35 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.140
2024-11-03 01:35 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:35 - INFO - ---------------------------------------------
2024-11-03 01:37 - INFO - ---------------------------------------------
2024-11-03 01:37 - INFO - Epoch: 03 | Time: 1m 43s
2024-11-03 01:37 - INFO - 	 Train Loss: 0.191
2024-11-03 01:37 - INFO - 	 Val. Loss: 0.228
2024-11-03 01:37 - INFO - 	 ROC-AUC: 0.781
2024-11-03 01:37 - INFO - 	 PR-AUC: 0.199
2024-11-03 01:37 - INFO - 	 Recall for 0.4 precision: 0.208
2024-11-03 01:37 - INFO - 	 Best Val. Loss: 0.228
2024-11-03 01:37 - INFO - 	 Best ROC-AUC: 0.781
2024-11-03 01:37 - INFO - 	 Best PR-AUC: 0.218
2024-11-03 01:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.758
2024-11-03 01:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.140
2024-11-03 01:37 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:37 - INFO - ---------------------------------------------
2024-11-03 01:38 - INFO - ---------------------------------------------
2024-11-03 01:38 - INFO - Epoch: 04 | Time: 1m 42s
2024-11-03 01:38 - INFO - 	 New best val_rocauc loss was found, current best value is 0.28528
2024-11-03 01:38 - INFO - 	 Train Loss: 0.177
2024-11-03 01:38 - INFO - 	 Val. Loss: 0.214
2024-11-03 01:38 - INFO - 	 ROC-AUC: 0.814
2024-11-03 01:38 - INFO - 	 PR-AUC: 0.285
2024-11-03 01:38 - INFO - 	 Recall for 0.4 precision: 0.167
2024-11-03 01:38 - INFO - 	 Best Val. Loss: 0.214
2024-11-03 01:38 - INFO - 	 Best ROC-AUC: 0.814
2024-11-03 01:38 - INFO - 	 Best PR-AUC: 0.285
2024-11-03 01:38 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.802
2024-11-03 01:38 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-03 01:38 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:38 - INFO - ---------------------------------------------
2024-11-03 01:40 - INFO - ---------------------------------------------
2024-11-03 01:40 - INFO - Epoch: 05 | Time: 1m 48s
2024-11-03 01:40 - INFO - 	 Train Loss: 0.170
2024-11-03 01:40 - INFO - 	 Val. Loss: 0.202
2024-11-03 01:40 - INFO - 	 ROC-AUC: 0.831
2024-11-03 01:40 - INFO - 	 PR-AUC: 0.264
2024-11-03 01:40 - INFO - 	 Recall for 0.4 precision: 0.299
2024-11-03 01:40 - INFO - 	 Best Val. Loss: 0.202
2024-11-03 01:40 - INFO - 	 Best ROC-AUC: 0.831
2024-11-03 01:40 - INFO - 	 Best PR-AUC: 0.285
2024-11-03 01:40 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.784
2024-11-03 01:40 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-03 01:40 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:40 - INFO - ---------------------------------------------
2024-11-03 01:42 - INFO - ---------------------------------------------
2024-11-03 01:42 - INFO - Epoch: 06 | Time: 1m 48s
2024-11-03 01:42 - INFO - 	 Train Loss: 0.163
2024-11-03 01:42 - INFO - 	 Val. Loss: 0.178
2024-11-03 01:42 - INFO - 	 ROC-AUC: 0.853
2024-11-03 01:42 - INFO - 	 PR-AUC: 0.259
2024-11-03 01:42 - INFO - 	 Recall for 0.4 precision: 0.010
2024-11-03 01:42 - INFO - 	 Best Val. Loss: 0.178
2024-11-03 01:42 - INFO - 	 Best ROC-AUC: 0.853
2024-11-03 01:42 - INFO - 	 Best PR-AUC: 0.285
2024-11-03 01:42 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.793
2024-11-03 01:42 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-03 01:42 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:42 - INFO - ---------------------------------------------
2024-11-03 01:44 - INFO - ---------------------------------------------
2024-11-03 01:44 - INFO - Epoch: 07 | Time: 1m 48s
2024-11-03 01:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30753
2024-11-03 01:44 - INFO - 	 Train Loss: 0.157
2024-11-03 01:44 - INFO - 	 Val. Loss: 0.168
2024-11-03 01:44 - INFO - 	 ROC-AUC: 0.885
2024-11-03 01:44 - INFO - 	 PR-AUC: 0.308
2024-11-03 01:44 - INFO - 	 Recall for 0.4 precision: 0.376
2024-11-03 01:44 - INFO - 	 Best Val. Loss: 0.168
2024-11-03 01:44 - INFO - 	 Best ROC-AUC: 0.885
2024-11-03 01:44 - INFO - 	 Best PR-AUC: 0.308
2024-11-03 01:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.797
2024-11-03 01:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-03 01:44 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:44 - INFO - ---------------------------------------------
2024-11-03 01:46 - INFO - ---------------------------------------------
2024-11-03 01:46 - INFO - Epoch: 08 | Time: 1m 49s
2024-11-03 01:46 - INFO - 	 New best val_rocauc loss was found, current best value is 0.30856
2024-11-03 01:46 - INFO - 	 Train Loss: 0.150
2024-11-03 01:46 - INFO - 	 Val. Loss: 0.150
2024-11-03 01:46 - INFO - 	 ROC-AUC: 0.897
2024-11-03 01:46 - INFO - 	 PR-AUC: 0.309
2024-11-03 01:46 - INFO - 	 Recall for 0.4 precision: 0.176
2024-11-03 01:46 - INFO - 	 Best Val. Loss: 0.150
2024-11-03 01:46 - INFO - 	 Best ROC-AUC: 0.897
2024-11-03 01:46 - INFO - 	 Best PR-AUC: 0.309
2024-11-03 01:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.819
2024-11-03 01:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.182
2024-11-03 01:46 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:46 - INFO - ---------------------------------------------
2024-11-03 01:47 - INFO - ---------------------------------------------
2024-11-03 01:47 - INFO - Epoch: 09 | Time: 1m 48s
2024-11-03 01:47 - INFO - 	 Train Loss: 0.146
2024-11-03 01:47 - INFO - 	 Val. Loss: 0.151
2024-11-03 01:47 - INFO - 	 ROC-AUC: 0.906
2024-11-03 01:47 - INFO - 	 PR-AUC: 0.295
2024-11-03 01:47 - INFO - 	 Recall for 0.4 precision: 0.047
2024-11-03 01:47 - INFO - 	 Best Val. Loss: 0.150
2024-11-03 01:47 - INFO - 	 Best ROC-AUC: 0.906
2024-11-03 01:47 - INFO - 	 Best PR-AUC: 0.309
2024-11-03 01:47 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.829
2024-11-03 01:47 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.182
2024-11-03 01:47 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:47 - INFO - ---------------------------------------------
2024-11-03 01:49 - INFO - ---------------------------------------------
2024-11-03 01:49 - INFO - Epoch: 10 | Time: 1m 49s
2024-11-03 01:49 - INFO - 	 Train Loss: 0.140
2024-11-03 01:49 - INFO - 	 Val. Loss: 0.166
2024-11-03 01:49 - INFO - 	 ROC-AUC: 0.883
2024-11-03 01:49 - INFO - 	 PR-AUC: 0.271
2024-11-03 01:49 - INFO - 	 Recall for 0.4 precision: 0.179
2024-11-03 01:49 - INFO - 	 Best Val. Loss: 0.150
2024-11-03 01:49 - INFO - 	 Best ROC-AUC: 0.906
2024-11-03 01:49 - INFO - 	 Best PR-AUC: 0.309
2024-11-03 01:49 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.829
2024-11-03 01:49 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.182
2024-11-03 01:49 - INFO - 	 Best Recall for 0.4 precision: 1.000
2024-11-03 01:49 - INFO - ---------------------------------------------
2024-11-03 01:52 - INFO - Fit the preprocessing pipeline
2024-11-03 01:52 - INFO - Training using device: mps
2024-11-03 01:52 - INFO - Creating generators
2024-11-03 01:52 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:52 - INFO - * Model:
2024-11-03 01:52 - INFO - * -----------
2024-11-03 01:52 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:52 - INFO - * -----------
2024-11-03 01:52 - INFO - Evaluating model based on: aucpr
2024-11-03 01:52 - INFO - Training..

2024-11-03 01:54 - INFO - ---------------------------------------------
2024-11-03 01:54 - INFO - Epoch: 01 | Time: 1m 41s
2024-11-03 01:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22487
2024-11-03 01:54 - INFO - 	 Train Loss: 0.255
2024-11-03 01:54 - INFO - 	 Val. Loss: 0.282
2024-11-03 01:54 - INFO - 	 ROC-AUC: 0.771
2024-11-03 01:54 - INFO - 	 PR-AUC: 0.225
2024-11-03 01:54 - INFO - 	 Recall for 0.4 precision: 0.195
2024-11-03 01:54 - INFO - 	 Best Val. Loss: 0.282
2024-11-03 01:54 - INFO - 	 Best ROC-AUC: 0.771
2024-11-03 01:54 - INFO - 	 Best PR-AUC: 0.225
2024-11-03 01:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.788
2024-11-03 01:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.182
2024-11-03 01:54 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-03 01:54 - INFO - ---------------------------------------------
2024-11-03 01:55 - INFO - ---------------------------------------------
2024-11-03 01:55 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.26141
2024-11-03 01:55 - INFO - 	 Train Loss: 0.217
2024-11-03 01:55 - INFO - 	 Val. Loss: 0.225
2024-11-03 01:55 - INFO - 	 ROC-AUC: 0.804
2024-11-03 01:55 - INFO - 	 PR-AUC: 0.261
2024-11-03 01:55 - INFO - 	 Recall for 0.4 precision: 0.202
2024-11-03 01:55 - INFO - 	 Best Val. Loss: 0.225
2024-11-03 01:55 - INFO - 	 Best ROC-AUC: 0.804
2024-11-03 01:55 - INFO - 	 Best PR-AUC: 0.261
2024-11-03 01:55 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.808
2024-11-03 01:55 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.144
2024-11-03 01:55 - INFO - 	 Best Recall for 0.4 precision: 0.202
2024-11-03 01:55 - INFO - ---------------------------------------------
2024-11-03 01:57 - INFO - ---------------------------------------------
2024-11-03 01:57 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-03 01:57 - INFO - 	 Train Loss: 0.189
2024-11-03 01:57 - INFO - 	 Val. Loss: 0.205
2024-11-03 01:57 - INFO - 	 ROC-AUC: 0.811
2024-11-03 01:57 - INFO - 	 PR-AUC: 0.237
2024-11-03 01:57 - INFO - 	 Recall for 0.4 precision: 0.026
2024-11-03 01:57 - INFO - 	 Best Val. Loss: 0.205
2024-11-03 01:57 - INFO - 	 Best ROC-AUC: 0.811
2024-11-03 01:57 - INFO - 	 Best PR-AUC: 0.261
2024-11-03 01:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.824
2024-11-03 01:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.144
2024-11-03 01:57 - INFO - 	 Best Recall for 0.4 precision: 0.202
2024-11-03 01:57 - INFO - ---------------------------------------------
2024-11-03 01:59 - INFO - ---------------------------------------------
2024-11-03 01:59 - INFO - Epoch: 04 | Time: 1m 42s
2024-11-03 01:59 - INFO - 	 New best val_rocauc loss was found, current best value is 0.35408
2024-11-03 01:59 - INFO - 	 Train Loss: 0.176
2024-11-03 01:59 - INFO - 	 Val. Loss: 0.192
2024-11-03 01:59 - INFO - 	 ROC-AUC: 0.804
2024-11-03 01:59 - INFO - 	 PR-AUC: 0.354
2024-11-03 01:59 - INFO - 	 Recall for 0.4 precision: 0.423
2024-11-03 01:59 - INFO - 	 Best Val. Loss: 0.192
2024-11-03 01:59 - INFO - 	 Best ROC-AUC: 0.811
2024-11-03 01:59 - INFO - 	 Best PR-AUC: 0.354
2024-11-03 01:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.824
2024-11-03 01:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:59 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 01:59 - INFO - ---------------------------------------------
2024-11-03 01:00 - INFO - ---------------------------------------------
2024-11-03 01:00 - INFO - Epoch: 05 | Time: 1m 45s
2024-11-03 01:00 - INFO - 	 Train Loss: 0.165
2024-11-03 01:00 - INFO - 	 Val. Loss: 0.175
2024-11-03 01:00 - INFO - 	 ROC-AUC: 0.810
2024-11-03 01:00 - INFO - 	 PR-AUC: 0.319
2024-11-03 01:00 - INFO - 	 Recall for 0.4 precision: 0.366
2024-11-03 01:00 - INFO - 	 Best Val. Loss: 0.175
2024-11-03 01:00 - INFO - 	 Best ROC-AUC: 0.811
2024-11-03 01:00 - INFO - 	 Best PR-AUC: 0.354
2024-11-03 01:00 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.824
2024-11-03 01:00 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:00 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 01:00 - INFO - ---------------------------------------------
2024-11-03 01:02 - INFO - ---------------------------------------------
2024-11-03 01:02 - INFO - Epoch: 06 | Time: 1m 46s
2024-11-03 01:02 - INFO - 	 Train Loss: 0.158
2024-11-03 01:02 - INFO - 	 Val. Loss: 0.166
2024-11-03 01:02 - INFO - 	 ROC-AUC: 0.822
2024-11-03 01:02 - INFO - 	 PR-AUC: 0.300
2024-11-03 01:02 - INFO - 	 Recall for 0.4 precision: 0.289
2024-11-03 01:02 - INFO - 	 Best Val. Loss: 0.166
2024-11-03 01:02 - INFO - 	 Best ROC-AUC: 0.822
2024-11-03 01:02 - INFO - 	 Best PR-AUC: 0.354
2024-11-03 01:02 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.755
2024-11-03 01:02 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:02 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 01:02 - INFO - ---------------------------------------------
2024-11-03 01:04 - INFO - ---------------------------------------------
2024-11-03 01:04 - INFO - Epoch: 07 | Time: 1m 47s
2024-11-03 01:04 - INFO - 	 Train Loss: 0.153
2024-11-03 01:04 - INFO - 	 Val. Loss: 0.160
2024-11-03 01:04 - INFO - 	 ROC-AUC: 0.837
2024-11-03 01:04 - INFO - 	 PR-AUC: 0.313
2024-11-03 01:04 - INFO - 	 Recall for 0.4 precision: 0.007
2024-11-03 01:04 - INFO - 	 Best Val. Loss: 0.160
2024-11-03 01:04 - INFO - 	 Best ROC-AUC: 0.837
2024-11-03 01:04 - INFO - 	 Best PR-AUC: 0.354
2024-11-03 01:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.760
2024-11-03 01:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.165
2024-11-03 01:04 - INFO - 	 Best Recall for 0.4 precision: 0.423
2024-11-03 01:04 - INFO - ---------------------------------------------
2024-11-03 01:09 - INFO - Fit the preprocessing pipeline
2024-11-03 01:09 - INFO - Training using device: mps
2024-11-03 01:09 - INFO - Creating generators
2024-11-03 01:09 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:09 - INFO - * Model:
2024-11-03 01:09 - INFO - * -----------
2024-11-03 01:09 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:09 - INFO - * -----------
2024-11-03 01:09 - INFO - Evaluating model based on: aucpr
2024-11-03 01:09 - INFO - Training..

2024-11-03 01:10 - INFO - ---------------------------------------------
2024-11-03 01:10 - INFO - Epoch: 01 | Time: 1m 41s
2024-11-03 01:10 - INFO - 	 New best val_rocauc loss was found, current best value is 0.17759
2024-11-03 01:10 - INFO - 	 Train Loss: 0.270
2024-11-03 01:10 - INFO - 	 Val. Loss: 0.320
2024-11-03 01:10 - INFO - 	 ROC-AUC: 0.743
2024-11-03 01:10 - INFO - 	 PR-AUC: 0.178
2024-11-03 01:10 - INFO - 	 Recall for 0.4 precision: 0.026
2024-11-03 01:10 - INFO - 	 Best Val. Loss: 0.320
2024-11-03 01:10 - INFO - 	 Best ROC-AUC: 0.743
2024-11-03 01:10 - INFO - 	 Best PR-AUC: 0.178
2024-11-03 01:10 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.763
2024-11-03 01:10 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 01:10 - INFO - 	 Best Recall for 0.4 precision: 0.026
2024-11-03 01:10 - INFO - ---------------------------------------------
2024-11-03 01:12 - INFO - ---------------------------------------------
2024-11-03 01:12 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:12 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22691
2024-11-03 01:12 - INFO - 	 Train Loss: 0.215
2024-11-03 01:12 - INFO - 	 Val. Loss: 0.291
2024-11-03 01:12 - INFO - 	 ROC-AUC: 0.769
2024-11-03 01:12 - INFO - 	 PR-AUC: 0.227
2024-11-03 01:12 - INFO - 	 Recall for 0.4 precision: 0.063
2024-11-03 01:12 - INFO - 	 Best Val. Loss: 0.291
2024-11-03 01:12 - INFO - 	 Best ROC-AUC: 0.769
2024-11-03 01:12 - INFO - 	 Best PR-AUC: 0.227
2024-11-03 01:12 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.773
2024-11-03 01:12 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.158
2024-11-03 01:12 - INFO - 	 Best Recall for 0.4 precision: 0.063
2024-11-03 01:12 - INFO - ---------------------------------------------
2024-11-03 01:14 - INFO - ---------------------------------------------
2024-11-03 01:14 - INFO - Epoch: 03 | Time: 1m 41s
2024-11-03 01:14 - INFO - 	 New best val_rocauc loss was found, current best value is 0.2524
2024-11-03 01:14 - INFO - 	 Train Loss: 0.189
2024-11-03 01:14 - INFO - 	 Val. Loss: 0.253
2024-11-03 01:14 - INFO - 	 ROC-AUC: 0.787
2024-11-03 01:14 - INFO - 	 PR-AUC: 0.252
2024-11-03 01:14 - INFO - 	 Recall for 0.4 precision: 0.111
2024-11-03 01:14 - INFO - 	 Best Val. Loss: 0.253
2024-11-03 01:14 - INFO - 	 Best ROC-AUC: 0.787
2024-11-03 01:14 - INFO - 	 Best PR-AUC: 0.252
2024-11-03 01:14 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.805
2024-11-03 01:14 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.175
2024-11-03 01:14 - INFO - 	 Best Recall for 0.4 precision: 0.111
2024-11-03 01:14 - INFO - ---------------------------------------------
2024-11-03 01:15 - INFO - ---------------------------------------------
2024-11-03 01:15 - INFO - Epoch: 04 | Time: 1m 42s
2024-11-03 01:15 - INFO - 	 New best val_rocauc loss was found, current best value is 0.33027
2024-11-03 01:15 - INFO - 	 Train Loss: 0.173
2024-11-03 01:15 - INFO - 	 Val. Loss: 0.212
2024-11-03 01:15 - INFO - 	 ROC-AUC: 0.813
2024-11-03 01:15 - INFO - 	 PR-AUC: 0.330
2024-11-03 01:15 - INFO - 	 Recall for 0.4 precision: 0.369
2024-11-03 01:15 - INFO - 	 Best Val. Loss: 0.212
2024-11-03 01:15 - INFO - 	 Best ROC-AUC: 0.813
2024-11-03 01:15 - INFO - 	 Best PR-AUC: 0.330
2024-11-03 01:15 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.797
2024-11-03 01:15 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.155
2024-11-03 01:15 - INFO - 	 Best Recall for 0.4 precision: 0.369
2024-11-03 01:15 - INFO - ---------------------------------------------
2024-11-03 01:17 - INFO - ---------------------------------------------
2024-11-03 01:17 - INFO - Epoch: 05 | Time: 1m 45s
2024-11-03 01:17 - INFO - 	 Train Loss: 0.164
2024-11-03 01:17 - INFO - 	 Val. Loss: 0.186
2024-11-03 01:17 - INFO - 	 ROC-AUC: 0.822
2024-11-03 01:17 - INFO - 	 PR-AUC: 0.324
2024-11-03 01:17 - INFO - 	 Recall for 0.4 precision: 0.420
2024-11-03 01:17 - INFO - 	 Best Val. Loss: 0.186
2024-11-03 01:17 - INFO - 	 Best ROC-AUC: 0.822
2024-11-03 01:17 - INFO - 	 Best PR-AUC: 0.330
2024-11-03 01:17 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.798
2024-11-03 01:17 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.155
2024-11-03 01:17 - INFO - 	 Best Recall for 0.4 precision: 0.420
2024-11-03 01:17 - INFO - ---------------------------------------------
2024-11-03 01:19 - INFO - ---------------------------------------------
2024-11-03 01:19 - INFO - Epoch: 06 | Time: 1m 45s
2024-11-03 01:19 - INFO - 	 New best val_rocauc loss was found, current best value is 0.34073
2024-11-03 01:19 - INFO - 	 Train Loss: 0.157
2024-11-03 01:19 - INFO - 	 Val. Loss: 0.173
2024-11-03 01:19 - INFO - 	 ROC-AUC: 0.842
2024-11-03 01:19 - INFO - 	 PR-AUC: 0.341
2024-11-03 01:19 - INFO - 	 Recall for 0.4 precision: 0.374
2024-11-03 01:19 - INFO - 	 Best Val. Loss: 0.173
2024-11-03 01:19 - INFO - 	 Best ROC-AUC: 0.842
2024-11-03 01:19 - INFO - 	 Best PR-AUC: 0.341
2024-11-03 01:19 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.802
2024-11-03 01:19 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.159
2024-11-03 01:19 - INFO - 	 Best Recall for 0.4 precision: 0.420
2024-11-03 01:19 - INFO - ---------------------------------------------
2024-11-03 01:21 - INFO - ---------------------------------------------
2024-11-03 01:21 - INFO - Epoch: 07 | Time: 1m 46s
2024-11-03 01:21 - INFO - 	 New best val_rocauc loss was found, current best value is 0.34226
2024-11-03 01:21 - INFO - 	 Train Loss: 0.153
2024-11-03 01:21 - INFO - 	 Val. Loss: 0.167
2024-11-03 01:21 - INFO - 	 ROC-AUC: 0.856
2024-11-03 01:21 - INFO - 	 PR-AUC: 0.342
2024-11-03 01:21 - INFO - 	 Recall for 0.4 precision: 0.433
2024-11-03 01:21 - INFO - 	 Best Val. Loss: 0.167
2024-11-03 01:21 - INFO - 	 Best ROC-AUC: 0.856
2024-11-03 01:21 - INFO - 	 Best PR-AUC: 0.342
2024-11-03 01:21 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.827
2024-11-03 01:21 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.181
2024-11-03 01:21 - INFO - 	 Best Recall for 0.4 precision: 0.433
2024-11-03 01:21 - INFO - ---------------------------------------------
2024-11-03 01:23 - INFO - ---------------------------------------------
2024-11-03 01:23 - INFO - Epoch: 08 | Time: 1m 47s
2024-11-03 01:23 - INFO - 	 Train Loss: 0.149
2024-11-03 01:23 - INFO - 	 Val. Loss: 0.178
2024-11-03 01:23 - INFO - 	 ROC-AUC: 0.856
2024-11-03 01:23 - INFO - 	 PR-AUC: 0.326
2024-11-03 01:23 - INFO - 	 Recall for 0.4 precision: 0.449
2024-11-03 01:23 - INFO - 	 Best Val. Loss: 0.167
2024-11-03 01:23 - INFO - 	 Best ROC-AUC: 0.856
2024-11-03 01:23 - INFO - 	 Best PR-AUC: 0.342
2024-11-03 01:23 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.817
2024-11-03 01:23 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.181
2024-11-03 01:23 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 01:23 - INFO - ---------------------------------------------
2024-11-03 01:24 - INFO - ---------------------------------------------
2024-11-03 01:24 - INFO - Epoch: 09 | Time: 1m 47s
2024-11-03 01:24 - INFO - 	 New best val_rocauc loss was found, current best value is 0.39174
2024-11-03 01:24 - INFO - 	 Train Loss: 0.148
2024-11-03 01:24 - INFO - 	 Val. Loss: 0.158
2024-11-03 01:24 - INFO - 	 ROC-AUC: 0.866
2024-11-03 01:24 - INFO - 	 PR-AUC: 0.392
2024-11-03 01:24 - INFO - 	 Recall for 0.4 precision: 0.013
2024-11-03 01:24 - INFO - 	 Best Val. Loss: 0.158
2024-11-03 01:24 - INFO - 	 Best ROC-AUC: 0.866
2024-11-03 01:24 - INFO - 	 Best PR-AUC: 0.392
2024-11-03 01:24 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.814
2024-11-03 01:24 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.162
2024-11-03 01:24 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 01:24 - INFO - ---------------------------------------------
2024-11-03 01:26 - INFO - ---------------------------------------------
2024-11-03 01:26 - INFO - Epoch: 10 | Time: 1m 47s
2024-11-03 01:26 - INFO - 	 Train Loss: 0.147
2024-11-03 01:26 - INFO - 	 Val. Loss: 0.151
2024-11-03 01:26 - INFO - 	 ROC-AUC: 0.875
2024-11-03 01:26 - INFO - 	 PR-AUC: 0.366
2024-11-03 01:26 - INFO - 	 Recall for 0.4 precision: 0.431
2024-11-03 01:26 - INFO - 	 Best Val. Loss: 0.151
2024-11-03 01:26 - INFO - 	 Best ROC-AUC: 0.875
2024-11-03 01:26 - INFO - 	 Best PR-AUC: 0.392
2024-11-03 01:26 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.818
2024-11-03 01:26 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.162
2024-11-03 01:26 - INFO - 	 Best Recall for 0.4 precision: 0.449
2024-11-03 01:26 - INFO - ---------------------------------------------
2024-11-03 01:29 - INFO - Fit the preprocessing pipeline
2024-11-03 01:29 - INFO - Training using device: mps
2024-11-03 01:29 - INFO - Creating generators
2024-11-03 01:29 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:29 - INFO - * Model:
2024-11-03 01:29 - INFO - * -----------
2024-11-03 01:29 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:29 - INFO - * -----------
2024-11-03 01:29 - INFO - Evaluating model based on: aucpr
2024-11-03 01:29 - INFO - Training..

2024-11-03 01:30 - INFO - ---------------------------------------------
2024-11-03 01:30 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-03 01:30 - INFO - 	 New best val_rocauc loss was found, current best value is 0.19256
2024-11-03 01:30 - INFO - 	 Train Loss: 0.264
2024-11-03 01:30 - INFO - 	 Val. Loss: 0.326
2024-11-03 01:30 - INFO - 	 ROC-AUC: 0.760
2024-11-03 01:30 - INFO - 	 PR-AUC: 0.193
2024-11-03 01:30 - INFO - 	 Recall for 0.4 precision: 0.195
2024-11-03 01:30 - INFO - 	 Best Val. Loss: 0.326
2024-11-03 01:30 - INFO - 	 Best ROC-AUC: 0.760
2024-11-03 01:30 - INFO - 	 Best PR-AUC: 0.193
2024-11-03 01:30 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.775
2024-11-03 01:30 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.188
2024-11-03 01:30 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-03 01:30 - INFO - ---------------------------------------------
2024-11-03 01:32 - INFO - ---------------------------------------------
2024-11-03 01:32 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:32 - INFO - 	 Train Loss: 0.209
2024-11-03 01:32 - INFO - 	 Val. Loss: 0.291
2024-11-03 01:32 - INFO - 	 ROC-AUC: 0.757
2024-11-03 01:32 - INFO - 	 PR-AUC: 0.153
2024-11-03 01:32 - INFO - 	 Recall for 0.4 precision: 0.117
2024-11-03 01:32 - INFO - 	 Best Val. Loss: 0.291
2024-11-03 01:32 - INFO - 	 Best ROC-AUC: 0.760
2024-11-03 01:32 - INFO - 	 Best PR-AUC: 0.193
2024-11-03 01:32 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.775
2024-11-03 01:32 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.188
2024-11-03 01:32 - INFO - 	 Best Recall for 0.4 precision: 0.195
2024-11-03 01:32 - INFO - ---------------------------------------------
2024-11-03 01:34 - INFO - ---------------------------------------------
2024-11-03 01:34 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-03 01:34 - INFO - 	 New best val_rocauc loss was found, current best value is 0.28407
2024-11-03 01:34 - INFO - 	 Train Loss: 0.190
2024-11-03 01:34 - INFO - 	 Val. Loss: 0.257
2024-11-03 01:34 - INFO - 	 ROC-AUC: 0.797
2024-11-03 01:34 - INFO - 	 PR-AUC: 0.284
2024-11-03 01:34 - INFO - 	 Recall for 0.4 precision: 0.322
2024-11-03 01:34 - INFO - 	 Best Val. Loss: 0.257
2024-11-03 01:34 - INFO - 	 Best ROC-AUC: 0.797
2024-11-03 01:34 - INFO - 	 Best PR-AUC: 0.284
2024-11-03 01:34 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.774
2024-11-03 01:34 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.143
2024-11-03 01:34 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:34 - INFO - ---------------------------------------------
2024-11-03 01:36 - INFO - ---------------------------------------------
2024-11-03 01:36 - INFO - Epoch: 04 | Time: 1m 42s
2024-11-03 01:36 - INFO - 	 Train Loss: 0.175
2024-11-03 01:36 - INFO - 	 Val. Loss: 0.244
2024-11-03 01:36 - INFO - 	 ROC-AUC: 0.812
2024-11-03 01:36 - INFO - 	 PR-AUC: 0.240
2024-11-03 01:36 - INFO - 	 Recall for 0.4 precision: 0.247
2024-11-03 01:36 - INFO - 	 Best Val. Loss: 0.244
2024-11-03 01:36 - INFO - 	 Best ROC-AUC: 0.812
2024-11-03 01:36 - INFO - 	 Best PR-AUC: 0.284
2024-11-03 01:36 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-03 01:36 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.143
2024-11-03 01:36 - INFO - 	 Best Recall for 0.4 precision: 0.322
2024-11-03 01:36 - INFO - ---------------------------------------------
2024-11-03 01:37 - INFO - ---------------------------------------------
2024-11-03 01:37 - INFO - Epoch: 05 | Time: 1m 41s
2024-11-03 01:37 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31504
2024-11-03 01:37 - INFO - 	 Train Loss: 0.167
2024-11-03 01:37 - INFO - 	 Val. Loss: 0.184
2024-11-03 01:37 - INFO - 	 ROC-AUC: 0.832
2024-11-03 01:37 - INFO - 	 PR-AUC: 0.315
2024-11-03 01:37 - INFO - 	 Recall for 0.4 precision: 0.379
2024-11-03 01:37 - INFO - 	 Best Val. Loss: 0.184
2024-11-03 01:37 - INFO - 	 Best ROC-AUC: 0.832
2024-11-03 01:37 - INFO - 	 Best PR-AUC: 0.315
2024-11-03 01:37 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.761
2024-11-03 01:37 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.149
2024-11-03 01:37 - INFO - 	 Best Recall for 0.4 precision: 0.379
2024-11-03 01:37 - INFO - ---------------------------------------------
2024-11-03 01:39 - INFO - ---------------------------------------------
2024-11-03 01:39 - INFO - Epoch: 06 | Time: 1m 43s
2024-11-03 01:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.39433
2024-11-03 01:39 - INFO - 	 Train Loss: 0.159
2024-11-03 01:39 - INFO - 	 Val. Loss: 0.163
2024-11-03 01:39 - INFO - 	 ROC-AUC: 0.864
2024-11-03 01:39 - INFO - 	 PR-AUC: 0.394
2024-11-03 01:39 - INFO - 	 Recall for 0.4 precision: 0.416
2024-11-03 01:39 - INFO - 	 Best Val. Loss: 0.163
2024-11-03 01:39 - INFO - 	 Best ROC-AUC: 0.864
2024-11-03 01:39 - INFO - 	 Best PR-AUC: 0.394
2024-11-03 01:39 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.789
2024-11-03 01:39 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.166
2024-11-03 01:39 - INFO - 	 Best Recall for 0.4 precision: 0.416
2024-11-03 01:39 - INFO - ---------------------------------------------
2024-11-03 01:41 - INFO - ---------------------------------------------
2024-11-03 01:41 - INFO - Epoch: 07 | Time: 1m 47s
2024-11-03 01:41 - INFO - 	 Train Loss: 0.153
2024-11-03 01:41 - INFO - 	 Val. Loss: 0.145
2024-11-03 01:41 - INFO - 	 ROC-AUC: 0.886
2024-11-03 01:41 - INFO - 	 PR-AUC: 0.338
2024-11-03 01:41 - INFO - 	 Recall for 0.4 precision: 0.485
2024-11-03 01:41 - INFO - 	 Best Val. Loss: 0.145
2024-11-03 01:41 - INFO - 	 Best ROC-AUC: 0.886
2024-11-03 01:41 - INFO - 	 Best PR-AUC: 0.394
2024-11-03 01:41 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.856
2024-11-03 01:41 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.166
2024-11-03 01:41 - INFO - 	 Best Recall for 0.4 precision: 0.485
2024-11-03 01:41 - INFO - ---------------------------------------------
2024-11-03 01:43 - INFO - ---------------------------------------------
2024-11-03 01:43 - INFO - Epoch: 08 | Time: 1m 48s
2024-11-03 01:43 - INFO - 	 New best val_rocauc loss was found, current best value is 0.42679
2024-11-03 01:43 - INFO - 	 Train Loss: 0.141
2024-11-03 01:43 - INFO - 	 Val. Loss: 0.132
2024-11-03 01:43 - INFO - 	 ROC-AUC: 0.925
2024-11-03 01:43 - INFO - 	 PR-AUC: 0.427
2024-11-03 01:43 - INFO - 	 Recall for 0.4 precision: 0.514
2024-11-03 01:43 - INFO - 	 Best Val. Loss: 0.132
2024-11-03 01:43 - INFO - 	 Best ROC-AUC: 0.925
2024-11-03 01:43 - INFO - 	 Best PR-AUC: 0.427
2024-11-03 01:43 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.888
2024-11-03 01:43 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.271
2024-11-03 01:43 - INFO - 	 Best Recall for 0.4 precision: 0.514
2024-11-03 01:43 - INFO - ---------------------------------------------
2024-11-03 01:44 - INFO - ---------------------------------------------
2024-11-03 01:44 - INFO - Epoch: 09 | Time: 1m 47s
2024-11-03 01:44 - INFO - 	 New best val_rocauc loss was found, current best value is 0.55733
2024-11-03 01:44 - INFO - 	 Train Loss: 0.132
2024-11-03 01:44 - INFO - 	 Val. Loss: 0.121
2024-11-03 01:44 - INFO - 	 ROC-AUC: 0.947
2024-11-03 01:44 - INFO - 	 PR-AUC: 0.557
2024-11-03 01:44 - INFO - 	 Recall for 0.4 precision: 0.702
2024-11-03 01:44 - INFO - 	 Best Val. Loss: 0.121
2024-11-03 01:44 - INFO - 	 Best ROC-AUC: 0.947
2024-11-03 01:44 - INFO - 	 Best PR-AUC: 0.557
2024-11-03 01:44 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.928
2024-11-03 01:44 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.351
2024-11-03 01:44 - INFO - 	 Best Recall for 0.4 precision: 0.702
2024-11-03 01:44 - INFO - ---------------------------------------------
2024-11-03 01:46 - INFO - ---------------------------------------------
2024-11-03 01:46 - INFO - Epoch: 10 | Time: 1m 47s
2024-11-03 01:46 - INFO - 	 Train Loss: 0.123
2024-11-03 01:46 - INFO - 	 Val. Loss: 0.145
2024-11-03 01:46 - INFO - 	 ROC-AUC: 0.930
2024-11-03 01:46 - INFO - 	 PR-AUC: 0.378
2024-11-03 01:46 - INFO - 	 Recall for 0.4 precision: 0.589
2024-11-03 01:46 - INFO - 	 Best Val. Loss: 0.121
2024-11-03 01:46 - INFO - 	 Best ROC-AUC: 0.947
2024-11-03 01:46 - INFO - 	 Best PR-AUC: 0.557
2024-11-03 01:46 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.928
2024-11-03 01:46 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.351
2024-11-03 01:46 - INFO - 	 Best Recall for 0.4 precision: 0.702
2024-11-03 01:46 - INFO - ---------------------------------------------
2024-11-03 01:49 - INFO - Fit the preprocessing pipeline
2024-11-03 01:49 - INFO - Training using device: mps
2024-11-03 01:49 - INFO - Creating generators
2024-11-03 01:49 - INFO - The model has 651,257 trainable parameters
2024-11-03 01:49 - INFO - * Model:
2024-11-03 01:49 - INFO - * -----------
2024-11-03 01:49 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-11-03 01:49 - INFO - * -----------
2024-11-03 01:49 - INFO - Evaluating model based on: aucpr
2024-11-03 01:49 - INFO - Training..

2024-11-03 01:50 - INFO - ---------------------------------------------
2024-11-03 01:50 - INFO - Epoch: 01 | Time: 1m 40s
2024-11-03 01:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.22578
2024-11-03 01:50 - INFO - 	 Train Loss: 0.256
2024-11-03 01:50 - INFO - 	 Val. Loss: 0.293
2024-11-03 01:50 - INFO - 	 ROC-AUC: 0.747
2024-11-03 01:50 - INFO - 	 PR-AUC: 0.226
2024-11-03 01:50 - INFO - 	 Recall for 0.4 precision: 0.172
2024-11-03 01:50 - INFO - 	 Best Val. Loss: 0.293
2024-11-03 01:50 - INFO - 	 Best ROC-AUC: 0.747
2024-11-03 01:50 - INFO - 	 Best PR-AUC: 0.226
2024-11-03 01:50 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.730
2024-11-03 01:50 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.122
2024-11-03 01:50 - INFO - 	 Best Recall for 0.4 precision: 0.172
2024-11-03 01:50 - INFO - ---------------------------------------------
2024-11-03 01:52 - INFO - ---------------------------------------------
2024-11-03 01:52 - INFO - Epoch: 02 | Time: 1m 41s
2024-11-03 01:52 - INFO - 	 Train Loss: 0.211
2024-11-03 01:52 - INFO - 	 Val. Loss: 0.239
2024-11-03 01:52 - INFO - 	 ROC-AUC: 0.766
2024-11-03 01:52 - INFO - 	 PR-AUC: 0.207
2024-11-03 01:52 - INFO - 	 Recall for 0.4 precision: 0.036
2024-11-03 01:52 - INFO - 	 Best Val. Loss: 0.239
2024-11-03 01:52 - INFO - 	 Best ROC-AUC: 0.766
2024-11-03 01:52 - INFO - 	 Best PR-AUC: 0.226
2024-11-03 01:52 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.733
2024-11-03 01:52 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.122
2024-11-03 01:52 - INFO - 	 Best Recall for 0.4 precision: 0.172
2024-11-03 01:52 - INFO - ---------------------------------------------
2024-11-03 01:54 - INFO - ---------------------------------------------
2024-11-03 01:54 - INFO - Epoch: 03 | Time: 1m 42s
2024-11-03 01:54 - INFO - 	 New best val_rocauc loss was found, current best value is 0.24532
2024-11-03 01:54 - INFO - 	 Train Loss: 0.185
2024-11-03 01:54 - INFO - 	 Val. Loss: 0.212
2024-11-03 01:54 - INFO - 	 ROC-AUC: 0.791
2024-11-03 01:54 - INFO - 	 PR-AUC: 0.245
2024-11-03 01:54 - INFO - 	 Recall for 0.4 precision: 0.189
2024-11-03 01:54 - INFO - 	 Best Val. Loss: 0.212
2024-11-03 01:54 - INFO - 	 Best ROC-AUC: 0.791
2024-11-03 01:54 - INFO - 	 Best PR-AUC: 0.245
2024-11-03 01:54 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-03 01:54 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.155
2024-11-03 01:54 - INFO - 	 Best Recall for 0.4 precision: 0.189
2024-11-03 01:54 - INFO - ---------------------------------------------
2024-11-03 01:56 - INFO - ---------------------------------------------
2024-11-03 01:56 - INFO - Epoch: 04 | Time: 1m 42s
2024-11-03 01:56 - INFO - 	 Train Loss: 0.171
2024-11-03 01:56 - INFO - 	 Val. Loss: 0.201
2024-11-03 01:56 - INFO - 	 ROC-AUC: 0.789
2024-11-03 01:56 - INFO - 	 PR-AUC: 0.237
2024-11-03 01:56 - INFO - 	 Recall for 0.4 precision: 0.234
2024-11-03 01:56 - INFO - 	 Best Val. Loss: 0.201
2024-11-03 01:56 - INFO - 	 Best ROC-AUC: 0.791
2024-11-03 01:56 - INFO - 	 Best PR-AUC: 0.245
2024-11-03 01:56 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.748
2024-11-03 01:56 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.155
2024-11-03 01:56 - INFO - 	 Best Recall for 0.4 precision: 0.234
2024-11-03 01:56 - INFO - ---------------------------------------------
2024-11-03 01:57 - INFO - ---------------------------------------------
2024-11-03 01:57 - INFO - Epoch: 05 | Time: 1m 42s
2024-11-03 01:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.25197
2024-11-03 01:57 - INFO - 	 Train Loss: 0.163
2024-11-03 01:57 - INFO - 	 Val. Loss: 0.185
2024-11-03 01:57 - INFO - 	 ROC-AUC: 0.818
2024-11-03 01:57 - INFO - 	 PR-AUC: 0.252
2024-11-03 01:57 - INFO - 	 Recall for 0.4 precision: 0.215
2024-11-03 01:57 - INFO - 	 Best Val. Loss: 0.185
2024-11-03 01:57 - INFO - 	 Best ROC-AUC: 0.818
2024-11-03 01:57 - INFO - 	 Best PR-AUC: 0.252
2024-11-03 01:57 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.785
2024-11-03 01:57 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.176
2024-11-03 01:57 - INFO - 	 Best Recall for 0.4 precision: 0.234
2024-11-03 01:57 - INFO - ---------------------------------------------
2024-11-03 01:59 - INFO - ---------------------------------------------
2024-11-03 01:59 - INFO - Epoch: 06 | Time: 1m 44s
2024-11-03 01:59 - INFO - 	 Train Loss: 0.159
2024-11-03 01:59 - INFO - 	 Val. Loss: 0.190
2024-11-03 01:59 - INFO - 	 ROC-AUC: 0.815
2024-11-03 01:59 - INFO - 	 PR-AUC: 0.211
2024-11-03 01:59 - INFO - 	 Recall for 0.4 precision: 0.033
2024-11-03 01:59 - INFO - 	 Best Val. Loss: 0.185
2024-11-03 01:59 - INFO - 	 Best ROC-AUC: 0.818
2024-11-03 01:59 - INFO - 	 Best PR-AUC: 0.252
2024-11-03 01:59 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.785
2024-11-03 01:59 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.176
2024-11-03 01:59 - INFO - 	 Best Recall for 0.4 precision: 0.234
2024-11-03 01:59 - INFO - ---------------------------------------------
2024-11-03 02:01 - INFO - ---------------------------------------------
2024-11-03 02:01 - INFO - Epoch: 07 | Time: 1m 44s
2024-11-03 02:01 - INFO - 	 Train Loss: 0.152
2024-11-03 02:01 - INFO - 	 Val. Loss: 0.166
2024-11-03 02:01 - INFO - 	 ROC-AUC: 0.769
2024-11-03 02:01 - INFO - 	 PR-AUC: 0.218
2024-11-03 02:01 - INFO - 	 Recall for 0.4 precision: 0.137
2024-11-03 02:01 - INFO - 	 Best Val. Loss: 0.166
2024-11-03 02:01 - INFO - 	 Best ROC-AUC: 0.818
2024-11-03 02:01 - INFO - 	 Best PR-AUC: 0.252
2024-11-03 02:01 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.785
2024-11-03 02:01 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.176
2024-11-03 02:01 - INFO - 	 Best Recall for 0.4 precision: 0.234
2024-11-03 02:01 - INFO - ---------------------------------------------
2024-11-03 02:03 - INFO - ---------------------------------------------
2024-11-03 02:03 - INFO - Epoch: 08 | Time: 1m 44s
2024-11-03 02:03 - INFO - 	 New best val_rocauc loss was found, current best value is 0.31031
2024-11-03 02:03 - INFO - 	 Train Loss: 0.147
2024-11-03 02:03 - INFO - 	 Val. Loss: 0.160
2024-11-03 02:03 - INFO - 	 ROC-AUC: 0.878
2024-11-03 02:03 - INFO - 	 PR-AUC: 0.310
2024-11-03 02:03 - INFO - 	 Recall for 0.4 precision: 0.156
2024-11-03 02:03 - INFO - 	 Best Val. Loss: 0.160
2024-11-03 02:03 - INFO - 	 Best ROC-AUC: 0.878
2024-11-03 02:03 - INFO - 	 Best PR-AUC: 0.310
2024-11-03 02:03 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.800
2024-11-03 02:03 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.172
2024-11-03 02:03 - INFO - 	 Best Recall for 0.4 precision: 0.234
2024-11-03 02:03 - INFO - ---------------------------------------------
2024-11-03 02:04 - INFO - ---------------------------------------------
2024-11-03 02:04 - INFO - Epoch: 09 | Time: 1m 45s
2024-11-03 02:04 - INFO - 	 New best val_rocauc loss was found, current best value is 0.32632
2024-11-03 02:04 - INFO - 	 Train Loss: 0.140
2024-11-03 02:04 - INFO - 	 Val. Loss: 0.154
2024-11-03 02:04 - INFO - 	 ROC-AUC: 0.893
2024-11-03 02:04 - INFO - 	 PR-AUC: 0.326
2024-11-03 02:04 - INFO - 	 Recall for 0.4 precision: 0.341
2024-11-03 02:04 - INFO - 	 Best Val. Loss: 0.154
2024-11-03 02:04 - INFO - 	 Best ROC-AUC: 0.893
2024-11-03 02:04 - INFO - 	 Best PR-AUC: 0.326
2024-11-03 02:04 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.874
2024-11-03 02:04 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.222
2024-11-03 02:04 - INFO - 	 Best Recall for 0.4 precision: 0.341
2024-11-03 02:04 - INFO - ---------------------------------------------
2024-11-03 02:06 - INFO - ---------------------------------------------
2024-11-03 02:06 - INFO - Epoch: 10 | Time: 1m 46s
2024-11-03 02:06 - INFO - 	 Train Loss: 0.134
2024-11-03 02:06 - INFO - 	 Val. Loss: 0.158
2024-11-03 02:06 - INFO - 	 ROC-AUC: 0.900
2024-11-03 02:06 - INFO - 	 PR-AUC: 0.271
2024-11-03 02:06 - INFO - 	 Recall for 0.4 precision: 0.156
2024-11-03 02:06 - INFO - 	 Best Val. Loss: 0.154
2024-11-03 02:06 - INFO - 	 Best ROC-AUC: 0.900
2024-11-03 02:06 - INFO - 	 Best PR-AUC: 0.326
2024-11-03 02:06 - INFO - 	 Test-ROC-AUC under Best Validation ROC-AUC: 0.863
2024-11-03 02:06 - INFO - 	 Test-PR-AUC under Best Validation Best PR-AUC: 0.222
2024-11-03 02:06 - INFO - 	 Best Recall for 0.4 precision: 0.341
2024-11-03 02:06 - INFO - ---------------------------------------------
