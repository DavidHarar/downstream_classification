2024-01-10 22:20 - INFO - Fit the preprocessing pipeline
2024-01-10 22:20 - INFO - Training using device: cuda
2024-01-10 22:20 - INFO - Creating generators
2024-01-10 22:20 - INFO - The model has 651,257 trainable parameters
2024-01-10 22:20 - INFO - * Model:
2024-01-10 22:20 - INFO - * -----------
2024-01-10 22:20 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-10 22:20 - INFO - * -----------
2024-01-10 22:20 - INFO - Evaluating model based on: rocauc
2024-01-10 22:20 - INFO - Training..

2024-01-10 22:21 - INFO - Fit the preprocessing pipeline
2024-01-10 22:21 - INFO - Training using device: cuda
2024-01-10 22:21 - INFO - Creating generators
2024-01-10 22:21 - INFO - The model has 651,257 trainable parameters
2024-01-10 22:21 - INFO - * Model:
2024-01-10 22:21 - INFO - * -----------
2024-01-10 22:21 - INFO - DownstreamInception(
  (conv1): ConvBlock(
    (conv): Conv1d(12, 64, kernel_size=(7,), stride=(2,), padding=(3,))
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv2): ConvBlock(
    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (inception3a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(256, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4a): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(480, 192, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 96, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(96, 208, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(480, 16, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(16, 48, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(480, 64, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): InceptionBlock(
    (branch1): ConvBlock(
      (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 112, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(112, 32, kernel_size=(3,), stride=(1,), padding=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): ConvBlock(
        (conv): Conv1d(512, 24, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvBlock(
        (conv): Conv1d(24, 64, kernel_size=(5,), stride=(1,), padding=(2,))
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
      (1): ConvBlock(
        (conv): Conv1d(512, 32, kernel_size=(1,), stride=(1,))
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=8480, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
2024-01-10 22:21 - INFO - * -----------
2024-01-10 22:21 - INFO - Evaluating model based on: rocauc
2024-01-10 22:21 - INFO - Training..

2024-01-10 22:27 - INFO - ---------------------------------------------
2024-01-10 22:27 - INFO - Epoch: 01 | Time: 6m 13s
2024-01-10 22:27 - INFO - 	 New best val_rocauc loss was found, current best value is 0.58605
2024-01-10 22:27 - INFO - 	 Train Loss: 0.571
2024-01-10 22:27 - INFO - 	 Val. Loss: 0.548
2024-01-10 22:27 - INFO - 	 ROC-AUC: 0.586
2024-01-10 22:27 - INFO - 	 PR-AUC: 0.320
2024-01-10 22:27 - INFO - 	 Recall for 0.4 precision: 0.133
2024-01-10 22:27 - INFO - 	 Best Val. Loss: 0.548
2024-01-10 22:27 - INFO - 	 Best ROC-AUC: 0.586
2024-01-10 22:27 - INFO - 	 Best PR-AUC: 0.320
2024-01-10 22:27 - INFO - 	 Best Recall for 0.4 precision: 0.133
2024-01-10 22:27 - INFO - ---------------------------------------------
2024-01-10 22:34 - INFO - ---------------------------------------------
2024-01-10 22:34 - INFO - Epoch: 02 | Time: 6m 15s
2024-01-10 22:34 - INFO - 	 New best val_rocauc loss was found, current best value is 0.69999
2024-01-10 22:34 - INFO - 	 Train Loss: 0.533
2024-01-10 22:34 - INFO - 	 Val. Loss: 0.510
2024-01-10 22:34 - INFO - 	 ROC-AUC: 0.700
2024-01-10 22:34 - INFO - 	 PR-AUC: 0.424
2024-01-10 22:34 - INFO - 	 Recall for 0.4 precision: 0.549
2024-01-10 22:34 - INFO - 	 Best Val. Loss: 0.510
2024-01-10 22:34 - INFO - 	 Best ROC-AUC: 0.700
2024-01-10 22:34 - INFO - 	 Best PR-AUC: 0.424
2024-01-10 22:34 - INFO - 	 Best Recall for 0.4 precision: 0.549
2024-01-10 22:34 - INFO - ---------------------------------------------
2024-01-10 22:39 - INFO - ---------------------------------------------
2024-01-10 22:39 - INFO - Epoch: 03 | Time: 5m 53s
2024-01-10 22:39 - INFO - 	 New best val_rocauc loss was found, current best value is 0.7145
2024-01-10 22:39 - INFO - 	 Train Loss: 0.505
2024-01-10 22:39 - INFO - 	 Val. Loss: 0.502
2024-01-10 22:39 - INFO - 	 ROC-AUC: 0.714
2024-01-10 22:39 - INFO - 	 PR-AUC: 0.439
2024-01-10 22:39 - INFO - 	 Recall for 0.4 precision: 0.598
2024-01-10 22:39 - INFO - 	 Best Val. Loss: 0.502
2024-01-10 22:39 - INFO - 	 Best ROC-AUC: 0.714
2024-01-10 22:39 - INFO - 	 Best PR-AUC: 0.439
2024-01-10 22:39 - INFO - 	 Best Recall for 0.4 precision: 0.598
2024-01-10 22:39 - INFO - ---------------------------------------------
2024-01-10 22:45 - INFO - ---------------------------------------------
2024-01-10 22:45 - INFO - Epoch: 04 | Time: 5m 50s
2024-01-10 22:45 - INFO - 	 New best val_rocauc loss was found, current best value is 0.71759
2024-01-10 22:45 - INFO - 	 Train Loss: 0.496
2024-01-10 22:45 - INFO - 	 Val. Loss: 0.500
2024-01-10 22:45 - INFO - 	 ROC-AUC: 0.718
2024-01-10 22:45 - INFO - 	 PR-AUC: 0.435
2024-01-10 22:45 - INFO - 	 Recall for 0.4 precision: 0.609
2024-01-10 22:45 - INFO - 	 Best Val. Loss: 0.500
2024-01-10 22:45 - INFO - 	 Best ROC-AUC: 0.718
2024-01-10 22:45 - INFO - 	 Best PR-AUC: 0.439
2024-01-10 22:45 - INFO - 	 Best Recall for 0.4 precision: 0.609
2024-01-10 22:45 - INFO - ---------------------------------------------
2024-01-10 22:50 - INFO - ---------------------------------------------
2024-01-10 22:50 - INFO - Epoch: 05 | Time: 5m 0s
2024-01-10 22:50 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72104
2024-01-10 22:50 - INFO - 	 Train Loss: 0.491
2024-01-10 22:50 - INFO - 	 Val. Loss: 0.498
2024-01-10 22:50 - INFO - 	 ROC-AUC: 0.721
2024-01-10 22:50 - INFO - 	 PR-AUC: 0.434
2024-01-10 22:50 - INFO - 	 Recall for 0.4 precision: 0.632
2024-01-10 22:50 - INFO - 	 Best Val. Loss: 0.498
2024-01-10 22:50 - INFO - 	 Best ROC-AUC: 0.721
2024-01-10 22:50 - INFO - 	 Best PR-AUC: 0.439
2024-01-10 22:50 - INFO - 	 Best Recall for 0.4 precision: 0.632
2024-01-10 22:50 - INFO - ---------------------------------------------
2024-01-10 22:52 - INFO - ---------------------------------------------
2024-01-10 22:52 - INFO - Epoch: 06 | Time: 1m 13s
2024-01-10 22:52 - INFO - 	 Train Loss: 0.489
2024-01-10 22:52 - INFO - 	 Val. Loss: 0.499
2024-01-10 22:52 - INFO - 	 ROC-AUC: 0.720
2024-01-10 22:52 - INFO - 	 PR-AUC: 0.432
2024-01-10 22:52 - INFO - 	 Recall for 0.4 precision: 0.619
2024-01-10 22:52 - INFO - 	 Best Val. Loss: 0.498
2024-01-10 22:52 - INFO - 	 Best ROC-AUC: 0.721
2024-01-10 22:52 - INFO - 	 Best PR-AUC: 0.439
2024-01-10 22:52 - INFO - 	 Best Recall for 0.4 precision: 0.632
2024-01-10 22:52 - INFO - ---------------------------------------------
2024-01-10 22:55 - INFO - ---------------------------------------------
2024-01-10 22:55 - INFO - Epoch: 07 | Time: 3m 36s
2024-01-10 22:55 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72494
2024-01-10 22:55 - INFO - 	 Train Loss: 0.486
2024-01-10 22:55 - INFO - 	 Val. Loss: 0.500
2024-01-10 22:55 - INFO - 	 ROC-AUC: 0.725
2024-01-10 22:55 - INFO - 	 PR-AUC: 0.438
2024-01-10 22:55 - INFO - 	 Recall for 0.4 precision: 0.638
2024-01-10 22:55 - INFO - 	 Best Val. Loss: 0.498
2024-01-10 22:55 - INFO - 	 Best ROC-AUC: 0.725
2024-01-10 22:55 - INFO - 	 Best PR-AUC: 0.439
2024-01-10 22:55 - INFO - 	 Best Recall for 0.4 precision: 0.638
2024-01-10 22:55 - INFO - ---------------------------------------------
2024-01-10 22:57 - INFO - ---------------------------------------------
2024-01-10 22:57 - INFO - Epoch: 08 | Time: 1m 35s
2024-01-10 22:57 - INFO - 	 New best val_rocauc loss was found, current best value is 0.72783
2024-01-10 22:57 - INFO - 	 Train Loss: 0.485
2024-01-10 22:57 - INFO - 	 Val. Loss: 0.495
2024-01-10 22:57 - INFO - 	 ROC-AUC: 0.728
2024-01-10 22:57 - INFO - 	 PR-AUC: 0.445
2024-01-10 22:57 - INFO - 	 Recall for 0.4 precision: 0.653
2024-01-10 22:57 - INFO - 	 Best Val. Loss: 0.495
2024-01-10 22:57 - INFO - 	 Best ROC-AUC: 0.728
2024-01-10 22:57 - INFO - 	 Best PR-AUC: 0.445
2024-01-10 22:57 - INFO - 	 Best Recall for 0.4 precision: 0.653
2024-01-10 22:57 - INFO - ---------------------------------------------
2024-01-10 22:58 - INFO - ---------------------------------------------
2024-01-10 22:58 - INFO - Epoch: 09 | Time: 1m 16s
2024-01-10 22:58 - INFO - 	 Train Loss: 0.483
2024-01-10 22:58 - INFO - 	 Val. Loss: 0.496
2024-01-10 22:58 - INFO - 	 ROC-AUC: 0.725
2024-01-10 22:58 - INFO - 	 PR-AUC: 0.439
2024-01-10 22:58 - INFO - 	 Recall for 0.4 precision: 0.626
2024-01-10 22:58 - INFO - 	 Best Val. Loss: 0.495
2024-01-10 22:58 - INFO - 	 Best ROC-AUC: 0.728
2024-01-10 22:58 - INFO - 	 Best PR-AUC: 0.445
2024-01-10 22:58 - INFO - 	 Best Recall for 0.4 precision: 0.653
2024-01-10 22:58 - INFO - ---------------------------------------------
2024-01-10 22:59 - INFO - ---------------------------------------------
2024-01-10 22:59 - INFO - Epoch: 10 | Time: 1m 6s
2024-01-10 22:59 - INFO - 	 Train Loss: 0.483
2024-01-10 22:59 - INFO - 	 Val. Loss: 0.495
2024-01-10 22:59 - INFO - 	 ROC-AUC: 0.727
2024-01-10 22:59 - INFO - 	 PR-AUC: 0.443
2024-01-10 22:59 - INFO - 	 Recall for 0.4 precision: 0.646
2024-01-10 22:59 - INFO - 	 Best Val. Loss: 0.495
2024-01-10 22:59 - INFO - 	 Best ROC-AUC: 0.728
2024-01-10 22:59 - INFO - 	 Best PR-AUC: 0.445
2024-01-10 22:59 - INFO - 	 Best Recall for 0.4 precision: 0.653
2024-01-10 22:59 - INFO - ---------------------------------------------
